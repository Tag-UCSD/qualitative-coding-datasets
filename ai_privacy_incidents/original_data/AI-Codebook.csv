AIAAIC ID,Content,Thematic Tag,Theme,Incident Title,Analysis Timeline,URL,Issue,Released,Occurred,Ended,Countries,Sectors,Deployers,Developers,System name,Technology,Purpose,Media Trigger,Issues,Transparency,External harms-individual,External harms-Societal,External harms-Environmental,Strategic_reputational,Operational,Financial,Legal/regulatory,Insights,Created,URL
AIAAIC1158,"Generative AI tools such as ChatGPT, Baidu-UNIT, and AI2sql can be tricked into producing malicious code, which could be used to launch cyber attacks, according to new research.  University of Sheffield researchers found that it is possible to manipulate six commercial AI tools capable of generating responses to text-to-SQL queries, including ChatGPT, into creating code capable of breaching other systems, steal sensitive personal information, tamper with or destroy databases, or bring down services using denial-of-service attacks. According to the researchers, OpenAI has since fixed all of the specific issues, as has Baidu, which financially rewarded the scientists. Developers of the four other systems have not responded publicly.",Entity - AI algorithm,Responsible Entities,ChatGPT writes code that makes databases leak sensitive info,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-writes-code-that-makes-databases-leak-sensitive-info,Issue,2022,2023,2023,USA,Technology,,AI2sql; Baidu; NiceAdmin; OpenAI; Text2SQL.AI; SQLAI.AI  ,AIHelperBot; AI2sql; Baidu-UNIT; ChatGPT; Text2SQL.AI; TOOLSKE,Chatbot; Text-to-SQL; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,Research study/report,Privacy; Security,Governance,Privacy loss,,,,,,,,10/7/2024 0:30,https://best-paper-award-ddck.dovetail.com/data/35eOWVfM6Fct55XHEj9btG#:v:h=1aa28fA5Dj68IsPzqyNq5
AIAAIC1158,"Generative AI tools such as ChatGPT, Baidu-UNIT, and AI2sql can be tricked into producing malicious code, which could be used to launch cyber attacks, according to new research.  University of Sheffield researchers found that it is possible to manipulate six commercial AI tools capable of generating responses to text-to-SQL queries, including ChatGPT, into creating code capable of breaching other systems, steal sensitive personal information, tamper with or destroy databases, or bring down services using denial-of-service attacks. According to the researchers, OpenAI has since fixed all of the specific issues, as has Baidu, which financially rewarded the scientists. Developers of the four other systems have not responded publicly.",Incident - organization-driven - problematic AI implementation,Incident Type,ChatGPT writes code that makes databases leak sensitive info,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-writes-code-that-makes-databases-leak-sensitive-info,Issue,2022,2023,2023,USA,Technology,,AI2sql; Baidu; NiceAdmin; OpenAI; Text2SQL.AI; SQLAI.AI  ,AIHelperBot; AI2sql; Baidu-UNIT; ChatGPT; Text2SQL.AI; TOOLSKE,Chatbot; Text-to-SQL; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,Research study/report,Privacy; Security,Governance,Privacy loss,,,,,,,,10/7/2024 0:30,https://best-paper-award-ddck.dovetail.com/data/35eOWVfM6Fct55XHEj9btG#:v:h=1aa28fA5Dj68IsPzqyNq5
AIAAIC1158,"Generative AI tools such as ChatGPT, Baidu-UNIT, and AI2sql can be tricked into producing malicious code, which could be used to launch cyber attacks, according to new research.  University of Sheffield researchers found that it is possible to manipulate six commercial AI tools capable of generating responses to text-to-SQL queries, including ChatGPT, into creating code capable of breaching other systems, steal sensitive personal information, tamper with or destroy databases, or bring down services using denial-of-service attacks. According to the researchers, OpenAI has since fixed all of the specific issues, as has Baidu, which financially rewarded the scientists. Developers of the four other systems have not responded publicly.",Cause - Human causes - Human abuse of AI tools,Cause,ChatGPT writes code that makes databases leak sensitive info,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-writes-code-that-makes-databases-leak-sensitive-info,Issue,2022,2023,2023,USA,Technology,,AI2sql; Baidu; NiceAdmin; OpenAI; Text2SQL.AI; SQLAI.AI  ,AIHelperBot; AI2sql; Baidu-UNIT; ChatGPT; Text2SQL.AI; TOOLSKE,Chatbot; Text-to-SQL; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,Research study/report,Privacy; Security,Governance,Privacy loss,,,,,,,,10/7/2024 0:30,https://best-paper-award-ddck.dovetail.com/data/35eOWVfM6Fct55XHEj9btG#:v:h=1aa28fA5Dj68IsPzqyNq5
AIAAIC1325,Amazon was fined EUR 32 million by France's privacy regulator for the 'excessive' and 'illegal' monitoring of staff activity and performance using scanners and several software systems.,Entity - AI developer company,Responsible Entities,Amazon France fined for excessive automated monitoring of workers,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-france-fined-for-excessive-automated-monitoring-of-workers,Incident,,2020,2024,France,Transport/logistics,Amazon France Logistique,Amazon France,"Stow Machine Gun indicator; Idle Time indicator, Latency under ten minutes indicator",Handheld scanner,Monitor employee performance,Regulatory inquiry/investigation,Employment; Necessity/proportionality; Privacy,Governance; Marketing,Privacy loss,,,,,EUR 32 million fine,Regulatory investigation,,10/2/2024 20:14,https://best-paper-award-ddck.dovetail.com/data/5XKzZRCbZ9Dzw1Zm8U8bJ1#:v:h=1E1G4yIRYbxSiWAD2Egsq
AIAAIC1325,Amazon was fined EUR 32 million by France's privacy regulator for the 'excessive' and 'illegal' monitoring of staff activity and performance using scanners and several software systems.,Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Amazon France fined for excessive automated monitoring of workers,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-france-fined-for-excessive-automated-monitoring-of-workers,Incident,,2020,2024,France,Transport/logistics,Amazon France Logistique,Amazon France,"Stow Machine Gun indicator; Idle Time indicator, Latency under ten minutes indicator",Handheld scanner,Monitor employee performance,Regulatory inquiry/investigation,Employment; Necessity/proportionality; Privacy,Governance; Marketing,Privacy loss,,,,,EUR 32 million fine,Regulatory investigation,,10/2/2024 20:14,https://best-paper-award-ddck.dovetail.com/data/5XKzZRCbZ9Dzw1Zm8U8bJ1#:v:h=1E1G4yIRYbxSiWAD2Egsq
AIAAIC0994,"My AI, a ChatGPT-powered chatbot launched by Snapchat, was discovered to be accessing users' location information and data, fueling concerns about its impact on user privacy and potential for surveillance. Software engineer David An used a prompt injection to reveal that the bot is provided with data showing where the user is located and the local time. In addition, he found that My AI's instructions state 'Do not mention the user’s current location unless it’s particularly relevant to the dialogue.'  And Insider journalist Jordan Hart persuaded the system to tell him his nearest pharmacy, which it did to within a few hundred yards. Snap responded by saying 'My AI understands a Snapchatter's age, and location if it has been granted by them.'",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Snapchat My AI accesses user location data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-location-access-opacity,Incident,2023,2023,2023,USA; Global,Media/entertainment/sports/arts,David An; Jordan Hart; Snapchat users,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning,"Provide information, communicate",User comments/complaints,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,,,10/11/2024 20:23,https://best-paper-award-ddck.dovetail.com/data/2LKScU9whfqvn0b7WetnZF#:v:h=22vMnpA1pHDwbRlHM2Bn7
AIAAIC0994,"My AI, a ChatGPT-powered chatbot launched by Snapchat, was discovered to be accessing users' location information and data, fueling concerns about its impact on user privacy and potential for surveillance. Software engineer David An used a prompt injection to reveal that the bot is provided with data showing where the user is located and the local time. In addition, he found that My AI's instructions state 'Do not mention the user’s current location unless it’s particularly relevant to the dialogue.'  And Insider journalist Jordan Hart persuaded the system to tell him his nearest pharmacy, which it did to within a few hundred yards. Snap responded by saying 'My AI understands a Snapchatter's age, and location if it has been granted by them.'",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Snapchat My AI accesses user location data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-location-access-opacity,Incident,2023,2023,2023,USA; Global,Media/entertainment/sports/arts,David An; Jordan Hart; Snapchat users,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning,"Provide information, communicate",User comments/complaints,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,,,10/11/2024 20:23,https://best-paper-award-ddck.dovetail.com/data/2LKScU9whfqvn0b7WetnZF#:v:h=22vMnpA1pHDwbRlHM2Bn7
AIAAIC0985,"The chat histories and, in some instances, the payment information of ChatGPT users were exposed to other users, prompting users to complain about poor system robustness, security, and privacy. According to OpenAI, 'In the hours before we took ChatGPT offline on Monday, it was possible for some users to see another active user’s first and last name, email address, payment address, the last four digits (only) of a credit card number, and credit card expiration date. Full credit card numbers were not exposed at any time.' Users' conversations with ChatGPT are stored in their chat history bar and can be revisited.",Cause - organization causes - lack of AI fail-safe measures,Cause,ChatGPT bug reveals user chat histories,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-bug-reveals-user-chat-histories,Incident,2022,2023,2023,USA; Global,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot; Machine learning,"Provide information, communicate",,Robustness; Privacy; Security,Governance; Black box,Privacy loss,,,,System suspension; System fix,,,,10/11/2024 20:38,https://best-paper-award-ddck.dovetail.com/data/3zQHmjyUK4sWrYiltP3q4Y#:v:h=25rJcQZwj3E1d7HbgKb16
AIAAIC0985,"The chat histories and, in some instances, the payment information of ChatGPT users were exposed to other users, prompting users to complain about poor system robustness, security, and privacy. According to OpenAI, 'In the hours before we took ChatGPT offline on Monday, it was possible for some users to see another active user’s first and last name, email address, payment address, the last four digits (only) of a credit card number, and credit card expiration date. Full credit card numbers were not exposed at any time.' Users' conversations with ChatGPT are stored in their chat history bar and can be revisited.",Entity - AI developer company,Responsible Entities,ChatGPT bug reveals user chat histories,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-bug-reveals-user-chat-histories,Incident,2022,2023,2023,USA; Global,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot; Machine learning,"Provide information, communicate",,Robustness; Privacy; Security,Governance; Black box,Privacy loss,,,,System suspension; System fix,,,,10/11/2024 20:38,https://best-paper-award-ddck.dovetail.com/data/3zQHmjyUK4sWrYiltP3q4Y#:v:h=25rJcQZwj3E1d7HbgKb16
AIAAIC0985,"The chat histories and, in some instances, the payment information of ChatGPT users were exposed to other users, prompting users to complain about poor system robustness, security, and privacy. According to OpenAI, 'In the hours before we took ChatGPT offline on Monday, it was possible for some users to see another active user’s first and last name, email address, payment address, the last four digits (only) of a credit card number, and credit card expiration date. Full credit card numbers were not exposed at any time.' Users' conversations with ChatGPT are stored in their chat history bar and can be revisited.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,ChatGPT bug reveals user chat histories,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-bug-reveals-user-chat-histories,Incident,2022,2023,2023,USA; Global,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot; Machine learning,"Provide information, communicate",,Robustness; Privacy; Security,Governance; Black box,Privacy loss,,,,System suspension; System fix,,,,10/11/2024 20:38,https://best-paper-award-ddck.dovetail.com/data/3zQHmjyUK4sWrYiltP3q4Y#:v:h=25rJcQZwj3E1d7HbgKb16
AIAAIC1147,"A few weeks earlier, 4chan members were discovered to be using ElevenLabs' voice generator to make celebrity voices read highly offensive messages. ",Entity - malicious human,Responsible Entities,Video game voice actors attacked using their own AI voices,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/video-game-voice-actors-attacked-using-their-own-ai-voices,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,ElevenLabs,ElevenLabs TTS; Prime Voice AI,Text-to-speech; Deep learning; Machine learning,Attack voice actors,User comments/complaints,Employment; Privacy; Safety,Governance; Marketing,Harassment,,,,,,,,10/11/2024 14:20,https://best-paper-award-ddck.dovetail.com/data/2CdZ2kjjZx5DEZ2wPi0aCY#:v:h=2VWZ2l3vj7h3ILoKY3Brh
AIAAIC0948,"The GFF had argued (in German) that Hesse and Hamburg had not made clear which sources the police could use for obtaining data or how much and on what grounds data mining could be conducted by law enforcement. Hesse State Police had been using the so-called Hessendata platform, which is based on Gotham. Hessendata reportedly triangulates datasets from police and other databases, including social media, to enable the analysis of potential suspects.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Hesse state Palantir predictive policing ruled 'unconstitutional',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hesse-palantir-predictive-policing,Incident,,2023,2023,Germany,Govt - police,Hesse State Police,Palantir,Hessendata; Gotham,Prediction algorithm,Predict crime,Lawsuit filing/litigation,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance; Black box,,Unconstitutional,,,Product ban,,Litigation,,10/13/2024 22:32,https://best-paper-award-ddck.dovetail.com/data/7u0NT2v9zlyvmGEXg8vJKl#:v:h=3vqHW193wbuccKPzcT9c0
AIAAIC1518,"Dataset LAION-5B was found to contain personal photos and details of identifiable Brazilian children without their knowledge or consent, prompting concerns about privacy and its creator's governance and integrity.",Cause - organization/human cause - lack of informed consent & transparency,Cause,LAION-5B links to photos of identifiable Brazilian children,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/laion-5b-links-to-photos-of-identifiable-brazilian-children,Incident,2020,2024,2024,Brazil,Private - individual,Human Rights Watch,LAION,LAION-5B,Database/dataset; Neural network; Deep learning; Machine learning,Pair text and images,Research study/report,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 11:55,https://best-paper-award-ddck.dovetail.com/data/zsB8JITme60asEvuq1ZUs#:v:h=3AWENWbzsQfTao8JXyPvF
AIAAIC1518,"Dataset LAION-5B was found to contain personal photos and details of identifiable Brazilian children without their knowledge or consent, prompting concerns about privacy and its creator's governance and integrity.",Entity - large dataset organization,Responsible Entities,LAION-5B links to photos of identifiable Brazilian children,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/laion-5b-links-to-photos-of-identifiable-brazilian-children,Incident,2020,2024,2024,Brazil,Private - individual,Human Rights Watch,LAION,LAION-5B,Database/dataset; Neural network; Deep learning; Machine learning,Pair text and images,Research study/report,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 11:55,https://best-paper-award-ddck.dovetail.com/data/zsB8JITme60asEvuq1ZUs#:v:h=3AWENWbzsQfTao8JXyPvF
AIAAIC1492,"Slack came under fire for using user messages and files to train its AI models by default, without explicit user consent.  Knowledge-sharing company Slack was found to have started training its AI models on its customers' data and information, without telling them or seeking their consent. In an undated statement on privacy principles quietly posted overnight to its website, Slack recommended that users wishing to opt-out of its AI training programme must do so by emailing the company, raising concerns about the use and misuse of potentially sensitive corporate and personal information.  In response, Slack said that user data would not be shared with third-party providers for training purposes and that customer data never leaves the platform.  The company also updated its privacy principles in an attempt to better explain the relationship between customer data and generative AI in Slack.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Slack forces users to opt-out of training its AI models,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/slack-uses-user-data-to-train-ai-models,Issue,2024,2024,2024,Global,Multiple,Salesforce/Slack,Salesforce/Slack,Bing Search; Google Search ,Machine learning,Predict search results; Recommend channels,Company statement,Confidentality; Privacy; Security,Governance; Marketing,Confidentiality loss; Privacy loss,,,,,,,,9/27/2024 0:41,https://best-paper-award-ddck.dovetail.com/data/5dWDeBQwyymYsMUz1BXFNg#:v:h=5CyT9foslDmjmryozAElP
AIAAIC1492,"Slack came under fire for using user messages and files to train its AI models by default, without explicit user consent.  Knowledge-sharing company Slack was found to have started training its AI models on its customers' data and information, without telling them or seeking their consent. In an undated statement on privacy principles quietly posted overnight to its website, Slack recommended that users wishing to opt-out of its AI training programme must do so by emailing the company, raising concerns about the use and misuse of potentially sensitive corporate and personal information.  In response, Slack said that user data would not be shared with third-party providers for training purposes and that customer data never leaves the platform.  The company also updated its privacy principles in an attempt to better explain the relationship between customer data and generative AI in Slack.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Slack forces users to opt-out of training its AI models,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/slack-uses-user-data-to-train-ai-models,Issue,2024,2024,2024,Global,Multiple,Salesforce/Slack,Salesforce/Slack,Bing Search; Google Search ,Machine learning,Predict search results; Recommend channels,Company statement,Confidentality; Privacy; Security,Governance; Marketing,Confidentiality loss; Privacy loss,,,,,,,,9/27/2024 0:41,https://best-paper-award-ddck.dovetail.com/data/5dWDeBQwyymYsMUz1BXFNg#:v:h=5CyT9foslDmjmryozAElP
AIAAIC1492,"Slack came under fire for using user messages and files to train its AI models by default, without explicit user consent.  Knowledge-sharing company Slack was found to have started training its AI models on its customers' data and information, without telling them or seeking their consent. In an undated statement on privacy principles quietly posted overnight to its website, Slack recommended that users wishing to opt-out of its AI training programme must do so by emailing the company, raising concerns about the use and misuse of potentially sensitive corporate and personal information.  In response, Slack said that user data would not be shared with third-party providers for training purposes and that customer data never leaves the platform.  The company also updated its privacy principles in an attempt to better explain the relationship between customer data and generative AI in Slack.",Entity - AI developer company,Responsible Entities,Slack forces users to opt-out of training its AI models,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/slack-uses-user-data-to-train-ai-models,Issue,2024,2024,2024,Global,Multiple,Salesforce/Slack,Salesforce/Slack,Bing Search; Google Search ,Machine learning,Predict search results; Recommend channels,Company statement,Confidentality; Privacy; Security,Governance; Marketing,Confidentiality loss; Privacy loss,,,,,,,,9/27/2024 0:41,https://best-paper-award-ddck.dovetail.com/data/5dWDeBQwyymYsMUz1BXFNg#:v:h=5CyT9foslDmjmryozAElP
AIAAIC1080,"San Francisco-based digital artist 'Lapine' found that private medical photographs taken by her doctor when she was undergoing treatment for a rare genetic condition in 2013 had been used to train the image-text dataset LAION-5B.  According to Lapine, the photographs had been taken as part of her clinical documentation, and she signed documents that restricted their use to her medical file. Lapine had discovered her images on LAION through the Have I Been Trained tool, which allows artists to see if their work is being used to train AI image generation models.  The LAION-5B dataset is supposed only to use publicly available images on the web. Lapine said the surgeon who took the medical photos died of cancer in 2018; she suspects that they somehow left his practice's custody after that.  Ars Technica said it discovered 'thousands of similar patient medical record photos in the data set, each of which may have a similar questionable ethical or legal status, many of which have likely been integrated into popular image synthesis models that companies like Midjourney and Stability AI offer as a commercial service'.",Entity - large dataset organization,Responsible Entities,Artist's private medical image trains LAION dataset,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/artists-private-medical-image-trains-laion-dataset,Incident,2020,2023,2023,USA,Media/entertainment/sports/arts,,LAION,LAION-5B,Database/dataset; Neural network; Deep learning; Machine learning,Pair text and images,User comments/complaints,Privacy; Ethics/values,Governance; Complaints/appeals,Privacy loss,,,,,,,,10/7/2024 1:03,https://best-paper-award-ddck.dovetail.com/data/1me23UbzuiM8UZkQpYHqkd#:v:h=6jAYzxtgduB7h81PKtD0b
AIAAIC1080,"San Francisco-based digital artist 'Lapine' found that private medical photographs taken by her doctor when she was undergoing treatment for a rare genetic condition in 2013 had been used to train the image-text dataset LAION-5B.  According to Lapine, the photographs had been taken as part of her clinical documentation, and she signed documents that restricted their use to her medical file. Lapine had discovered her images on LAION through the Have I Been Trained tool, which allows artists to see if their work is being used to train AI image generation models.  The LAION-5B dataset is supposed only to use publicly available images on the web. Lapine said the surgeon who took the medical photos died of cancer in 2018; she suspects that they somehow left his practice's custody after that.  Ars Technica said it discovered 'thousands of similar patient medical record photos in the data set, each of which may have a similar questionable ethical or legal status, many of which have likely been integrated into popular image synthesis models that companies like Midjourney and Stability AI offer as a commercial service'.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Artist's private medical image trains LAION dataset,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/artists-private-medical-image-trains-laion-dataset,Incident,2020,2023,2023,USA,Media/entertainment/sports/arts,,LAION,LAION-5B,Database/dataset; Neural network; Deep learning; Machine learning,Pair text and images,User comments/complaints,Privacy; Ethics/values,Governance; Complaints/appeals,Privacy loss,,,,,,,,10/7/2024 1:03,https://best-paper-award-ddck.dovetail.com/data/1me23UbzuiM8UZkQpYHqkd#:v:h=6jAYzxtgduB7h81PKtD0b
AIAAIC1080,"San Francisco-based digital artist 'Lapine' found that private medical photographs taken by her doctor when she was undergoing treatment for a rare genetic condition in 2013 had been used to train the image-text dataset LAION-5B.  According to Lapine, the photographs had been taken as part of her clinical documentation, and she signed documents that restricted their use to her medical file. Lapine had discovered her images on LAION through the Have I Been Trained tool, which allows artists to see if their work is being used to train AI image generation models.  The LAION-5B dataset is supposed only to use publicly available images on the web. Lapine said the surgeon who took the medical photos died of cancer in 2018; she suspects that they somehow left his practice's custody after that.  Ars Technica said it discovered 'thousands of similar patient medical record photos in the data set, each of which may have a similar questionable ethical or legal status, many of which have likely been integrated into popular image synthesis models that companies like Midjourney and Stability AI offer as a commercial service'.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Artist's private medical image trains LAION dataset,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/artists-private-medical-image-trains-laion-dataset,Incident,2020,2023,2023,USA,Media/entertainment/sports/arts,,LAION,LAION-5B,Database/dataset; Neural network; Deep learning; Machine learning,Pair text and images,User comments/complaints,Privacy; Ethics/values,Governance; Complaints/appeals,Privacy loss,,,,,,,,10/7/2024 1:03,https://best-paper-award-ddck.dovetail.com/data/1me23UbzuiM8UZkQpYHqkd#:v:h=6jAYzxtgduB7h81PKtD0b
AIAAIC1196,announced it was opening an investigation into OpenAI's ChatGPT for violating the privacy of Polish users.,Entity - AI developer company,Responsible Entities,Poland investigates ChatGPT for alleged privacy abuse,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/poland-investigates-chatgpt-alleged-privacy-abuse,Incident,2022,2023,2023,Poland,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance; Privacy,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:14,https://best-paper-award-ddck.dovetail.com/data/6MIgBLj98nrsZHmvhkHkHV#:v:h=6woI0jOnBgXF77VSkoBSj
AIAAIC1105,"Multiple instances of non-consensual sexual imagery of specific people have been discovered on online AI model marketplace CivitAI. Despite the company's terms of service saying it would remove 'content depicting or intended to depict real individuals or minors (under 18) in a mature context,' a 404 Media investigation uncovered a Billie Eilish model that generated nude images of a pregnant Eilish that was 'in place for weeks' before being removed. According to 404 Media, while CivitAI does enforce its policy and remove offending content, non-consensual sexual imagery is still posted to the site 'regularly', some of which stays on the platform 'for months'. The Billie Eilish model, and the user who created the nude images, were allowed to remain on the site, alongside images of the singer clad in lingerie and with very large breasts, both of which are against CivitAI’s terms of service.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,CivitAI generates nonconsensual AI pornography,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-nonconsensual-ai-pornography,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Media investigation,Ethics/values; Privacy; Safety,Governance,Dehumanisation/objectification,,,,,,,,10/7/2024 0:59,https://best-paper-award-ddck.dovetail.com/data/6pBwAolbSEH2RW1V8CYG5N#:v:h=9a2Y1BdXPkttP5tKffsFA
AIAAIC1105,"Multiple instances of non-consensual sexual imagery of specific people have been discovered on online AI model marketplace CivitAI. Despite the company's terms of service saying it would remove 'content depicting or intended to depict real individuals or minors (under 18) in a mature context,' a 404 Media investigation uncovered a Billie Eilish model that generated nude images of a pregnant Eilish that was 'in place for weeks' before being removed. According to 404 Media, while CivitAI does enforce its policy and remove offending content, non-consensual sexual imagery is still posted to the site 'regularly', some of which stays on the platform 'for months'. The Billie Eilish model, and the user who created the nude images, were allowed to remain on the site, alongside images of the singer clad in lingerie and with very large breasts, both of which are against CivitAI’s terms of service.",Cause - developer causes - programmed AI with problematic functions,Cause,CivitAI generates nonconsensual AI pornography,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-nonconsensual-ai-pornography,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Media investigation,Ethics/values; Privacy; Safety,Governance,Dehumanisation/objectification,,,,,,,,10/7/2024 0:59,https://best-paper-award-ddck.dovetail.com/data/6pBwAolbSEH2RW1V8CYG5N#:v:h=9a2Y1BdXPkttP5tKffsFA
AIAAIC1225,It also raised questions about OpenAI's corporate and product transparency.  ,Cause - organization/human cause - lack of informed consent & transparency,Cause,ChatGPT used to collect users' personal information ,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-used-to-collect-users-personal-information,Issue,,2023,2023,USA; Switzerland,Multiple,"Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramèr, Katherine Lee",OpenAI,ChatGPT; GPT-3,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Research study/report,Privacy; Security,,Privacy loss,,,,,,,,10/11/2024 13:33,https://best-paper-award-ddck.dovetail.com/data/1Sa11cldSvyodSULBtLMq1#:v:h=dAE9gpj9kUivtLqEDZCK6
AIAAIC1237,as well as privacy risks to people who do not want their images being used to train AI.,Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Image-generation AIs memorise training images,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/image-generation-ais-memorise-training-images,Issue,2022,2023,2023,Global,Multiple,"Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace",Google; OpenAI; Stability AI,DALL-E; Imagen; Stable Diffusion,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Research study/report,Copyright; Privacy,Governance,IP/copyright loss; Privacy loss,,,,,,,,10/11/2024 13:29,https://best-paper-award-ddck.dovetail.com/data/64MgH0sdqN50AnnPT8bjZU#:v:h=fLvhFlFWMVqc0OoILZueh
AIAAIC0948,Palantir has also been the subject of controversy in Denmark and the Netherlands over its potential for inaccuracy and ability to reinforce racial and ethnic bias,Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Hesse state Palantir predictive policing ruled 'unconstitutional',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hesse-palantir-predictive-policing,Incident,,2023,2023,Germany,Govt - police,Hesse State Police,Palantir,Hessendata; Gotham,Prediction algorithm,Predict crime,Lawsuit filing/litigation,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance; Black box,,Unconstitutional,,,Product ban,,Litigation,,10/13/2024 22:32,https://best-paper-award-ddck.dovetail.com/data/7u0NT2v9zlyvmGEXg8vJKl#:v:h=g03BBiCSLfvCE20aG4fbw
AIAAIC0948,Palantir has also been the subject of controversy in Denmark and the Netherlands over its potential for inaccuracy and ability to reinforce racial and ethnic bias,Cause - AI causes - potential AI bias (racism - inequality) ,Cause,Hesse state Palantir predictive policing ruled 'unconstitutional',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hesse-palantir-predictive-policing,Incident,,2023,2023,Germany,Govt - police,Hesse State Police,Palantir,Hessendata; Gotham,Prediction algorithm,Predict crime,Lawsuit filing/litigation,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance; Black box,,Unconstitutional,,,Product ban,,Litigation,,10/13/2024 22:32,https://best-paper-award-ddck.dovetail.com/data/7u0NT2v9zlyvmGEXg8vJKl#:v:h=g03BBiCSLfvCE20aG4fbw
AIAAIC1129,"Snapchat owner Snap Inc has been issued with a provisional enforcement notice by the UK privacy watchdog for failing to assess privacy risks its My AI chatbot poses to users, notably children.  The UK Information Commissioner's Office (ICO) said Snap had failed to 'adequately identify and assess the risks' to several million UK users of My AI, including among 13- to 17-year-olds. Snap responded by saying it would 'work constructively' with the ICO, and that it had carried out a 'robust legal and privacy review' before My AI was launched.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Snapchat fails to assess My AI privacy risks,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-fails-to-assess-my-ai-privacy-risks,Incident,2023,2023,2023,UK,Media/entertainment/sports/arts,,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:45,https://best-paper-award-ddck.dovetail.com/data/5N2M5pNyD71iGlNTxFx7gs#:v:h=i7vOduagiz647NFbbzRlU
AIAAIC1129,"Snapchat owner Snap Inc has been issued with a provisional enforcement notice by the UK privacy watchdog for failing to assess privacy risks its My AI chatbot poses to users, notably children.  The UK Information Commissioner's Office (ICO) said Snap had failed to 'adequately identify and assess the risks' to several million UK users of My AI, including among 13- to 17-year-olds. Snap responded by saying it would 'work constructively' with the ICO, and that it had carried out a 'robust legal and privacy review' before My AI was launched.",Cause - organization causes - poor business ethics,Cause,Snapchat fails to assess My AI privacy risks,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-fails-to-assess-my-ai-privacy-risks,Incident,2023,2023,2023,UK,Media/entertainment/sports/arts,,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:45,https://best-paper-award-ddck.dovetail.com/data/5N2M5pNyD71iGlNTxFx7gs#:v:h=i7vOduagiz647NFbbzRlU
AIAAIC1129,"Snapchat owner Snap Inc has been issued with a provisional enforcement notice by the UK privacy watchdog for failing to assess privacy risks its My AI chatbot poses to users, notably children.  The UK Information Commissioner's Office (ICO) said Snap had failed to 'adequately identify and assess the risks' to several million UK users of My AI, including among 13- to 17-year-olds. Snap responded by saying it would 'work constructively' with the ICO, and that it had carried out a 'robust legal and privacy review' before My AI was launched.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Snapchat fails to assess My AI privacy risks,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-fails-to-assess-my-ai-privacy-risks,Incident,2023,2023,2023,UK,Media/entertainment/sports/arts,,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:45,https://best-paper-award-ddck.dovetail.com/data/5N2M5pNyD71iGlNTxFx7gs#:v:h=i7vOduagiz647NFbbzRlU
AIAAIC1129,"Snapchat owner Snap Inc has been issued with a provisional enforcement notice by the UK privacy watchdog for failing to assess privacy risks its My AI chatbot poses to users, notably children.  The UK Information Commissioner's Office (ICO) said Snap had failed to 'adequately identify and assess the risks' to several million UK users of My AI, including among 13- to 17-year-olds. Snap responded by saying it would 'work constructively' with the ICO, and that it had carried out a 'robust legal and privacy review' before My AI was launched.",Cause - organization causes - legal non-compliance,Cause,Snapchat fails to assess My AI privacy risks,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-fails-to-assess-my-ai-privacy-risks,Incident,2023,2023,2023,UK,Media/entertainment/sports/arts,,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:45,https://best-paper-award-ddck.dovetail.com/data/5N2M5pNyD71iGlNTxFx7gs#:v:h=i7vOduagiz647NFbbzRlU
"AIAAIC1773
","Character AI allows users to create characters based on real people, but this case illustrates the platform's failure to prevent unauthorised impersonation.",Incident - human-driven - bypassing AI safeguards,Incident Type,"Character AI used to create ""disturbing"" Jennifer Ann Clemente persona",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/character-ai-fails-to-police-non-consensual-ai-personas,Incident,,2024,2024,"USA
","Media/entertainment/sports/arts
",,,,,,,,,,,,,,,,,11/4/2024 17:03,https://best-paper-award-ddck.dovetail.com/data/2RnvcQTcMjOqJ18UMfJxtK#:v:h=jv72HXD6wiaEgoZB0ZUOZ
AIAAIC1120,"suggesting OpenAI had access to user conversations, and calling into question the company's privacy duty of care.",Entity - AI developer company,Responsible Entities,"ChatGPT leaks user conversations, personal information",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-leaks-user-conversations,Incident,2022,2023,2023,USA,Technology,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,,Privacy,Governance,Privacy loss,,,,System update,,,,10/11/2024 14:29,https://best-paper-award-ddck.dovetail.com/data/7Innvupi1JGm8bssWwNSJA#:v:h=jRNWYlbgUY8nChFQrihsw
AIAAIC1025,"Alicante, Spain-based manufacturing business Albero Forte Composite (aka Plastic Forte) was fined by the country's data protection authority for violating the privacy of its workers using facial recognition.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Plastic Forte employee facial recognition monitoring,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/plastic-forte-employee-facial-recognition-monitoring,Incident,,2023,2023,Spain,Manufacturing/engineering,Albero Forte Composite (Plastic Forte),,,Facial recognition,Improve productivity,Regulatory ruling,Privacy; Necessity/proportionality,Governance; Privacy; Marketing,,,,,,"EUR 12,000 fine",Regulatory investigation,,10/11/2024 18:32,https://best-paper-award-ddck.dovetail.com/data/2YeP3iocQDgZqOPgVqtW74#:v:h=luUNXdM2DkBi54eqVZdsL
AIAAIC1025,"Alicante, Spain-based manufacturing business Albero Forte Composite (aka Plastic Forte) was fined by the country's data protection authority for violating the privacy of its workers using facial recognition.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Plastic Forte employee facial recognition monitoring,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/plastic-forte-employee-facial-recognition-monitoring,Incident,,2023,2023,Spain,Manufacturing/engineering,Albero Forte Composite (Plastic Forte),,,Facial recognition,Improve productivity,Regulatory ruling,Privacy; Necessity/proportionality,Governance; Privacy; Marketing,,,,,,"EUR 12,000 fine",Regulatory investigation,,10/11/2024 18:32,https://best-paper-award-ddck.dovetail.com/data/2YeP3iocQDgZqOPgVqtW74#:v:h=luUNXdM2DkBi54eqVZdsL
AIAAIC1015,President Recep Tayyip Erdogan showed the video,Entity - malicious human,Responsible Entities,Election deepfake falsely links Kemal Kilicdaroglu to PKK,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kemal-kilicdaroglu-pkk-links-deepfake,Incident,,2023,2023,Turkey,Politics,,Government of Russia,,Deepfake - video; Machine learning,Damage reputation,Candidate speech,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage,,,,,,,,11/4/2024 16:25,https://best-paper-award-ddck.dovetail.com/data/Sr6xTuaSAhyBCrIAw81n6#:v:h=peWxuueIkPkGKGHcJBHMt
AIAAIC1330,"Schools in the UK have been accused of covertly monitoring students in toilets in an attempt to curb vaping, bullying, and unruly behaviour, without their parents' permission. According to SchoolsWeek, schools have been using products such as Triton's 3D Pro Sensor to actively detect vape smells and anomolous noises using sensors, as well as certain keywords through machine learning algorithms, which trigger alerts to selected staff members.  The report cited the head teacher at Baxter College, Kidderminster, acknowledging that parental permission had not been obtained, though parents were very positive' about the school's attempts to crack down on vaping, she said.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Toilet sensors ‘actively listen’ to school pupils,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/toilet-sensors-actively-listen-to-uk-school-pupils,Issue,,2024,2024,UK,Education,"Baxter College, Kidderminster",Triton,3D Sense Pro,Machine learning; Keyword detection,Detect vaping; Increase safety,Media investigation,Privacy,Marketing,Privacy loss,,,,,,,,10/2/2024 20:06,https://best-paper-award-ddck.dovetail.com/data/735qJPdpGQbLfnjqJhjqGG#:v:h=pnAxARspjgDYxEET3Bnp9
AIAAIC1330,"Schools in the UK have been accused of covertly monitoring students in toilets in an attempt to curb vaping, bullying, and unruly behaviour, without their parents' permission. According to SchoolsWeek, schools have been using products such as Triton's 3D Pro Sensor to actively detect vape smells and anomolous noises using sensors, as well as certain keywords through machine learning algorithms, which trigger alerts to selected staff members.  The report cited the head teacher at Baxter College, Kidderminster, acknowledging that parental permission had not been obtained, though parents were very positive' about the school's attempts to crack down on vaping, she said.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Toilet sensors ‘actively listen’ to school pupils,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/toilet-sensors-actively-listen-to-uk-school-pupils,Issue,,2024,2024,UK,Education,"Baxter College, Kidderminster",Triton,3D Sense Pro,Machine learning; Keyword detection,Detect vaping; Increase safety,Media investigation,Privacy,Marketing,Privacy loss,,,,,,,,10/2/2024 20:06,https://best-paper-award-ddck.dovetail.com/data/735qJPdpGQbLfnjqJhjqGG#:v:h=pnAxARspjgDYxEET3Bnp9
AIAAIC0917,"Mental health non-profit Koko use GPT-3 in a Discord-based 'experiment' to provide support to people seeking counseling was criticised for failing to obtain the informed consent of the 4,000 people using the system.  Users send direct messages to the Discord 'Kokobot' that asks several multiple-choice questions, and then shares a person's concerns anonymously with someone else on the server who can reply anonymously with a short message - either of their own, or one automatically generated by GPT-3.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Koko AI mental health counselling 'experiment' fails to obtain user consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/koko-ai-mental-health-counselling-experiment,Incident,,2023,2023,USA,Multiple; Health,Koko; Discord,Koko,GPT-3,Large language model; Machine learning,Provide mental health support,CEO statement,Ethics/values; Privacy,Governance,,,,,,,,,10/13/2024 22:38,https://best-paper-award-ddck.dovetail.com/data/4m68Cxn6n7RdYeBNYZskV0#:v:h=pWlslrxzzDfIL5bdTcnqB
AIAAIC0917,"Mental health non-profit Koko use GPT-3 in a Discord-based 'experiment' to provide support to people seeking counseling was criticised for failing to obtain the informed consent of the 4,000 people using the system.  Users send direct messages to the Discord 'Kokobot' that asks several multiple-choice questions, and then shares a person's concerns anonymously with someone else on the server who can reply anonymously with a short message - either of their own, or one automatically generated by GPT-3.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Koko AI mental health counselling 'experiment' fails to obtain user consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/koko-ai-mental-health-counselling-experiment,Incident,,2023,2023,USA,Multiple; Health,Koko; Discord,Koko,GPT-3,Large language model; Machine learning,Provide mental health support,CEO statement,Ethics/values; Privacy,Governance,,,,,,,,,10/13/2024 22:38,https://best-paper-award-ddck.dovetail.com/data/4m68Cxn6n7RdYeBNYZskV0#:v:h=pWlslrxzzDfIL5bdTcnqB
AIAAIC0917,"Mental health non-profit Koko use GPT-3 in a Discord-based 'experiment' to provide support to people seeking counseling was criticised for failing to obtain the informed consent of the 4,000 people using the system.  Users send direct messages to the Discord 'Kokobot' that asks several multiple-choice questions, and then shares a person's concerns anonymously with someone else on the server who can reply anonymously with a short message - either of their own, or one automatically generated by GPT-3.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Koko AI mental health counselling 'experiment' fails to obtain user consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/koko-ai-mental-health-counselling-experiment,Incident,,2023,2023,USA,Multiple; Health,Koko; Discord,Koko,GPT-3,Large language model; Machine learning,Provide mental health support,CEO statement,Ethics/values; Privacy,Governance,,,,,,,,,10/13/2024 22:38,https://best-paper-award-ddck.dovetail.com/data/4m68Cxn6n7RdYeBNYZskV0#:v:h=pWlslrxzzDfIL5bdTcnqB
AIAAIC0917,"Mental health non-profit Koko use GPT-3 in a Discord-based 'experiment' to provide support to people seeking counseling was criticised for failing to obtain the informed consent of the 4,000 people using the system.  Users send direct messages to the Discord 'Kokobot' that asks several multiple-choice questions, and then shares a person's concerns anonymously with someone else on the server who can reply anonymously with a short message - either of their own, or one automatically generated by GPT-3.",Cause - human causes - Overtrusting AI,Cause,Koko AI mental health counselling 'experiment' fails to obtain user consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/koko-ai-mental-health-counselling-experiment,Incident,,2023,2023,USA,Multiple; Health,Koko; Discord,Koko,GPT-3,Large language model; Machine learning,Provide mental health support,CEO statement,Ethics/values; Privacy,Governance,,,,,,,,,10/13/2024 22:38,https://best-paper-award-ddck.dovetail.com/data/4m68Cxn6n7RdYeBNYZskV0#:v:h=pWlslrxzzDfIL5bdTcnqB
AIAAIC1608,"The French national police were accused of secretly and illegally using facial recognition technology since 2015, sparking significant controversy and calls for an independent investigation.  The French national police quietly started using Israeli company BriefCam's Video Synposis facial recognition software since 2015, according to non-profit journalist outfit Disclose. The software, which allows for broad, one-to-many facial matching with minimal oversight, was reportedly installed in multiple police stations, including Paris and Marseilles.  The use of facial recognition violates French and European law, including the country's Informatics and Freedom Law and the EU's General Data Protection Act, which prohibit biometric identification systems and facial recognition techniques in most circumstances.  The discovery prompted concerns about mass surveillance and infringements on individual liberties and privacy, with France's police and the Ministry of the Interior accused of opacity and inadequate accountability. Critics claimed the use of facial recognition occurred without necessary data impact assessments or judicial oversight.",Entity - government authorities that adopt AI,Responsible Entities,French national police accused of illegally using facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/french-national-police-accused-of-illegally-using-facial-recognition,Issue,2015,2023,2023,France,Govt - police,Seine-et-Marne Departmental Directorate of Public Security,BriefCam,Video Synopsis,Facial recognition,Identify criminal suspects,NGO investigation,Privacy,Governance; Marketing,Privacy loss,,,,,,Govt investigation,,9/26/2024 23:41,https://best-paper-award-ddck.dovetail.com/data/5jeoMddR9Z62yQODuMQE4v#:v:h=qAFBLoPYBKL2yPDgHvJE1
AIAAIC1521,"A significant expansion and upgrade of police facial recognition and ethnic minority surveillance capabilities in Shanghai, China, raised concerns about the loss of human rights and liberties by Uyghurs and others.  A report by video research company IPVM revealed that Shanghai's Xuhui District completed the implementation of a facial recognition system that specifically detects ""Uyghur ethnicity"" based on facial features across thousands of cameras.  The system is part of a larger surveillance expansion reportedly aimed at capturing 25.9 million faces daily and storing them in a database of over 50 million individual files. The system performs ""Passerby Attribute Recognition"" analysis to assess attributes like gender, age group, and ""Uyghur ethnicity."" This data is then stored with corresponding images for retrieval by police and data analysis.  The report highlighted concerns about the discriminatory targeting of the Uyghur community and the pervasive surveillance of people's activities and movements, regardless of wrongdoing, by Shanghai authorities.",Cause - AI causes - potential AI bias (racism - inequality) ,Cause,"Shanghai triples facial urveillance in Xuhui district, raising concerns",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/shanghai-plans-to-triple-facial-surveillance-in-xuhui-district,Issue,,2024,2024,China,Govt - police,,,,Attribute recognition; Facial recognition,Identify and control ethnic minorities,Media investigation,Human/civil rights; Privacy,,Privacy loss,,,,,,,,9/27/2024 0:22,https://best-paper-award-ddck.dovetail.com/data/5Ah0qWMtocupQ6feMdKH73#:v:h=r5UZpUQ4tslbMyCx0vvdj
AIAAIC1521,"A significant expansion and upgrade of police facial recognition and ethnic minority surveillance capabilities in Shanghai, China, raised concerns about the loss of human rights and liberties by Uyghurs and others.  A report by video research company IPVM revealed that Shanghai's Xuhui District completed the implementation of a facial recognition system that specifically detects ""Uyghur ethnicity"" based on facial features across thousands of cameras.  The system is part of a larger surveillance expansion reportedly aimed at capturing 25.9 million faces daily and storing them in a database of over 50 million individual files. The system performs ""Passerby Attribute Recognition"" analysis to assess attributes like gender, age group, and ""Uyghur ethnicity."" This data is then stored with corresponding images for retrieval by police and data analysis.  The report highlighted concerns about the discriminatory targeting of the Uyghur community and the pervasive surveillance of people's activities and movements, regardless of wrongdoing, by Shanghai authorities.",Cause - Human causes - Undertrusting AI,Cause,"Shanghai triples facial urveillance in Xuhui district, raising concerns",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/shanghai-plans-to-triple-facial-surveillance-in-xuhui-district,Issue,,2024,2024,China,Govt - police,,,,Attribute recognition; Facial recognition,Identify and control ethnic minorities,Media investigation,Human/civil rights; Privacy,,Privacy loss,,,,,,,,9/27/2024 0:22,https://best-paper-award-ddck.dovetail.com/data/5Ah0qWMtocupQ6feMdKH73#:v:h=r5UZpUQ4tslbMyCx0vvdj
AIAAIC1521,"A significant expansion and upgrade of police facial recognition and ethnic minority surveillance capabilities in Shanghai, China, raised concerns about the loss of human rights and liberties by Uyghurs and others.  A report by video research company IPVM revealed that Shanghai's Xuhui District completed the implementation of a facial recognition system that specifically detects ""Uyghur ethnicity"" based on facial features across thousands of cameras.  The system is part of a larger surveillance expansion reportedly aimed at capturing 25.9 million faces daily and storing them in a database of over 50 million individual files. The system performs ""Passerby Attribute Recognition"" analysis to assess attributes like gender, age group, and ""Uyghur ethnicity."" This data is then stored with corresponding images for retrieval by police and data analysis.  The report highlighted concerns about the discriminatory targeting of the Uyghur community and the pervasive surveillance of people's activities and movements, regardless of wrongdoing, by Shanghai authorities.",Entity - government authorities that adopt AI,Responsible Entities,"Shanghai triples facial urveillance in Xuhui district, raising concerns",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/shanghai-plans-to-triple-facial-surveillance-in-xuhui-district,Issue,,2024,2024,China,Govt - police,,,,Attribute recognition; Facial recognition,Identify and control ethnic minorities,Media investigation,Human/civil rights; Privacy,,Privacy loss,,,,,,,,9/27/2024 0:22,https://best-paper-award-ddck.dovetail.com/data/5Ah0qWMtocupQ6feMdKH73#:v:h=r5UZpUQ4tslbMyCx0vvdj
AIAAIC1718,"Microsoft Dynamics 365's field service management tools have been criticised for potentially enabling excessive worker surveillance and micro-management. A report by Austrian research group Cracked Labs raised concerns about how the software allows employers to closely monitor mobile workers through smartphone apps. The software tracks workers' activities, locations, and other data points, which, the researchers argue, can diminish worker autonomy and discretion. It also uses AI to predicttask durations and single out individual workers' performance, raising questions about how this data could be used.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Microsoft app accused of enabling employee mobile surveillance,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/microsoft-app-accused-of-enabling-employee-mobile-surveillance,Issue,,2024,2024,Global,Multiple,Microsoft,Microsoft,Microsoft Dynamics 365 Field Service,Machine learning,Manage field service workers,Research study/report,Privacy; Surveillance,Governance,Privacy loss,,,,,,,,9/26/2024 20:05,https://best-paper-award-ddck.dovetail.com/data/2JgK8Oi0pMC0SA1PMCYJKY#:v:h=rdanmZ4rkjL10dL4Wqb8Y
AIAAIC1718,"Microsoft Dynamics 365's field service management tools have been criticised for potentially enabling excessive worker surveillance and micro-management. A report by Austrian research group Cracked Labs raised concerns about how the software allows employers to closely monitor mobile workers through smartphone apps. The software tracks workers' activities, locations, and other data points, which, the researchers argue, can diminish worker autonomy and discretion. It also uses AI to predicttask durations and single out individual workers' performance, raising questions about how this data could be used.",Cause - developer causes - programmed AI with problematic functions,Cause,Microsoft app accused of enabling employee mobile surveillance,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/microsoft-app-accused-of-enabling-employee-mobile-surveillance,Issue,,2024,2024,Global,Multiple,Microsoft,Microsoft,Microsoft Dynamics 365 Field Service,Machine learning,Manage field service workers,Research study/report,Privacy; Surveillance,Governance,Privacy loss,,,,,,,,9/26/2024 20:05,https://best-paper-award-ddck.dovetail.com/data/2JgK8Oi0pMC0SA1PMCYJKY#:v:h=rdanmZ4rkjL10dL4Wqb8Y
AIAAIC1718,"Microsoft Dynamics 365's field service management tools have been criticised for potentially enabling excessive worker surveillance and micro-management. A report by Austrian research group Cracked Labs raised concerns about how the software allows employers to closely monitor mobile workers through smartphone apps. The software tracks workers' activities, locations, and other data points, which, the researchers argue, can diminish worker autonomy and discretion. It also uses AI to predicttask durations and single out individual workers' performance, raising questions about how this data could be used.",Entity - AI developer company,Responsible Entities,Microsoft app accused of enabling employee mobile surveillance,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/microsoft-app-accused-of-enabling-employee-mobile-surveillance,Issue,,2024,2024,Global,Multiple,Microsoft,Microsoft,Microsoft Dynamics 365 Field Service,Machine learning,Manage field service workers,Research study/report,Privacy; Surveillance,Governance,Privacy loss,,,,,,,,9/26/2024 20:05,https://best-paper-award-ddck.dovetail.com/data/2JgK8Oi0pMC0SA1PMCYJKY#:v:h=rdanmZ4rkjL10dL4Wqb8Y
AIAAIC1744,"  without informing or gaining their consent  to train its own AI models and those of its ""affiliates"".  Revealed by  404 Media,  t he move  comes in the wake of an updated company privacy policy that explicitly states that user data from the platform will be used to train generative  AI and other models developed by LinkedIn, Microsoft and other unnamed ""affiliates"" and that  opting out will not affect any training that has already occurred using a user's  personal data or content.",Entity - AI developer company's affiliated parterns,Responsible Entities,LinkedIn trains AI models without user consent,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/linkedin-trains-ai-models-without-user-consent,Issue,,2024,2024,Global,Multiple,LinkedIn,LinkedIn,,Machine learning,Train AI models,User comments/complaints,Confidentality; Ethics/values; Privacy,Governance,Confidentiality loss; Privacy loss,,,,,,,,9/26/2024 18:30,https://best-paper-award-ddck.dovetail.com/data/5k4RicGAHvOEDcmUaFZPyG#:v:h=sCZFqbtD1GaWtIiUPTWHc
AIAAIC1744,"  without informing or gaining their consent  to train its own AI models and those of its ""affiliates"".  Revealed by  404 Media,  t he move  comes in the wake of an updated company privacy policy that explicitly states that user data from the platform will be used to train generative  AI and other models developed by LinkedIn, Microsoft and other unnamed ""affiliates"" and that  opting out will not affect any training that has already occurred using a user's  personal data or content.",Entity - AI developer company,Responsible Entities,LinkedIn trains AI models without user consent,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/linkedin-trains-ai-models-without-user-consent,Issue,,2024,2024,Global,Multiple,LinkedIn,LinkedIn,,Machine learning,Train AI models,User comments/complaints,Confidentality; Ethics/values; Privacy,Governance,Confidentiality loss; Privacy loss,,,,,,,,9/26/2024 18:30,https://best-paper-award-ddck.dovetail.com/data/5k4RicGAHvOEDcmUaFZPyG#:v:h=sCZFqbtD1GaWtIiUPTWHc
AIAAIC1744,"  without informing or gaining their consent  to train its own AI models and those of its ""affiliates"".  Revealed by  404 Media,  t he move  comes in the wake of an updated company privacy policy that explicitly states that user data from the platform will be used to train generative  AI and other models developed by LinkedIn, Microsoft and other unnamed ""affiliates"" and that  opting out will not affect any training that has already occurred using a user's  personal data or content.",Cause - organization/human cause - lack of informed consent & transparency,Cause,LinkedIn trains AI models without user consent,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/linkedin-trains-ai-models-without-user-consent,Issue,,2024,2024,Global,Multiple,LinkedIn,LinkedIn,,Machine learning,Train AI models,User comments/complaints,Confidentality; Ethics/values; Privacy,Governance,Confidentiality loss; Privacy loss,,,,,,,,9/26/2024 18:30,https://best-paper-award-ddck.dovetail.com/data/5k4RicGAHvOEDcmUaFZPyG#:v:h=sCZFqbtD1GaWtIiUPTWHc
AIAAIC1130,"The latest in a series of fraud attempts involving celebrities manipulated using synthetic media, the incident raised concerns about the volume and nature of deepfake impersonations. TikTok also came under fire for its apparent inability to properly moderate its platform.",Cause - Lack of AI control,Cause,Deepfake MrBeast iPhone giveaway scam,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-mrbeast-iphone-giveaway-scam,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,"Deepfake - video, audio; Machine learning",Defraud,User comments/complaints,Safety - fraud,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 16:29,https://best-paper-award-ddck.dovetail.com/data/4g64EwFnI9AeQ38FmWIPqm#:v:h=toinLXh38nyqEGWpskBKJ
AIAAIC1130,"The latest in a series of fraud attempts involving celebrities manipulated using synthetic media, the incident raised concerns about the volume and nature of deepfake impersonations. TikTok also came under fire for its apparent inability to properly moderate its platform.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake MrBeast iPhone giveaway scam,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-mrbeast-iphone-giveaway-scam,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,"Deepfake - video, audio; Machine learning",Defraud,User comments/complaints,Safety - fraud,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 16:29,https://best-paper-award-ddck.dovetail.com/data/4g64EwFnI9AeQ38FmWIPqm#:v:h=toinLXh38nyqEGWpskBKJ
AIAAIC1179,"The bot is 'plagued by weak password requirements, sharing of personal data with advertisers, and recording of personal photos, videos, and voice and text messages consumers shared with the chatbot,' Mozilla found.",Cause - organization causes - lack of data protection,Cause,Replika shares user data with advertisers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-replika-fails-to-meet-minimum-privacy-standards,Issue,2017,2023,2023,Global,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Research study/report,Privacy,,,,,,,,,,10/7/2024 0:25,https://best-paper-award-ddck.dovetail.com/data/6Ictyc7kKTXwtfgaowLSph#:v:h=uu3PR5ZNCWlm066Bk7Ysn
AIAAIC1179,"The bot is 'plagued by weak password requirements, sharing of personal data with advertisers, and recording of personal photos, videos, and voice and text messages consumers shared with the chatbot,' Mozilla found.",Incident - organization-driven - unauthorized sell of user data,Incident Type,Replika shares user data with advertisers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-replika-fails-to-meet-minimum-privacy-standards,Issue,2017,2023,2023,Global,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Research study/report,Privacy,,,,,,,,,,10/7/2024 0:25,https://best-paper-award-ddck.dovetail.com/data/6Ictyc7kKTXwtfgaowLSph#:v:h=uu3PR5ZNCWlm066Bk7Ysn
AIAAIC0948,unconstitutional,Cause - organization causes - legal non-compliance,Cause,Hesse state Palantir predictive policing ruled 'unconstitutional',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hesse-palantir-predictive-policing,Incident,,2023,2023,Germany,Govt - police,Hesse State Police,Palantir,Hessendata; Gotham,Prediction algorithm,Predict crime,Lawsuit filing/litigation,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance; Black box,,Unconstitutional,,,Product ban,,Litigation,,10/18/2024 13:58,https://best-paper-award-ddck.dovetail.com/data/7u0NT2v9zlyvmGEXg8vJKl#:v:h=v283GWSJdnwRsEeVnM2aj
AIAAIC1726,"A long-time court reporter in the Tübingen area of Germany, Bernklau queried the system about himself, only tofind it incorrectly claimed he was a convicted child molester, an escapee from a psychiatric facility, and a fraudsterwho preyed on widows. The bot also provided Bernklau's personal information, including his full address and phone number Copilot appears to have mistakenly cast Bernklau as a perpetrator based on his decades of reporting on abuse,violence, and fraud cases.",Entity - AI algorithm,Responsible Entities,Copilot falsely accuses journalist of being a child molester and fraudster,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/copilot-falsely-accuses-journalist-of-being-a-child-molester-and-fraudster,Incident,,2024,2024,Germany,Media/entertainment/sports/arts,Martin Bernklau,Microsoft,Copilot,Chatbot; Machine learning,Generate text,Legal threat,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Defamation; Privacy loss,,,,,,,,9/26/2024 19:40,https://best-paper-award-ddck.dovetail.com/data/28PGP98tOtvO2BJTypDV9U#:v:h=y22DNxs0zeqVtGIgI3K2Y
AIAAIC1726,"A long-time court reporter in the Tübingen area of Germany, Bernklau queried the system about himself, only tofind it incorrectly claimed he was a convicted child molester, an escapee from a psychiatric facility, and a fraudsterwho preyed on widows. The bot also provided Bernklau's personal information, including his full address and phone number Copilot appears to have mistakenly cast Bernklau as a perpetrator based on his decades of reporting on abuse,violence, and fraud cases.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Copilot falsely accuses journalist of being a child molester and fraudster,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/copilot-falsely-accuses-journalist-of-being-a-child-molester-and-fraudster,Incident,,2024,2024,Germany,Media/entertainment/sports/arts,Martin Bernklau,Microsoft,Copilot,Chatbot; Machine learning,Generate text,Legal threat,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Defamation; Privacy loss,,,,,,,,9/26/2024 19:40,https://best-paper-award-ddck.dovetail.com/data/28PGP98tOtvO2BJTypDV9U#:v:h=y22DNxs0zeqVtGIgI3K2Y
AIAAIC1080,"The LAION-5B dataset is supposed only to use publicly available images on the web. Lapine said the surgeon who took the medical photos died of cancer in 2018; she suspects that they somehow left his practice's custody after that.  Ars Technica said it discovered 'thousands of similar patient medical record photos in the data set, each of which may have a similar questionable ethical or legal status, many of which have likely been integrated into popular image synthesis models that companies like Midjourney and Stability AI offer as a commercial service'.",Cause - organization causes - poor business ethics,Cause,Artist's private medical image trains LAION dataset,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/artists-private-medical-image-trains-laion-dataset,Incident,2020,2023,2023,USA,Media/entertainment/sports/arts,,LAION,LAION-5B,Database/dataset; Neural network; Deep learning; Machine learning,Pair text and images,User comments/complaints,Privacy; Ethics/values,Governance; Complaints/appeals,Privacy loss,,,,,,,,10/11/2024 14:44,https://best-paper-award-ddck.dovetail.com/data/1me23UbzuiM8UZkQpYHqkd#:v:h=ypynAJerdSU8coOmfF17W
AIAAIC1507,"“All Eyes on Rafah”, an AI-generated image that went viral online, prompted accusations of ""sanitisation"" of the Israel-Hamas war and ""slacktivism"". The fake image depicts tent camps for displaced Palestinians stretching out into the horizon, overlaid with the phrase ""All Eyes on Rafah"". The phrase was originally used by World Health Organization representative Dr. Richard “Rik” Peeperkorn. Apparently created by Malaysian Instagram user @shahv4012, ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,All eyes on Rafah' deepfake criticised for 'sanitising' Gaza invasion,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/all-eyes-on-rafah-deepfake-criticised-for-sanitising-gaza-invasion,Issue,,2024,2024,Israel; Palestine,Govt - police; Govt - security; Govt - defence; Politics,@shahv4012,,,Deepfake - image; Machine learning,,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 0:59,https://best-paper-award-ddck.dovetail.com/data/3pMQJiGVIlqWlwBZ77v23m#:v:h=zr4Hvnr4RTltg7XCOFj77
AIAAIC1179,"AI chatbot Replika makes little effort to protect its users' privacy, according to a research study. According to a May 2023 Mozilla Foundation assessment of mental health apps, Replika is one of the worst apps Mozilla has ever reviewed', and 'a hot mess of privacy and creepiness'. ",Entity - AI developer company,Responsible Entities,Replika shares user data with advertisers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-replika-fails-to-meet-minimum-privacy-standards,Issue,2017,2023,2023,Global,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Research study/report,Privacy,,,,,,,,,,10/7/2024 0:24,https://best-paper-award-ddck.dovetail.com/data/6Ictyc7kKTXwtfgaowLSph#:v:h=zDvD6A5FgCRFWBEYodurB
AIAAIC1179,"AI chatbot Replika makes little effort to protect its users' privacy, according to a research study. According to a May 2023 Mozilla Foundation assessment of mental health apps, Replika is one of the worst apps Mozilla has ever reviewed', and 'a hot mess of privacy and creepiness'. ",Incident - organization-driven - problematic AI implementation,Incident Type,Replika shares user data with advertisers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-replika-fails-to-meet-minimum-privacy-standards,Issue,2017,2023,2023,Global,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Research study/report,Privacy,,,,,,,,,,10/7/2024 0:24,https://best-paper-award-ddck.dovetail.com/data/6Ictyc7kKTXwtfgaowLSph#:v:h=zDvD6A5FgCRFWBEYodurB
AIAAIC1179,"AI chatbot Replika makes little effort to protect its users' privacy, according to a research study. According to a May 2023 Mozilla Foundation assessment of mental health apps, Replika is one of the worst apps Mozilla has ever reviewed', and 'a hot mess of privacy and creepiness'. ",Cause - organization causes - poor business ethics,Cause,Replika shares user data with advertisers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-replika-fails-to-meet-minimum-privacy-standards,Issue,2017,2023,2023,Global,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Research study/report,Privacy,,,,,,,,,,10/7/2024 0:24,https://best-paper-award-ddck.dovetail.com/data/6Ictyc7kKTXwtfgaowLSph#:v:h=zDvD6A5FgCRFWBEYodurB
AIAAIC1105,"Despite the company's terms of service saying it would remove 'content depicting or intended to depict real individuals or minors (under 18) in a mature context,' a 404 Media investigation uncovered a Billie Eilish model that generated nude images of a pregnant Eilish that was 'in place for weeks' before being removed. According to 404 Media, while CivitAI does enforce its policy and remove offending content, non-consensual sexual imagery is still posted to the site 'regularly', some of which stays on the platform 'for months'. The Billie Eilish model, and the user who created the nude images, were allowed to remain on the site, alongside images of the singer clad in lingerie and with very large breasts, both of which are against CivitAI’s terms of service.",Entity - AI developer company,Responsible Entities,CivitAI generates nonconsensual AI pornography,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-nonconsensual-ai-pornography,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Media investigation,Ethics/values; Privacy; Safety,Governance,Dehumanisation/objectification,,,,,,,,10/7/2024 0:59,https://best-paper-award-ddck.dovetail.com/data/6pBwAolbSEH2RW1V8CYG5N#:v:h=BiTR8RTcQTFTM17ACOVjI
AIAAIC1105,"Despite the company's terms of service saying it would remove 'content depicting or intended to depict real individuals or minors (under 18) in a mature context,' a 404 Media investigation uncovered a Billie Eilish model that generated nude images of a pregnant Eilish that was 'in place for weeks' before being removed. According to 404 Media, while CivitAI does enforce its policy and remove offending content, non-consensual sexual imagery is still posted to the site 'regularly', some of which stays on the platform 'for months'. The Billie Eilish model, and the user who created the nude images, were allowed to remain on the site, alongside images of the singer clad in lingerie and with very large breasts, both of which are against CivitAI’s terms of service.",Entity - malicious human,Responsible Entities,CivitAI generates nonconsensual AI pornography,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-nonconsensual-ai-pornography,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Media investigation,Ethics/values; Privacy; Safety,Governance,Dehumanisation/objectification,,,,,,,,10/7/2024 0:59,https://best-paper-award-ddck.dovetail.com/data/6pBwAolbSEH2RW1V8CYG5N#:v:h=BiTR8RTcQTFTM17ACOVjI
AIAAIC0969,"Users were never asked to verify their age, and the choice of videos on which users could attach their faces included scantily clad women in bikinis and a section named 'Hot'. the app has since been removed from the Android and Apple app stores.",Cause - Lack of AI control,Cause,FaceMega sexualised face swap ads violate platform policies,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/facemega-sexualised-face-swapping,Incident,,2023,2023,USA,Media/entertainment/sports/arts,Wondershare/Ufoto,Wondershare/Ufoto,Facemega,Deepfake - video; Machine learning,Swap faces,Media investigation,Safety; Copyright,Governance,Reputational damage; Financial loss,,,,App store removal,,,,10/30/2024 19:29,https://best-paper-award-ddck.dovetail.com/data/1kveiSuTHOwau1j1igocK2#:v:h=BzgBwOQs1fsoPibeuEPV0
AIAAIC1020,"According to local police, the fraudster stole an individual’s WeChat account and used AI to create a deepfake of the person's face.",Entity - malicious human,Responsible Entities,"Chinese scammer uses AI to defraud 'fiend' of USD 622,000",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chinese-scammer-uses-ai-to-defraud-fiend-of-usd-622000,Incident,,2023,2023,China,"Private - individual, family",Tencent/WeChat,,,"Deepfake - video, audio; Machine learning",Defraud,Police investigation,Security,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:32,https://best-paper-award-ddck.dovetail.com/data/1NvLyobBWf5j1dgdXFBr1p#:v:h=Ck5Da0V7K3KG7UrcagkZA
AIAAIC1296,"A group of hackers gained access to AI recruitment chatbot Chattr, revealing sensitive information about job applicants, fast food franchises, and Chattr itself.",Entity - malicious human,Responsible Entities,AI hiring chatbot hack violates applicants' privacy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-hiring-chatbot-hack-violates-applicants-privacy,Incident,,2024,2024,USA,Business/professional services; Food/food services,"Applebees, Arbys, Chick-fil-A, DunkinDonuts, IHOP, KFC, Shoneys, Subway, Tacobell, Target, Wendys",Chattr,Chattr,Chatbot; Machine learning; Neural network; Deep learning; Machine learning; Reinforcement learning,Recruit employees,White-hat hack,Confidentiality; Privacy; Security,Governance,Privacy loss,,,,,,,,10/2/2024 21:12,https://best-paper-award-ddck.dovetail.com/data/5XiFZ25AMksPdlUlJ2Qrrz#:v:h=DKlxcvcYA6P4a71PozS4F
AIAAIC1296,"A group of hackers gained access to AI recruitment chatbot Chattr, revealing sensitive information about job applicants, fast food franchises, and Chattr itself.",Incident - organization-driven - problematic AI implementation,Incident Type,AI hiring chatbot hack violates applicants' privacy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-hiring-chatbot-hack-violates-applicants-privacy,Incident,,2024,2024,USA,Business/professional services; Food/food services,"Applebees, Arbys, Chick-fil-A, DunkinDonuts, IHOP, KFC, Shoneys, Subway, Tacobell, Target, Wendys",Chattr,Chattr,Chatbot; Machine learning; Neural network; Deep learning; Machine learning; Reinforcement learning,Recruit employees,White-hat hack,Confidentiality; Privacy; Security,Governance,Privacy loss,,,,,,,,10/2/2024 21:12,https://best-paper-award-ddck.dovetail.com/data/5XiFZ25AMksPdlUlJ2Qrrz#:v:h=DKlxcvcYA6P4a71PozS4F
AIAAIC1296,"A group of hackers gained access to AI recruitment chatbot Chattr, revealing sensitive information about job applicants, fast food franchises, and Chattr itself.",Incident - AI-driven - AI data breach,Incident Type,AI hiring chatbot hack violates applicants' privacy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-hiring-chatbot-hack-violates-applicants-privacy,Incident,,2024,2024,USA,Business/professional services; Food/food services,"Applebees, Arbys, Chick-fil-A, DunkinDonuts, IHOP, KFC, Shoneys, Subway, Tacobell, Target, Wendys",Chattr,Chattr,Chatbot; Machine learning; Neural network; Deep learning; Machine learning; Reinforcement learning,Recruit employees,White-hat hack,Confidentiality; Privacy; Security,Governance,Privacy loss,,,,,,,,10/2/2024 21:12,https://best-paper-award-ddck.dovetail.com/data/5XiFZ25AMksPdlUlJ2Qrrz#:v:h=DKlxcvcYA6P4a71PozS4F
AIAAIC1296,"A group of hackers gained access to AI recruitment chatbot Chattr, revealing sensitive information about job applicants, fast food franchises, and Chattr itself.",Entity - AI developer company,Responsible Entities,AI hiring chatbot hack violates applicants' privacy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-hiring-chatbot-hack-violates-applicants-privacy,Incident,,2024,2024,USA,Business/professional services; Food/food services,"Applebees, Arbys, Chick-fil-A, DunkinDonuts, IHOP, KFC, Shoneys, Subway, Tacobell, Target, Wendys",Chattr,Chattr,Chatbot; Machine learning; Neural network; Deep learning; Machine learning; Reinforcement learning,Recruit employees,White-hat hack,Confidentiality; Privacy; Security,Governance,Privacy loss,,,,,,,,10/2/2024 21:12,https://best-paper-award-ddck.dovetail.com/data/5XiFZ25AMksPdlUlJ2Qrrz#:v:h=DKlxcvcYA6P4a71PozS4F
AIAAIC1305,"The incident raised questions about PimEyes' multi-purpose nature, the ease with which it can be used to identify and monitor third-parties, and about the quality and effectiveness of its governance. It also led to further calls for the system to be banned.",Entity - AI developer company,Responsible Entities,Film fan uses PimEyes to identify anonymous porn stars,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-used-to-identify-anonymous-porn-stars,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Media investigation,Governance; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 20:40,https://best-paper-award-ddck.dovetail.com/data/3Op3fWrJoLvAWUiBCnquJa#:v:h=DNZKKsMK5dpHO86gILMPz
AIAAIC1189,Canadian law bans the visual representation of someone depicted as being under the age of 18 engaged in explicit sexual activity. The ruling is believed to be the first of its kind in Canada.,Cause - organization causes - legal non-compliance,Cause,Quebec man jailed for producing AI child porn,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/quebec-man-jailed-for-producing-ai-child-porn,Incident,,2023,2023,Canada,Media/entertainment/sports/arts,Steven Larouche,,,"Deepfake - audio, video; Machine learning",Self-gratification,Lawsuit filing/litigation,Safety; Legal,Governance; Marketing,Dignity loss,,,,,,Litigation,,10/28/2024 16:18,https://best-paper-award-ddck.dovetail.com/data/6EbqXh5baeg6xaig7Sd3Dj#:v:h=FkUAp1xpCv5zOiXp2vhsB
AIAAIC1257,The suit also argued that this data collection violated the terms of service of these platforms and privacy laws and constituted unauthorised access to people’s information.,Cause - organization causes - legal non-compliance,Cause,OpenAI 'unprecedented web scraping' trains AI models,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-unprecedented-web-scraping-trains-ai-models,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,,OpenAI,ChatGPT; DALL-E,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text; Generate images,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 21:23,https://best-paper-award-ddck.dovetail.com/data/7xeqrtiiKXcFbniKLZDcBj#:v:h=Glnwd6JrGoa92zOC1MvLu
AIAAIC0994,"a prompt injection to reveal that the bot is provided with data showing where the user is located and the local time. In addition, he found that My AI's instructions state 'Do not mention the user’s current location unless it’s particularly relevant to the dialogue.'  And Insider journalist Jordan Hart persuaded the system to tell him his nearest pharmacy, which it did to within a few hundred yards.",Cause - organization causes - lack of data protection,Cause,Snapchat My AI accesses user location data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-location-access-opacity,Incident,2023,2023,2023,USA; Global,Media/entertainment/sports/arts,David An; Jordan Hart; Snapchat users,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning,"Provide information, communicate",User comments/complaints,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,,,10/11/2024 20:25,https://best-paper-award-ddck.dovetail.com/data/2LKScU9whfqvn0b7WetnZF#:v:h=GZjnWVlXCZlJ29mGqIefy
AIAAIC0994,"a prompt injection to reveal that the bot is provided with data showing where the user is located and the local time. In addition, he found that My AI's instructions state 'Do not mention the user’s current location unless it’s particularly relevant to the dialogue.'  And Insider journalist Jordan Hart persuaded the system to tell him his nearest pharmacy, which it did to within a few hundred yards.",Cause - Human causes - Human abuse of AI tools,Cause,Snapchat My AI accesses user location data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-location-access-opacity,Incident,2023,2023,2023,USA; Global,Media/entertainment/sports/arts,David An; Jordan Hart; Snapchat users,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning,"Provide information, communicate",User comments/complaints,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,,,10/11/2024 20:25,https://best-paper-award-ddck.dovetail.com/data/2LKScU9whfqvn0b7WetnZF#:v:h=GZjnWVlXCZlJ29mGqIefy
AIAAIC0994,"a prompt injection to reveal that the bot is provided with data showing where the user is located and the local time. In addition, he found that My AI's instructions state 'Do not mention the user’s current location unless it’s particularly relevant to the dialogue.'  And Insider journalist Jordan Hart persuaded the system to tell him his nearest pharmacy, which it did to within a few hundred yards.",Entity - malicious human,Responsible Entities,Snapchat My AI accesses user location data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-location-access-opacity,Incident,2023,2023,2023,USA; Global,Media/entertainment/sports/arts,David An; Jordan Hart; Snapchat users,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning,"Provide information, communicate",User comments/complaints,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,,,10/11/2024 20:25,https://best-paper-award-ddck.dovetail.com/data/2LKScU9whfqvn0b7WetnZF#:v:h=GZjnWVlXCZlJ29mGqIefy
AIAAIC0994,"a prompt injection to reveal that the bot is provided with data showing where the user is located and the local time. In addition, he found that My AI's instructions state 'Do not mention the user’s current location unless it’s particularly relevant to the dialogue.'  And Insider journalist Jordan Hart persuaded the system to tell him his nearest pharmacy, which it did to within a few hundred yards.",Incident - human-driven - bypassing AI safeguards,Incident Type,Snapchat My AI accesses user location data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-location-access-opacity,Incident,2023,2023,2023,USA; Global,Media/entertainment/sports/arts,David An; Jordan Hart; Snapchat users,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning,"Provide information, communicate",User comments/complaints,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,,,10/11/2024 20:25,https://best-paper-award-ddck.dovetail.com/data/2LKScU9whfqvn0b7WetnZF#:v:h=GZjnWVlXCZlJ29mGqIefy
AIAAIC1196,"According to Olejnik, OpenAI had said it was unable to correct incorrect personal data about him, and had failed to respond properly to his subject access request, giving 'evasive, misleading and internally contradictory' answers when he had sought to exercise his legal rights to data access.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Poland investigates ChatGPT for alleged privacy abuse,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/poland-investigates-chatgpt-alleged-privacy-abuse,Incident,2022,2023,2023,Poland,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance; Privacy,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:15,https://best-paper-award-ddck.dovetail.com/data/6MIgBLj98nrsZHmvhkHkHV#:v:h=IxhDi9EeS6RB2OmMVHDxg
AIAAIC1683,"US supermarket chain Kroger prompted alarm for adjusting the prices of its products in real-time using artificial intelligence. Kroger's dynamic pricing system enables real-time price adjustments based on factors such as demand andcustomer data. The company introduced electronic shelf labels (ESLs) with ""Kroger Edge"" technology in 2018,expanding the initiative to 500 stores across the US by 2023. Kroger now plans to install cameras at digital displays that use facial recognition to determine customers' genderand age, presenting personalised offers based on this information, claiming it will enhance customer experience.",Cause - no specific info,Cause,Kroger under fire for AI-powered dynamic pricing,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kroger-under-fire-for-ai-powered-dynamic-pricing,Issue,,2024,2024,USA,Retail,Kroger,IntelligenceNode; Kroger; Microsoft,EDGE,Computer vision; Facial recognition; Machine learning; Pricing algorithm,Set prices,Legislator enquiry/complaint,Fairness; Privacy,,Financial loss,,,Reputational damage,,,,,9/26/2024 23:03,https://best-paper-award-ddck.dovetail.com/data/2LivY6szgeR6eALTsM8zmg#:v:h=IHc23QOFhJdw41fB5BGu9
AIAAIC1683,"US supermarket chain Kroger prompted alarm for adjusting the prices of its products in real-time using artificial intelligence. Kroger's dynamic pricing system enables real-time price adjustments based on factors such as demand andcustomer data. The company introduced electronic shelf labels (ESLs) with ""Kroger Edge"" technology in 2018,expanding the initiative to 500 stores across the US by 2023. Kroger now plans to install cameras at digital displays that use facial recognition to determine customers' genderand age, presenting personalised offers based on this information, claiming it will enhance customer experience.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Kroger under fire for AI-powered dynamic pricing,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kroger-under-fire-for-ai-powered-dynamic-pricing,Issue,,2024,2024,USA,Retail,Kroger,IntelligenceNode; Kroger; Microsoft,EDGE,Computer vision; Facial recognition; Machine learning; Pricing algorithm,Set prices,Legislator enquiry/complaint,Fairness; Privacy,,Financial loss,,,Reputational damage,,,,,9/26/2024 23:03,https://best-paper-award-ddck.dovetail.com/data/2LivY6szgeR6eALTsM8zmg#:v:h=IHc23QOFhJdw41fB5BGu9
AIAAIC1683,"US supermarket chain Kroger prompted alarm for adjusting the prices of its products in real-time using artificial intelligence. Kroger's dynamic pricing system enables real-time price adjustments based on factors such as demand andcustomer data. The company introduced electronic shelf labels (ESLs) with ""Kroger Edge"" technology in 2018,expanding the initiative to 500 stores across the US by 2023. Kroger now plans to install cameras at digital displays that use facial recognition to determine customers' genderand age, presenting personalised offers based on this information, claiming it will enhance customer experience.",Incident - organization-driven - problematic AI implementation,Incident Type,Kroger under fire for AI-powered dynamic pricing,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kroger-under-fire-for-ai-powered-dynamic-pricing,Issue,,2024,2024,USA,Retail,Kroger,IntelligenceNode; Kroger; Microsoft,EDGE,Computer vision; Facial recognition; Machine learning; Pricing algorithm,Set prices,Legislator enquiry/complaint,Fairness; Privacy,,Financial loss,,,Reputational damage,,,,,9/26/2024 23:03,https://best-paper-award-ddck.dovetail.com/data/2LivY6szgeR6eALTsM8zmg#:v:h=IHc23QOFhJdw41fB5BGu9
AIAAIC1522,"An update to Adobe's terms of service generated significant controversy amongst its users, primarily due to concerns about privacy and copyright. The update, which required users to accept to continue using Adobe's software, included provisions allowing Adobe to access and use their content for various purposes, including improving its services and products through automated and manual methods. Users argued that the terms are too broad and vague, and feared that this could allow Adobe access to sensitive projects, potentially violating confidentiality agreements and user privacy, while allowing Adobe to use their work to train its AI models, notably Adobe Firefly.  Adobe later clarified that it does not train its AI on customer content and only uses licensed or public domain content for this purpose. The fracas reflected concerns about the use of customer content and data to train Adobe's AI models. It also highlighted widespread distrust in technology companies in general.",Entity - AI developer company,Responsible Entities,"Adobe terms of use update sparks AI privacy, copyright controversy",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/adobe-terms-of-use-update-sparks-privacy-copyright-controversy,Issue,2023,2024,2024,Global,Media/entertainment/sports/arts,Adobe users,Adobe,Adobe Firefly,Text-to-image,Generate images,User comments/complaints,Confidentiality; Copyright; Privacy ,,Confidentality loss; Copyright loss; Privacy loss,,,,,,,,9/27/2024 0:14,https://best-paper-award-ddck.dovetail.com/data/50BVwpxjFxKKLQoy6WEn34#:v:h=J1glYk7fmmtXsoJYQDztp
AIAAIC1522,"An update to Adobe's terms of service generated significant controversy amongst its users, primarily due to concerns about privacy and copyright. The update, which required users to accept to continue using Adobe's software, included provisions allowing Adobe to access and use their content for various purposes, including improving its services and products through automated and manual methods. Users argued that the terms are too broad and vague, and feared that this could allow Adobe access to sensitive projects, potentially violating confidentiality agreements and user privacy, while allowing Adobe to use their work to train its AI models, notably Adobe Firefly.  Adobe later clarified that it does not train its AI on customer content and only uses licensed or public domain content for this purpose. The fracas reflected concerns about the use of customer content and data to train Adobe's AI models. It also highlighted widespread distrust in technology companies in general.",Incident - organization-driven - unclear info on user agreements and policy statements,Incident Type,"Adobe terms of use update sparks AI privacy, copyright controversy",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/adobe-terms-of-use-update-sparks-privacy-copyright-controversy,Issue,2023,2024,2024,Global,Media/entertainment/sports/arts,Adobe users,Adobe,Adobe Firefly,Text-to-image,Generate images,User comments/complaints,Confidentiality; Copyright; Privacy ,,Confidentality loss; Copyright loss; Privacy loss,,,,,,,,9/27/2024 0:14,https://best-paper-award-ddck.dovetail.com/data/50BVwpxjFxKKLQoy6WEn34#:v:h=J1glYk7fmmtXsoJYQDztp
AIAAIC1522,"An update to Adobe's terms of service generated significant controversy amongst its users, primarily due to concerns about privacy and copyright. The update, which required users to accept to continue using Adobe's software, included provisions allowing Adobe to access and use their content for various purposes, including improving its services and products through automated and manual methods. Users argued that the terms are too broad and vague, and feared that this could allow Adobe access to sensitive projects, potentially violating confidentiality agreements and user privacy, while allowing Adobe to use their work to train its AI models, notably Adobe Firefly.  Adobe later clarified that it does not train its AI on customer content and only uses licensed or public domain content for this purpose. The fracas reflected concerns about the use of customer content and data to train Adobe's AI models. It also highlighted widespread distrust in technology companies in general.",Cause - organziation causes - vague policy information,Cause,"Adobe terms of use update sparks AI privacy, copyright controversy",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/adobe-terms-of-use-update-sparks-privacy-copyright-controversy,Issue,2023,2024,2024,Global,Media/entertainment/sports/arts,Adobe users,Adobe,Adobe Firefly,Text-to-image,Generate images,User comments/complaints,Confidentiality; Copyright; Privacy ,,Confidentality loss; Copyright loss; Privacy loss,,,,,,,,9/27/2024 0:14,https://best-paper-award-ddck.dovetail.com/data/50BVwpxjFxKKLQoy6WEn34#:v:h=J1glYk7fmmtXsoJYQDztp
AIAAIC1303,They also argued the company had failed to explain its data management policies.,Cause - organziation causes - vague policy information,Cause,"PimEyes sued in Illinois, USA, for privacy violations",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-sued-in-illinois-usa-for-privacy-violations,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Lawsuit filing/litigation,Governance; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 20:43,https://best-paper-award-ddck.dovetail.com/data/2kP3ZgJskd8oyopMz2hnhm#:v:h=JhY2KxJN6oGHjcTWrheqt
AIAAIC1425,"An AI-altered TikTok video purportedly falsely showed Anies Baswedan, an Indonesian presidential candidate, speaking Arabic at a rally. Despite Baswedan's team clarifying he only has a basic grasp of Arabic, the video falsely portrayed him as fluent. Analysis by AFP confirmed the video had been automatically translated. The 18-second fake clip highlighted Baswedan advocating for the Nasdem Party, which had endorsed his presidential bid, and garnered over 2.6 million views. This incident led to the widespread belief amongst viewers regarding Baswedan’s linguistic prowess. ",Cause - no specific info,Cause,Al video depicts Indonesian presidential hopeful speaking fluent Arabic,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/al-video-depicts-indonesian-presidential-hopeful-speaking-arabic,Incident,,2023,2023,Indonesia,Politics,,HeyGen,HeyGen,"Deepfake - audio, video; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning",Manipulate public opinion,Media investigation,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:26,https://best-paper-award-ddck.dovetail.com/data/15rhUv443ilI5bzGrn1IRF#:v:h=K49IalS879G5A0vDM0OFO
AIAAIC1425,"An AI-altered TikTok video purportedly falsely showed Anies Baswedan, an Indonesian presidential candidate, speaking Arabic at a rally. Despite Baswedan's team clarifying he only has a basic grasp of Arabic, the video falsely portrayed him as fluent. Analysis by AFP confirmed the video had been automatically translated. The 18-second fake clip highlighted Baswedan advocating for the Nasdem Party, which had endorsed his presidential bid, and garnered over 2.6 million views. This incident led to the widespread belief amongst viewers regarding Baswedan’s linguistic prowess. ",Entity - no specific info,Responsible Entities,Al video depicts Indonesian presidential hopeful speaking fluent Arabic,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/al-video-depicts-indonesian-presidential-hopeful-speaking-arabic,Incident,,2023,2023,Indonesia,Politics,,HeyGen,HeyGen,"Deepfake - audio, video; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning",Manipulate public opinion,Media investigation,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:26,https://best-paper-award-ddck.dovetail.com/data/15rhUv443ilI5bzGrn1IRF#:v:h=K49IalS879G5A0vDM0OFO
AIAAIC1425,"An AI-altered TikTok video purportedly falsely showed Anies Baswedan, an Indonesian presidential candidate, speaking Arabic at a rally. Despite Baswedan's team clarifying he only has a basic grasp of Arabic, the video falsely portrayed him as fluent. Analysis by AFP confirmed the video had been automatically translated. The 18-second fake clip highlighted Baswedan advocating for the Nasdem Party, which had endorsed his presidential bid, and garnered over 2.6 million views. This incident led to the widespread belief amongst viewers regarding Baswedan’s linguistic prowess. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Al video depicts Indonesian presidential hopeful speaking fluent Arabic,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/al-video-depicts-indonesian-presidential-hopeful-speaking-arabic,Incident,,2023,2023,Indonesia,Politics,,HeyGen,HeyGen,"Deepfake - audio, video; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning",Manipulate public opinion,Media investigation,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:26,https://best-paper-award-ddck.dovetail.com/data/15rhUv443ilI5bzGrn1IRF#:v:h=K49IalS879G5A0vDM0OFO
AIAAIC1459,"Despite possible road safety benefits, motorists believe an AI speed camera system being rolled out across the UK constitutes an 'invasion of privacy'.  10 police forces across the UK are testing the system, which is installed in vans and can detect whether road users are using their phones behind the wheel or travelling without a seatbelt. Data and images is sent to police officers who decide whether or not to take action.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Intrusive' AI speed cameras criticised by UK motorists,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/intrusive-ai-speed-cameras-criticised-by-uk-motorists,Issue,,2024,2024,UK,Govt - transport; Govt - police,AECOM; National Highways,Acusensus,,Computer vision; Object recognition,Detect driver violations,User comments/complaints,Privacy,,,Privacy loss,,,,,,,10/2/2024 13:20,https://best-paper-award-ddck.dovetail.com/data/42PuzCKeaArTbYmaw9ORkc#:v:h=LKVIInwfiNI1Qz7Igpa0b
AIAAIC1459,"Despite possible road safety benefits, motorists believe an AI speed camera system being rolled out across the UK constitutes an 'invasion of privacy'.  10 police forces across the UK are testing the system, which is installed in vans and can detect whether road users are using their phones behind the wheel or travelling without a seatbelt. Data and images is sent to police officers who decide whether or not to take action.",Cause - Human causes - Undertrusting AI,Cause,Intrusive' AI speed cameras criticised by UK motorists,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/intrusive-ai-speed-cameras-criticised-by-uk-motorists,Issue,,2024,2024,UK,Govt - transport; Govt - police,AECOM; National Highways,Acusensus,,Computer vision; Object recognition,Detect driver violations,User comments/complaints,Privacy,,,Privacy loss,,,,,,,10/2/2024 13:20,https://best-paper-award-ddck.dovetail.com/data/42PuzCKeaArTbYmaw9ORkc#:v:h=LKVIInwfiNI1Qz7Igpa0b
AIAAIC1459,"Despite possible road safety benefits, motorists believe an AI speed camera system being rolled out across the UK constitutes an 'invasion of privacy'.  10 police forces across the UK are testing the system, which is installed in vans and can detect whether road users are using their phones behind the wheel or travelling without a seatbelt. Data and images is sent to police officers who decide whether or not to take action.",Entity - government authorities that adopt AI,Responsible Entities,Intrusive' AI speed cameras criticised by UK motorists,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/intrusive-ai-speed-cameras-criticised-by-uk-motorists,Issue,,2024,2024,UK,Govt - transport; Govt - police,AECOM; National Highways,Acusensus,,Computer vision; Object recognition,Detect driver violations,User comments/complaints,Privacy,,,Privacy loss,,,,,,,10/2/2024 13:20,https://best-paper-award-ddck.dovetail.com/data/42PuzCKeaArTbYmaw9ORkc#:v:h=LKVIInwfiNI1Qz7Igpa0b
AIAAIC1151,"Audio recordings appearing to show Omar al-Bashir, the former leader of Sudan, criticising the head of the Sudanese army have been identified as having been manipulated using artificial intelligence. The recordings were initially posted to political channel The Voice of Sudan, before garnering hundreds of thousands of views on TikTok. BBC analysts identified several of the recordings as matching broadcasts aired days earlier by popular Sudanese political commentator, Al Insirafi. The evidence suggested that AI-powered voice conversion software was used to mimic Bashir speaking.  While the purpose of the campaign remains unclear, The Voice of Sudan denied misleading the public and said it was not affiliated with any political or military groups. TikTok has since taken down the account on the basis that it broke its guidelines on posting 'false content that may cause significant harm', and its rules on the use of synthetic media.",Incident - organization-driven - problematic AI implementation,Incident Type,Audio AIs impersonate former South Sudan leader Omar al-Bashir,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-campaign-impersonates-former-south-sudan-leader-omar-al-bashir,Incident,,2023,2023,Sudan,Politics,,,,Deepfake - audio; Machine learning,Damage reputation,,"Governance, Mis/disinformation",Governance,,,,,,,,,10/29/2024 23:11,https://best-paper-award-ddck.dovetail.com/data/2VXX5W5ETJxTFHzwExTnDW#:v:h=MjhwpdJR80ZHegqNa1rgp
AIAAIC1151,"Audio recordings appearing to show Omar al-Bashir, the former leader of Sudan, criticising the head of the Sudanese army have been identified as having been manipulated using artificial intelligence. The recordings were initially posted to political channel The Voice of Sudan, before garnering hundreds of thousands of views on TikTok. BBC analysts identified several of the recordings as matching broadcasts aired days earlier by popular Sudanese political commentator, Al Insirafi. The evidence suggested that AI-powered voice conversion software was used to mimic Bashir speaking.  While the purpose of the campaign remains unclear, The Voice of Sudan denied misleading the public and said it was not affiliated with any political or military groups. TikTok has since taken down the account on the basis that it broke its guidelines on posting 'false content that may cause significant harm', and its rules on the use of synthetic media.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Audio AIs impersonate former South Sudan leader Omar al-Bashir,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-campaign-impersonates-former-south-sudan-leader-omar-al-bashir,Incident,,2023,2023,Sudan,Politics,,,,Deepfake - audio; Machine learning,Damage reputation,,"Governance, Mis/disinformation",Governance,,,,,,,,,10/29/2024 23:11,https://best-paper-award-ddck.dovetail.com/data/2VXX5W5ETJxTFHzwExTnDW#:v:h=MjhwpdJR80ZHegqNa1rgp
AIAAIC1716,"Several high-profile universities decided to disable Turnitin's AI writing detection tool due to concerns about its accuracy and potential for falsely accusing students of academic dishonesty. Even with Turnitin's claimed 1 percent false positive rate, large universities were concerned that they may see hundreds of papers incorrectly flagged as AI-generated. Some universities were wary of sharing student data with third-party AI detection services, including Turnitin. Major institutions that disabled Turnitin's AI detector include Vanderbilt University, Michigan State University, Northwestern University and the University of Texas at Austin.",Entity - AI algorithm,Responsible Entities,"Universities disable Turnitin AI detection ""in the best interests of students""",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/universities-disable-turnitin-ai-detection-in-students-best-interests,Issue,2023,2023,2023,USA,Education,Turnitin,Turnitin,AI writing detector,NLP/text analysis; Neural network; Deep learning; Machine learning,Detect AI writing,Media investigation,Accuracy/reliability; Effectiveness/value; Privacy,Governance; Black box,,,,,,,,,9/26/2024 21:04,https://best-paper-award-ddck.dovetail.com/data/4s2vn0VGlBHwnbzjsVOhDc#:v:h=NzEi1Dfsqqeu7IaWRMxNu
AIAAIC1716,"Several high-profile universities decided to disable Turnitin's AI writing detection tool due to concerns about its accuracy and potential for falsely accusing students of academic dishonesty. Even with Turnitin's claimed 1 percent false positive rate, large universities were concerned that they may see hundreds of papers incorrectly flagged as AI-generated. Some universities were wary of sharing student data with third-party AI detection services, including Turnitin. Major institutions that disabled Turnitin's AI detector include Vanderbilt University, Michigan State University, Northwestern University and the University of Texas at Austin.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,"Universities disable Turnitin AI detection ""in the best interests of students""",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/universities-disable-turnitin-ai-detection-in-students-best-interests,Issue,2023,2023,2023,USA,Education,Turnitin,Turnitin,AI writing detector,NLP/text analysis; Neural network; Deep learning; Machine learning,Detect AI writing,Media investigation,Accuracy/reliability; Effectiveness/value; Privacy,Governance; Black box,,,,,,,,,9/26/2024 21:04,https://best-paper-award-ddck.dovetail.com/data/4s2vn0VGlBHwnbzjsVOhDc#:v:h=NzEi1Dfsqqeu7IaWRMxNu
AIAAIC1716,"Several high-profile universities decided to disable Turnitin's AI writing detection tool due to concerns about its accuracy and potential for falsely accusing students of academic dishonesty. Even with Turnitin's claimed 1 percent false positive rate, large universities were concerned that they may see hundreds of papers incorrectly flagged as AI-generated. Some universities were wary of sharing student data with third-party AI detection services, including Turnitin. Major institutions that disabled Turnitin's AI detector include Vanderbilt University, Michigan State University, Northwestern University and the University of Texas at Austin.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,"Universities disable Turnitin AI detection ""in the best interests of students""",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/universities-disable-turnitin-ai-detection-in-students-best-interests,Issue,2023,2023,2023,USA,Education,Turnitin,Turnitin,AI writing detector,NLP/text analysis; Neural network; Deep learning; Machine learning,Detect AI writing,Media investigation,Accuracy/reliability; Effectiveness/value; Privacy,Governance; Black box,,,,,,,,,9/26/2024 21:04,https://best-paper-award-ddck.dovetail.com/data/4s2vn0VGlBHwnbzjsVOhDc#:v:h=NzEi1Dfsqqeu7IaWRMxNu
AIAAIC1239,"Amazon's Q generative AI service suffers from inaccuracy, privacy, and security issues, according to company internal documents. ",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,"Amazon Q hallucinates, leaks data",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-q-hallucinates-leaks-data,Issue,2023,2023,2023,USA,Business/professional services,Casey Newton; Zoe Schiffler,Amazon,Amazon Q,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Media investigation,Accuracy/reliability; Confidentiality; Privacy,Governance,,Confidentiality loss,,,,,,,10/6/2024 23:42,https://best-paper-award-ddck.dovetail.com/data/6qdPVS8qLWNLyJwXajPT1d#:v:h=RIh4hKP7N5loNJULLiVOt
AIAAIC0959,Tesla made changes to its vehicle security cameras after an Autoriteit Persoonsgegevens (Dutch Data Protection Authority) investigation into whether the car maker had violated the privacy of people coming close to its cars.,Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Tesla safety cameras capture neighbourhood movements,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/tesla-safety-cameras-capture-neighbourhood-movements,Incident,2019,2023,2023,Netherlands,Automotive,Tesla,Tesla,Sentry Mode,,Strengthen security,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,System update,,,,10/13/2024 22:27,https://best-paper-award-ddck.dovetail.com/data/19MCJAfQZTeVc663cf6cGX#:v:h=S90mxlGyscZF1dwmbzaHn
AIAAIC0959,Tesla made changes to its vehicle security cameras after an Autoriteit Persoonsgegevens (Dutch Data Protection Authority) investigation into whether the car maker had violated the privacy of people coming close to its cars.,Entity - no specific info,Responsible Entities,Tesla safety cameras capture neighbourhood movements,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/tesla-safety-cameras-capture-neighbourhood-movements,Incident,2019,2023,2023,Netherlands,Automotive,Tesla,Tesla,Sentry Mode,,Strengthen security,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,System update,,,,10/13/2024 22:27,https://best-paper-award-ddck.dovetail.com/data/19MCJAfQZTeVc663cf6cGX#:v:h=S90mxlGyscZF1dwmbzaHn
AIAAIC1164,r its apparent lack of consent from Swift ,Cause - organization/human cause - lack of informed consent & transparency,Cause,Taylor Swift speaks in Mandarin deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/taylor-swift-speaks-in-mandarin-deepfake,Incident,,2023,2023,China; USA,Media/entertainment/sports/arts,,HeyGen,Video Translate,"Deepfake - audio, video; Machine learning",Promote developer,User comments/complaints,Mis/disinformation; Privacy,,Manipulation,,,,,,,,10/24/2024 21:25,https://best-paper-award-ddck.dovetail.com/data/7oLXMZ0AGOivl1qXp4MMxA#:v:h=SV75t1kFYYGAqvf98m662
AIAAIC1121,"Google Search started showing user conversations with its Bard chatbot in its search results, raising concerns about loss of privacy and confidentiality and the nature and effectiveness of Google's security. First discovered by SEO consultant Gagan Ghotra, the results appearing in Google's search engine were limited to conversations users had chosen to share with others, and did not include their usernames. However, it also transpired that some Bard conversations were ranked as Featured Snippets in Google Search in order to answer common search queries. Google later said it did not intend for Bard shared chats to be indexed by Google Search, and that it was working on blocking them from being indexed.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Google Search indexes Bard personal chats,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-search-indexes-bard-personal-chats,Incident,2023,2023,2023,USA,Technology,Google,Google,Bard/Gemini; Google Search,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,User comments/complaints,Privacy,Governance,Privacy loss,,,,System update,,,,10/7/2024 0:49,https://best-paper-award-ddck.dovetail.com/data/68LLBEHwY7kTfWCePxl8Nt#:v:h=TLEZPg5sgOEMVMLuTAExO
AIAAIC1121,"Google Search started showing user conversations with its Bard chatbot in its search results, raising concerns about loss of privacy and confidentiality and the nature and effectiveness of Google's security. First discovered by SEO consultant Gagan Ghotra, the results appearing in Google's search engine were limited to conversations users had chosen to share with others, and did not include their usernames. However, it also transpired that some Bard conversations were ranked as Featured Snippets in Google Search in order to answer common search queries. Google later said it did not intend for Bard shared chats to be indexed by Google Search, and that it was working on blocking them from being indexed.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Google Search indexes Bard personal chats,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-search-indexes-bard-personal-chats,Incident,2023,2023,2023,USA,Technology,Google,Google,Bard/Gemini; Google Search,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,User comments/complaints,Privacy,Governance,Privacy loss,,,,System update,,,,10/7/2024 0:49,https://best-paper-award-ddck.dovetail.com/data/68LLBEHwY7kTfWCePxl8Nt#:v:h=TLEZPg5sgOEMVMLuTAExO
AIAAIC1121,"Google Search started showing user conversations with its Bard chatbot in its search results, raising concerns about loss of privacy and confidentiality and the nature and effectiveness of Google's security. First discovered by SEO consultant Gagan Ghotra, the results appearing in Google's search engine were limited to conversations users had chosen to share with others, and did not include their usernames. However, it also transpired that some Bard conversations were ranked as Featured Snippets in Google Search in order to answer common search queries. Google later said it did not intend for Bard shared chats to be indexed by Google Search, and that it was working on blocking them from being indexed.",Entity - AI algorithm,Responsible Entities,Google Search indexes Bard personal chats,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-search-indexes-bard-personal-chats,Incident,2023,2023,2023,USA,Technology,Google,Google,Bard/Gemini; Google Search,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,User comments/complaints,Privacy,Governance,Privacy loss,,,,System update,,,,10/7/2024 0:49,https://best-paper-award-ddck.dovetail.com/data/68LLBEHwY7kTfWCePxl8Nt#:v:h=TLEZPg5sgOEMVMLuTAExO
AIAAIC1025,"The regulator also said in its ruling that that Plastic Forte should have conducted an impact assessment setting out the 'necessity and proportionality' of the system, and that it had failed to disclose the existence of the system and how data was managed to its workers.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Plastic Forte employee facial recognition monitoring,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/plastic-forte-employee-facial-recognition-monitoring,Incident,,2023,2023,Spain,Manufacturing/engineering,Albero Forte Composite (Plastic Forte),,,Facial recognition,Improve productivity,Regulatory ruling,Privacy; Necessity/proportionality,Governance; Privacy; Marketing,,,,,,"EUR 12,000 fine",Regulatory investigation,,10/11/2024 20:07,https://best-paper-award-ddck.dovetail.com/data/2YeP3iocQDgZqOPgVqtW74#:v:h=TPpNwzSWJF2NSSxHfSnE9
AIAAIC1025,"The regulator also said in its ruling that that Plastic Forte should have conducted an impact assessment setting out the 'necessity and proportionality' of the system, and that it had failed to disclose the existence of the system and how data was managed to its workers.",Cause - organization causes - lack of AI fail-safe measures,Cause,Plastic Forte employee facial recognition monitoring,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/plastic-forte-employee-facial-recognition-monitoring,Incident,,2023,2023,Spain,Manufacturing/engineering,Albero Forte Composite (Plastic Forte),,,Facial recognition,Improve productivity,Regulatory ruling,Privacy; Necessity/proportionality,Governance; Privacy; Marketing,,,,,,"EUR 12,000 fine",Regulatory investigation,,10/11/2024 20:07,https://best-paper-award-ddck.dovetail.com/data/2YeP3iocQDgZqOPgVqtW74#:v:h=TPpNwzSWJF2NSSxHfSnE9
AIAAIC1025,"The regulator also said in its ruling that that Plastic Forte should have conducted an impact assessment setting out the 'necessity and proportionality' of the system, and that it had failed to disclose the existence of the system and how data was managed to its workers.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Plastic Forte employee facial recognition monitoring,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/plastic-forte-employee-facial-recognition-monitoring,Incident,,2023,2023,Spain,Manufacturing/engineering,Albero Forte Composite (Plastic Forte),,,Facial recognition,Improve productivity,Regulatory ruling,Privacy; Necessity/proportionality,Governance; Privacy; Marketing,,,,,,"EUR 12,000 fine",Regulatory investigation,,10/11/2024 20:07,https://best-paper-award-ddck.dovetail.com/data/2YeP3iocQDgZqOPgVqtW74#:v:h=TPpNwzSWJF2NSSxHfSnE9
AIAAIC1415,Italy's data protection regulator announced it has launched an investigation into OpenAI's video generation tool Sora.,Entity - AI developer company,Responsible Entities,Italian privacy watchdog opens investigation into Sora,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/italian-privacy-watchdog-opens-investigation-into-sora,Issue,,2024,2024,Italy,Media/entertainment/sports/arts,OpenAI,OpenAI,Sora,Text-to-video,Generate video,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 15:08,https://best-paper-award-ddck.dovetail.com/data/4PmxyCy3JxbQ7JYazWWW70#:v:h=Vak4pCb9WDOYEYpofazLT
AIAAIC1222,"OpenAI and Microsoft were sued by a product engineer and software engineer of illegally feeding their AI models with their personal information and professional expertise.  The two anonymous plaintiffs claimed (pdf) that OpenAI used their personal information scraped from the internet to train its generative AI systems, including ChatGPT. They also accused OpenAI of stealing their 'skills and expertise' in order to make products that could 'someday result in [their] professional obsolescence.'",Entity - AI developer company's affiliated parterns,Responsible Entities,"Software engineers sue OpenAI, Microsoft for violating personal privacy",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/software-engineers-sue-openai-microsoft-for-violating-personal-privacy,Incident,2022,2023,2023,USA,Technology,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy; Employment,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:55,https://best-paper-award-ddck.dovetail.com/data/5c29dtmiSFiXntYPX48ckg#:v:h=VTGDtU4DZrYh1j5lNgcfO
AIAAIC1222,"OpenAI and Microsoft were sued by a product engineer and software engineer of illegally feeding their AI models with their personal information and professional expertise.  The two anonymous plaintiffs claimed (pdf) that OpenAI used their personal information scraped from the internet to train its generative AI systems, including ChatGPT. They also accused OpenAI of stealing their 'skills and expertise' in order to make products that could 'someday result in [their] professional obsolescence.'",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,"Software engineers sue OpenAI, Microsoft for violating personal privacy",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/software-engineers-sue-openai-microsoft-for-violating-personal-privacy,Incident,2022,2023,2023,USA,Technology,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy; Employment,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:55,https://best-paper-award-ddck.dovetail.com/data/5c29dtmiSFiXntYPX48ckg#:v:h=VTGDtU4DZrYh1j5lNgcfO
AIAAIC1222,"OpenAI and Microsoft were sued by a product engineer and software engineer of illegally feeding their AI models with their personal information and professional expertise.  The two anonymous plaintiffs claimed (pdf) that OpenAI used their personal information scraped from the internet to train its generative AI systems, including ChatGPT. They also accused OpenAI of stealing their 'skills and expertise' in order to make products that could 'someday result in [their] professional obsolescence.'",Entity - AI developer company,Responsible Entities,"Software engineers sue OpenAI, Microsoft for violating personal privacy",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/software-engineers-sue-openai-microsoft-for-violating-personal-privacy,Incident,2022,2023,2023,USA,Technology,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy; Employment,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:55,https://best-paper-award-ddck.dovetail.com/data/5c29dtmiSFiXntYPX48ckg#:v:h=VTGDtU4DZrYh1j5lNgcfO
AIAAIC1222,"OpenAI and Microsoft were sued by a product engineer and software engineer of illegally feeding their AI models with their personal information and professional expertise.  The two anonymous plaintiffs claimed (pdf) that OpenAI used their personal information scraped from the internet to train its generative AI systems, including ChatGPT. They also accused OpenAI of stealing their 'skills and expertise' in order to make products that could 'someday result in [their] professional obsolescence.'",Cause - organization/human cause - lack of informed consent & transparency,Cause,"Software engineers sue OpenAI, Microsoft for violating personal privacy",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/software-engineers-sue-openai-microsoft-for-violating-personal-privacy,Incident,2022,2023,2023,USA,Technology,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy; Employment,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:55,https://best-paper-award-ddck.dovetail.com/data/5c29dtmiSFiXntYPX48ckg#:v:h=VTGDtU4DZrYh1j5lNgcfO
"AIAAIC1768
","A child protection worker used ChatGPT to draft a critical report for a custody case, inadvertently disclosing sensitive information that could have endangered a child's safety. What happened The incident, which was reported to the Victorian Office of the Information Commissioner (OVIC) in December 2023, revealed that the worker included personal details about the child and their family, which ChatGPT mishandled by downplaying risks associated with the child's living situation with parents charged with sexual offenses.",Entity - government authorities that adopt AI,Responsible Entities,Inaccuracies reveal child protection worker used ChatGPT to draft court report,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/inaccuracies-reveal-child-protection-worker-used-chatgpt-to-draft-report,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 10:53,https://best-paper-award-ddck.dovetail.com/data/548I1sYhv6Ia6AIEDOi9qI#:v:h=Wp51XYtnQUIWHIt2kBTRb
"AIAAIC1768
","A child protection worker used ChatGPT to draft a critical report for a custody case, inadvertently disclosing sensitive information that could have endangered a child's safety. What happened The incident, which was reported to the Victorian Office of the Information Commissioner (OVIC) in December 2023, revealed that the worker included personal details about the child and their family, which ChatGPT mishandled by downplaying risks associated with the child's living situation with parents charged with sexual offenses.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Inaccuracies reveal child protection worker used ChatGPT to draft court report,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/inaccuracies-reveal-child-protection-worker-used-chatgpt-to-draft-report,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 10:53,https://best-paper-award-ddck.dovetail.com/data/548I1sYhv6Ia6AIEDOi9qI#:v:h=Wp51XYtnQUIWHIt2kBTRb
"AIAAIC1768
","A child protection worker used ChatGPT to draft a critical report for a custody case, inadvertently disclosing sensitive information that could have endangered a child's safety. What happened The incident, which was reported to the Victorian Office of the Information Commissioner (OVIC) in December 2023, revealed that the worker included personal details about the child and their family, which ChatGPT mishandled by downplaying risks associated with the child's living situation with parents charged with sexual offenses.",Cause - human causes - Overtrusting AI,Cause,Inaccuracies reveal child protection worker used ChatGPT to draft court report,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/inaccuracies-reveal-child-protection-worker-used-chatgpt-to-draft-report,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 10:53,https://best-paper-award-ddck.dovetail.com/data/548I1sYhv6Ia6AIEDOi9qI#:v:h=Wp51XYtnQUIWHIt2kBTRb
AIAAIC1684,"Civil liberties groups, including the American Civil Liberties Union (ACLU), spoke out against the plan, arguing that it is an invasion of privacy and a threat to the rights of migrantchildren. The plan has also been criticised by lawmakers and human rights organisations. The DHS defended the plan, arguing that it is necessary to improve border security and prevent human trafficking.However, the controversy surrounding the plan highlighted the need for greater transparency and oversight in the use of facial recognition, particularly when it involvesvulnerable populations such as migrant children.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,US plan to train AI system by scanning migrants' kids faces prompts controversy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/us-plans-to-train-ai-system-by-scanning-migrants-kids-faces,Issue,,2024,2024,USA,Govt - immigration,Department of Homeland Security (DHS),,,Facial recognition,Train AI systems,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 22:59,https://best-paper-award-ddck.dovetail.com/data/52nVgSbgvAMYokd9QLPhBw#:v:h=10E46zbdfI0BGCAZSn7Pw2
AIAAIC1426,"However, the accuracy of the system has proved (pdf) low, with 10-15 pecent accuracy for lived-in cars and 70-75 percent for RVs.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,"San Jose homeless detection AI sparks privacy, inequality fears",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-jose-homeless-detection-ai-sparks-privacy-inequality-fears,Issue,2023,2024,2024,USA,Govt - municipal,City of San Jose,SenSen AI; Zyrex,SenDISA,Computer vision; Machine learning; Object recognition,Detect homeless encampments,Media investigation,Accuracy/reliability; Human/civil rights; Privacy,Governance; Marketing,Privacy loss,Societal inequality,,,,,,,10/2/2024 15:02,https://best-paper-award-ddck.dovetail.com/data/3KmUZXi99Qn1loVq4paAyt#:v:h=12lG4rYvzqA6fVqtgjziPb
"AIAAIC1771
","According to security researcher Sam Mitrovic, who experienced it first hand, the scam begins with an unexpected notification asking users to approve a recovery request they had not initiated.  Following this, victims typically receive a phone call from someone posing as a Google support representative, using a convincing American accent and professional demeanour.  The American voice explained there had been some suspicious activity on Mitrovic's Google account and someone had accessed it a week ago. The apparent Google employee offered to send an email detailing what happened, and that message promptly arrived from an official Google address.  However, Mitrovic realised the voice was actually AI-manipulated or generated and hung up. Why it happened With nearly 2.5 billion users globally, Gmail is an appealing target for cybercriminals.  Scammers use sophisticated techniques, including AI-generated voices and spoofed email addresses, to create a sense of legitimacy. The use of AI enhances the realism of the calls, making it harder for victims to detect the fraud.  In addition, the scammers take advantage of common fears about account security, manipulating users into acting quickly without verifying the authenticity of the requests.",Cause - Human causes - Human abuse of AI tools,Cause,Al account recovery scam calls target Gmail users,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/al-account-recovery-scam-calls-target-gmail-users,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:29,https://best-paper-award-ddck.dovetail.com/data/2TN1Xv6Nk2yONAWllaHBjm#:v:h=12Wf2VXqaCuQnRAvprcLDz
"AIAAIC1771
","According to security researcher Sam Mitrovic, who experienced it first hand, the scam begins with an unexpected notification asking users to approve a recovery request they had not initiated.  Following this, victims typically receive a phone call from someone posing as a Google support representative, using a convincing American accent and professional demeanour.  The American voice explained there had been some suspicious activity on Mitrovic's Google account and someone had accessed it a week ago. The apparent Google employee offered to send an email detailing what happened, and that message promptly arrived from an official Google address.  However, Mitrovic realised the voice was actually AI-manipulated or generated and hung up. Why it happened With nearly 2.5 billion users globally, Gmail is an appealing target for cybercriminals.  Scammers use sophisticated techniques, including AI-generated voices and spoofed email addresses, to create a sense of legitimacy. The use of AI enhances the realism of the calls, making it harder for victims to detect the fraud.  In addition, the scammers take advantage of common fears about account security, manipulating users into acting quickly without verifying the authenticity of the requests.",Entity - malicious human,Responsible Entities,Al account recovery scam calls target Gmail users,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/al-account-recovery-scam-calls-target-gmail-users,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:29,https://best-paper-award-ddck.dovetail.com/data/2TN1Xv6Nk2yONAWllaHBjm#:v:h=12Wf2VXqaCuQnRAvprcLDz
"AIAAIC1771
","According to security researcher Sam Mitrovic, who experienced it first hand, the scam begins with an unexpected notification asking users to approve a recovery request they had not initiated.  Following this, victims typically receive a phone call from someone posing as a Google support representative, using a convincing American accent and professional demeanour.  The American voice explained there had been some suspicious activity on Mitrovic's Google account and someone had accessed it a week ago. The apparent Google employee offered to send an email detailing what happened, and that message promptly arrived from an official Google address.  However, Mitrovic realised the voice was actually AI-manipulated or generated and hung up. Why it happened With nearly 2.5 billion users globally, Gmail is an appealing target for cybercriminals.  Scammers use sophisticated techniques, including AI-generated voices and spoofed email addresses, to create a sense of legitimacy. The use of AI enhances the realism of the calls, making it harder for victims to detect the fraud.  In addition, the scammers take advantage of common fears about account security, manipulating users into acting quickly without verifying the authenticity of the requests.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Al account recovery scam calls target Gmail users,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/al-account-recovery-scam-calls-target-gmail-users,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:29,https://best-paper-award-ddck.dovetail.com/data/2TN1Xv6Nk2yONAWllaHBjm#:v:h=12Wf2VXqaCuQnRAvprcLDz
AIAAIC0984,"Fake AI images of Donald Trump appearing to be tackled to the ground and arrested by New York police officers went viral online, fooling some people into thinking they were real.  Created by Eliot Higgins, founder of investigative website Belingcat, using AI image generator Midjourney, the images included shots of Trump's wife Melania screaming, his daughter Ivanka yelling, son Donald Trump Jr protesting, and the former US president in orange prison fatigues.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake Donald Trump arrest photos,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-donald-trump-arrest-photos,Incident,2022,2023,2023,USA,Politics,Eliot Higgins; Midjourney,Midjourney,Midjourney,Deepfake - video; Machine learning,Entertain,,Mis/disinformation; Ethics/values,Governance; Black box,,,,,System update,,,,10/30/2024 19:09,https://best-paper-award-ddck.dovetail.com/data/yy1hWocgKUCeMfmf8igGv#:v:h=1417ARw58fnafQ8nBRtvDl
AIAAIC0984,"Fake AI images of Donald Trump appearing to be tackled to the ground and arrested by New York police officers went viral online, fooling some people into thinking they were real.  Created by Eliot Higgins, founder of investigative website Belingcat, using AI image generator Midjourney, the images included shots of Trump's wife Melania screaming, his daughter Ivanka yelling, son Donald Trump Jr protesting, and the former US president in orange prison fatigues.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake Donald Trump arrest photos,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-donald-trump-arrest-photos,Incident,2022,2023,2023,USA,Politics,Eliot Higgins; Midjourney,Midjourney,Midjourney,Deepfake - video; Machine learning,Entertain,,Mis/disinformation; Ethics/values,Governance; Black box,,,,,System update,,,,10/30/2024 19:09,https://best-paper-award-ddck.dovetail.com/data/yy1hWocgKUCeMfmf8igGv#:v:h=1417ARw58fnafQ8nBRtvDl
AIAAIC0984,"Fake AI images of Donald Trump appearing to be tackled to the ground and arrested by New York police officers went viral online, fooling some people into thinking they were real.  Created by Eliot Higgins, founder of investigative website Belingcat, using AI image generator Midjourney, the images included shots of Trump's wife Melania screaming, his daughter Ivanka yelling, son Donald Trump Jr protesting, and the former US president in orange prison fatigues.",Entity - malicious human,Responsible Entities,Deepfake Donald Trump arrest photos,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-donald-trump-arrest-photos,Incident,2022,2023,2023,USA,Politics,Eliot Higgins; Midjourney,Midjourney,Midjourney,Deepfake - video; Machine learning,Entertain,,Mis/disinformation; Ethics/values,Governance; Black box,,,,,System update,,,,10/30/2024 19:09,https://best-paper-award-ddck.dovetail.com/data/yy1hWocgKUCeMfmf8igGv#:v:h=1417ARw58fnafQ8nBRtvDl
"AIAAIC1774
","Telegram's platform supports a multitude of channels and bots that facilitate the sharing and creation of these images, with users incentivised through gamification elements in which they earn rewards for creating and sharing deepfake images.",Cause - organization causes - poor business ethics,Cause,AI nudification bots swamp Telegram,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-nudification-bots-swamp-telegram,,,,,,,,,,,,,,,,,,,,,,,11/4/2024 17:15,https://best-paper-award-ddck.dovetail.com/data/6edhbS6Pc2s0Qme33ezFgt#:v:h=14qxJbKC7fOKbPiCsKRP4u
AIAAIC1146,"An AI voice generator was criticised for its lack of safeguards and the ease with which it can be made to generate racist, transphobic, homophobic, anti-semitic, violent, and offensive audio content in other people's names. 4chan and Reddit members were found to be using ElevenLab's Prime Voice AI (since renamed ElevenLabs TTS) to make deepfake voices of Emma Watson (reading out Adolf Hitler's Mein Kampf) and Joe Rogan, amongst others, spewing vile rhetoric, including at US House representative Alexandria Ocasio-Cortez. ElevenLabs responded by saying it had seen 'an increasing number of voice cloning misuse cases' and asked for 'thoughts and feedback'",Cause - Human causes - Human abuse of AI tools,Cause,ElevenLabs voice generator makes celebrity voices read offensive messages,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elevenlabs-voice-generator-makes-celebrity-voices-read-offensive-messages,Incident,2023,2023,2023,USA; UK,Media/entertainment/sports/arts,,ElevenLabs,ElevenLabs TTS; Prime Voice AI,Text-to-speech; Deep learning; Machine learning,Mimic celebrities,User comments/complaints,Safety; Mis/disinformation; Privacy; Copyright; Ethics/values,Governance; Marketing,Manipulation,,,,,,,,10/7/2024 0:40,https://best-paper-award-ddck.dovetail.com/data/3nyyH0s0cIRgsOaA0KaTQr#:v:h=15XS5CBGp1dx70y8IWgMcD
AIAAIC1146,"An AI voice generator was criticised for its lack of safeguards and the ease with which it can be made to generate racist, transphobic, homophobic, anti-semitic, violent, and offensive audio content in other people's names. 4chan and Reddit members were found to be using ElevenLab's Prime Voice AI (since renamed ElevenLabs TTS) to make deepfake voices of Emma Watson (reading out Adolf Hitler's Mein Kampf) and Joe Rogan, amongst others, spewing vile rhetoric, including at US House representative Alexandria Ocasio-Cortez. ElevenLabs responded by saying it had seen 'an increasing number of voice cloning misuse cases' and asked for 'thoughts and feedback'",Entity - AI developer company,Responsible Entities,ElevenLabs voice generator makes celebrity voices read offensive messages,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elevenlabs-voice-generator-makes-celebrity-voices-read-offensive-messages,Incident,2023,2023,2023,USA; UK,Media/entertainment/sports/arts,,ElevenLabs,ElevenLabs TTS; Prime Voice AI,Text-to-speech; Deep learning; Machine learning,Mimic celebrities,User comments/complaints,Safety; Mis/disinformation; Privacy; Copyright; Ethics/values,Governance; Marketing,Manipulation,,,,,,,,10/7/2024 0:40,https://best-paper-award-ddck.dovetail.com/data/3nyyH0s0cIRgsOaA0KaTQr#:v:h=15XS5CBGp1dx70y8IWgMcD
AIAAIC1146,"An AI voice generator was criticised for its lack of safeguards and the ease with which it can be made to generate racist, transphobic, homophobic, anti-semitic, violent, and offensive audio content in other people's names. 4chan and Reddit members were found to be using ElevenLab's Prime Voice AI (since renamed ElevenLabs TTS) to make deepfake voices of Emma Watson (reading out Adolf Hitler's Mein Kampf) and Joe Rogan, amongst others, spewing vile rhetoric, including at US House representative Alexandria Ocasio-Cortez. ElevenLabs responded by saying it had seen 'an increasing number of voice cloning misuse cases' and asked for 'thoughts and feedback'","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,ElevenLabs voice generator makes celebrity voices read offensive messages,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elevenlabs-voice-generator-makes-celebrity-voices-read-offensive-messages,Incident,2023,2023,2023,USA; UK,Media/entertainment/sports/arts,,ElevenLabs,ElevenLabs TTS; Prime Voice AI,Text-to-speech; Deep learning; Machine learning,Mimic celebrities,User comments/complaints,Safety; Mis/disinformation; Privacy; Copyright; Ethics/values,Governance; Marketing,Manipulation,,,,,,,,10/7/2024 0:40,https://best-paper-award-ddck.dovetail.com/data/3nyyH0s0cIRgsOaA0KaTQr#:v:h=15XS5CBGp1dx70y8IWgMcD
AIAAIC0960,"Twitch personality Brandon Ewing, 31, known online as Atrioc, inadvertently shared a link to a deepfake video site during a livestreaming event, exposing synthetic pornographic images of QTCinderella, Pokimane, and Sweet Anita.",Entity - malicious human,Responsible Entities,"QTCinderella, Pokimane, Sweet Anita deepfakes exposed using live stream",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/qtcinderella-pokimane-sweet-anita-deepfakes,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Generate revenue,Twitch streamer voyeurism,Safety; Privacy; Ethics/values,Governance; Privacy; Marketing,Privacy loss; Emotional damage; Reputational damage,,,,,,,,10/30/2024 19:35,https://best-paper-award-ddck.dovetail.com/data/LaSn2Wonl3QqFQgWUxgLe#:v:h=16JSbxsQxxMEPM81NO2apm
AIAAIC0960,"Twitch personality Brandon Ewing, 31, known online as Atrioc, inadvertently shared a link to a deepfake video site during a livestreaming event, exposing synthetic pornographic images of QTCinderella, Pokimane, and Sweet Anita.",Incident - human-driven - Public entity amplified of misleading content,Incident Type,"QTCinderella, Pokimane, Sweet Anita deepfakes exposed using live stream",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/qtcinderella-pokimane-sweet-anita-deepfakes,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Generate revenue,Twitch streamer voyeurism,Safety; Privacy; Ethics/values,Governance; Privacy; Marketing,Privacy loss; Emotional damage; Reputational damage,,,,,,,,10/30/2024 19:35,https://best-paper-award-ddck.dovetail.com/data/LaSn2Wonl3QqFQgWUxgLe#:v:h=16JSbxsQxxMEPM81NO2apm
AIAAIC0971,Both are alleged to be in violation of New York City's 2021 Biometric Identifier Information Law. The law requires all New York City businessses to post a sign informing customers or visitors that their biometrics are being recorded.,Entity - AI developer company,Responsible Entities,Amazon Go fails to inform NYC customers about facial recognition,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-go-fails-to-inform-nyc-customers-about-facial-recognition,Incident,,2023,2023,USA,Retail,Amazon,Amazon,Just Walk Out,Facial recognition; Computer vision; Deep learning,Verify identity,Lawsuit filing/litigation,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,Litigation,,10/13/2024 22:26,https://best-paper-award-ddck.dovetail.com/data/4weXgJzYx9XhAQKBkzduCA#:v:h=19k6KRKygQ4JbxjDFPBoD1
AIAAIC0971,Both are alleged to be in violation of New York City's 2021 Biometric Identifier Information Law. The law requires all New York City businessses to post a sign informing customers or visitors that their biometrics are being recorded.,Cause - organization causes - legal non-compliance,Cause,Amazon Go fails to inform NYC customers about facial recognition,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-go-fails-to-inform-nyc-customers-about-facial-recognition,Incident,,2023,2023,USA,Retail,Amazon,Amazon,Just Walk Out,Facial recognition; Computer vision; Deep learning,Verify identity,Lawsuit filing/litigation,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,Litigation,,10/13/2024 22:26,https://best-paper-award-ddck.dovetail.com/data/4weXgJzYx9XhAQKBkzduCA#:v:h=19k6KRKygQ4JbxjDFPBoD1
AIAAIC1728,"Clearview AI has been fined EUR 30.5 million (approximately USD 33.7 million) by the DutchData Protection Authority (DPA) for multiple violations of the General Data Protection Regulation(GDPR). The penalty is the largest GDPR fine imposed on the company to date and stems from its creation of an extensivefacial recognition database, which is said to include over 30 billion images scraped from the internet without userconsent.",Entity - AI developer company,Responsible Entities,Dutch regulator fines Clearview AI for privacy violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dutch-regulator-fines-clearview-ai,Incident,,2024,2024,Netherlands,Multiple,Clearview AI,Clearview AI,Clearview AI,Facial recognition; Machine learning,Identify individuals,Regulatory action,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:34,https://best-paper-award-ddck.dovetail.com/data/1C4UyEheRNvTZLRRZsqSJP#:v:h=1bVFMFyH2foQEPESJoghnK
AIAAIC1200,"A lawsuit alleged Google scraped data from millions of users without their consent and violated copyright laws in order to train and develop its AI products. Eight individuals sued (pdf) Google, DeepMind, and their parent company Alphabet for 'secretly stealing' huge amounts of online data to train its AI technologies, including Bard. Led by Clarkson Law Firm, Google was accused of negligence, larceny, copyright infringement, invasion of privacy, and profiting from illegally obtained personal data",Cause - organization/human cause - lack of informed consent & transparency,Cause,Google sued for AI data scraping,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-sued-for-ai-data-scraping,Incident,2023,2023,2023,USA,Multiple,,Google,Bard/Gemini,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Copyright; Privacy,Governance,IP/copyright loss,,,,,,,,10/7/2024 0:12,https://best-paper-award-ddck.dovetail.com/data/77S4eyH1VDVyIKcg5Cpm8L#:v:h=1bVVF5Lqzy6ihgZvo6KFn5
AIAAIC1200,"A lawsuit alleged Google scraped data from millions of users without their consent and violated copyright laws in order to train and develop its AI products. Eight individuals sued (pdf) Google, DeepMind, and their parent company Alphabet for 'secretly stealing' huge amounts of online data to train its AI technologies, including Bard. Led by Clarkson Law Firm, Google was accused of negligence, larceny, copyright infringement, invasion of privacy, and profiting from illegally obtained personal data",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Google sued for AI data scraping,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-sued-for-ai-data-scraping,Incident,2023,2023,2023,USA,Multiple,,Google,Bard/Gemini,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Copyright; Privacy,Governance,IP/copyright loss,,,,,,,,10/7/2024 0:12,https://best-paper-award-ddck.dovetail.com/data/77S4eyH1VDVyIKcg5Cpm8L#:v:h=1bVVF5Lqzy6ihgZvo6KFn5
AIAAIC1403,The fracas indicated poor governance and ethics at Catalyst Research Alliance.,Cause - organization causes - poor business ethics,Cause,University of Michigan partner sells student data for AI training,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/university-of-michigan-partner-sells-student-data-for-ai-training,Issue,,2024,2024,USA,Education,Catalyst Research Alliance,University of Michigan,,Database/dataset,Train AI models,,Ethics/values; Privacy,Governance,,Privacy loss,,,,,,,10/2/2024 19:09,https://best-paper-award-ddck.dovetail.com/data/2yskPx5uiE7q8yNGsDSuGA#:v:h=1cGGD5MP5wqmKVfbzsy5iE
AIAAIC1616,"Tesla CEO Elon Musk shared online a video featuring an AI-generated voice clone of US Vice-President Kamapa Harris saying things she had never said, raising concerns about AI-generated political misinformation.  Designed to resemble a campaign ad, the video included audio of ""Harris"" making statements she never actually said, such as calling herself a ""diversity hire"" and criticising her own qualifications for the presidency. It also called Harris a ""deep state puppet"".","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Elon Musk shares Kamala Harris voice close video ad,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elon-musk-shares-kamala-harris-voice-clone-video-ad,Issue,,2024,2024,USA,Politics,,,,Deepfake - video; Machine learning,Satirise/parody,,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:10,https://best-paper-award-ddck.dovetail.com/data/7DBPDK65ZBX1OiFoY6lnPh#:v:h=1g8vA53wgvzy7aYPnt2jQK
AIAAIC1156,"'Digital identity and financial network' Worldcoin had its operations suspended in Kenya after regulators raised concerns about its collection and storage of sensitive biometric data.  Worldcoin had seen strong demand from Kenyan citizens to register for the platform, which uses a 'chrome orb' to scan the irises and faces of people agreeing to sign up for a share of its new WLD currency.",Entity - AI developer company,Responsible Entities,"Worldcoin suspended in Kenya over privacy, security concerns",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/worldcoin-suspended-in-kenya-for-privacy-abuse,Incident,2023,2023,2023,Kenya,Banking/financial services,"Tools for Humanity/Worldcoin
","Tools for Humanity/Worldcoin
",Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security; Legal,Governance; Privacy; Marketing,Privacy loss; Financial loss,,,,System suspension,,Restraining order; Parliamentary investigation,,10/7/2024 0:36,https://best-paper-award-ddck.dovetail.com/data/4sPxaecAc36dgjjjvzKHEn#:v:h=1iNwNUdNuq8Hwflnre0HCQ
AIAAIC1156,"'Digital identity and financial network' Worldcoin had its operations suspended in Kenya after regulators raised concerns about its collection and storage of sensitive biometric data.  Worldcoin had seen strong demand from Kenyan citizens to register for the platform, which uses a 'chrome orb' to scan the irises and faces of people agreeing to sign up for a share of its new WLD currency.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,"Worldcoin suspended in Kenya over privacy, security concerns",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/worldcoin-suspended-in-kenya-for-privacy-abuse,Incident,2023,2023,2023,Kenya,Banking/financial services,"Tools for Humanity/Worldcoin
","Tools for Humanity/Worldcoin
",Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security; Legal,Governance; Privacy; Marketing,Privacy loss; Financial loss,,,,System suspension,,Restraining order; Parliamentary investigation,,10/7/2024 0:36,https://best-paper-award-ddck.dovetail.com/data/4sPxaecAc36dgjjjvzKHEn#:v:h=1iNwNUdNuq8Hwflnre0HCQ
AIAAIC1067,"A photograph showing UK Prime Minister Rishi Sunak pulling a pint of beer that was shared by an opposition member of parliament has been found to have been doctored. The image showed an onlooker giving Sunak a disapproving side-eye, which was not the case in the original image, which was taken at the Great British Beer Festival and posted on the prime minister's official Twitter account.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Rishi Sunak pulls pint deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rishi-sunak-pulls-pint-deepfake,Incident,,2023,2023,UK,Politics,XCorp/xAI/Twitter,Adobe,Photoshop,Deepfake - image; Machine learning,Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/30/2024 16:58,https://best-paper-award-ddck.dovetail.com/data/76DqzQd426GplTUSmMoAlL#:v:h=1jAOnOlkLpwO94G45bgTs0
AIAAIC1067,"A photograph showing UK Prime Minister Rishi Sunak pulling a pint of beer that was shared by an opposition member of parliament has been found to have been doctored. The image showed an onlooker giving Sunak a disapproving side-eye, which was not the case in the original image, which was taken at the Great British Beer Festival and posted on the prime minister's official Twitter account.",Entity - malicious human,Responsible Entities,Rishi Sunak pulls pint deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rishi-sunak-pulls-pint-deepfake,Incident,,2023,2023,UK,Politics,XCorp/xAI/Twitter,Adobe,Photoshop,Deepfake - image; Machine learning,Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/30/2024 16:58,https://best-paper-award-ddck.dovetail.com/data/76DqzQd426GplTUSmMoAlL#:v:h=1jAOnOlkLpwO94G45bgTs0
AIAAIC1431,"A voiceover artist in China filed a lawsuit alleging an AI-generated voice resembling her own was used in audiobooks without her consent. The voiceover artist, Yin, is suing 5 companies, including the provider of the AI text-to-speech system and the company that had recorded her voice. The system in question uses generative artificial intelligence to recreate voices, allegedly with high precision.",Entity - large dataset organization,Responsible Entities,Chinese voice actor sues AI companies for using her voice without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chinese-voice-actor-sues-ai-companies-for-using-her-voice-without-consent,Incident,,2023,2023,China,Media/entertainment/sports/arts,,,,Text-to-speech; Deepfake - audio; Neural network; Deep learning; Machine learning,Generate audio,Lawsuit filing/litigation,"Personality rights, Workforce dislocation/replacement",,"Personality rights loss,  Financial loss",,,Reputational damage,,,Litigation,,10/24/2024 23:29,https://best-paper-award-ddck.dovetail.com/data/33ElwjC99Z5zpq4OgVKbRc#:v:h=1l2ph10L3s0S7GBNNErkgX
AIAAIC1431,"A voiceover artist in China filed a lawsuit alleging an AI-generated voice resembling her own was used in audiobooks without her consent. The voiceover artist, Yin, is suing 5 companies, including the provider of the AI text-to-speech system and the company that had recorded her voice. The system in question uses generative artificial intelligence to recreate voices, allegedly with high precision.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Chinese voice actor sues AI companies for using her voice without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chinese-voice-actor-sues-ai-companies-for-using-her-voice-without-consent,Incident,,2023,2023,China,Media/entertainment/sports/arts,,,,Text-to-speech; Deepfake - audio; Neural network; Deep learning; Machine learning,Generate audio,Lawsuit filing/litigation,"Personality rights, Workforce dislocation/replacement",,"Personality rights loss,  Financial loss",,,Reputational damage,,,Litigation,,10/24/2024 23:29,https://best-paper-award-ddck.dovetail.com/data/33ElwjC99Z5zpq4OgVKbRc#:v:h=1l2ph10L3s0S7GBNNErkgX
AIAAIC1431,"A voiceover artist in China filed a lawsuit alleging an AI-generated voice resembling her own was used in audiobooks without her consent. The voiceover artist, Yin, is suing 5 companies, including the provider of the AI text-to-speech system and the company that had recorded her voice. The system in question uses generative artificial intelligence to recreate voices, allegedly with high precision.",Entity - AI developer company,Responsible Entities,Chinese voice actor sues AI companies for using her voice without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chinese-voice-actor-sues-ai-companies-for-using-her-voice-without-consent,Incident,,2023,2023,China,Media/entertainment/sports/arts,,,,Text-to-speech; Deepfake - audio; Neural network; Deep learning; Machine learning,Generate audio,Lawsuit filing/litigation,"Personality rights, Workforce dislocation/replacement",,"Personality rights loss,  Financial loss",,,Reputational damage,,,Litigation,,10/24/2024 23:29,https://best-paper-award-ddck.dovetail.com/data/33ElwjC99Z5zpq4OgVKbRc#:v:h=1l2ph10L3s0S7GBNNErkgX
AIAAIC1431,"A voiceover artist in China filed a lawsuit alleging an AI-generated voice resembling her own was used in audiobooks without her consent. The voiceover artist, Yin, is suing 5 companies, including the provider of the AI text-to-speech system and the company that had recorded her voice. The system in question uses generative artificial intelligence to recreate voices, allegedly with high precision.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Chinese voice actor sues AI companies for using her voice without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chinese-voice-actor-sues-ai-companies-for-using-her-voice-without-consent,Incident,,2023,2023,China,Media/entertainment/sports/arts,,,,Text-to-speech; Deepfake - audio; Neural network; Deep learning; Machine learning,Generate audio,Lawsuit filing/litigation,"Personality rights, Workforce dislocation/replacement",,"Personality rights loss,  Financial loss",,,Reputational damage,,,Litigation,,10/24/2024 23:29,https://best-paper-award-ddck.dovetail.com/data/33ElwjC99Z5zpq4OgVKbRc#:v:h=1l2ph10L3s0S7GBNNErkgX
AIAAIC1403,"A partner to the University of Michigan tried to sell student data to organisations training AI models, causing controversy about the possible abuse of student privacy. Catalyst Research Alliance, which claims to partner the University of Michigan (UM) and North Carolina State University, was found to be hawking licenses for academic data from 65 speech events, 85 hours of audio recordings and 829 student papers for USD 25,000. ",Entity - large dataset organization,Responsible Entities,University of Michigan partner sells student data for AI training,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/university-of-michigan-partner-sells-student-data-for-ai-training,Issue,,2024,2024,USA,Education,Catalyst Research Alliance,University of Michigan,,Database/dataset,Train AI models,,Ethics/values; Privacy,Governance,,Privacy loss,,,,,,,10/2/2024 19:06,https://best-paper-award-ddck.dovetail.com/data/2yskPx5uiE7q8yNGsDSuGA#:v:h=1lkoOyVHUKgjOPMEjNRTea
AIAAIC1403,"A partner to the University of Michigan tried to sell student data to organisations training AI models, causing controversy about the possible abuse of student privacy. Catalyst Research Alliance, which claims to partner the University of Michigan (UM) and North Carolina State University, was found to be hawking licenses for academic data from 65 speech events, 85 hours of audio recordings and 829 student papers for USD 25,000. ",Incident - organization-driven - unauthorized sell of user data,Incident Type,University of Michigan partner sells student data for AI training,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/university-of-michigan-partner-sells-student-data-for-ai-training,Issue,,2024,2024,USA,Education,Catalyst Research Alliance,University of Michigan,,Database/dataset,Train AI models,,Ethics/values; Privacy,Governance,,Privacy loss,,,,,,,10/2/2024 19:06,https://best-paper-award-ddck.dovetail.com/data/2yskPx5uiE7q8yNGsDSuGA#:v:h=1lkoOyVHUKgjOPMEjNRTea
AIAAIC1518,"Dataset LAION-5B was found to contain personal photos and details of identifiable Brazilian children without their knowledge or consent, prompting concerns about privacy and its creator's governance and integrity. Human Rights Watch (HRW) discovered over 170 photos of children across 10 Brazilian states in the dataset, including names, ages, locations, and other identifying information. Some of the photos dated back to the mid-1990s, while others are as recent as 2023. All images had been posted by families on social media. In one instance, details revealed a 2-year-old girl and newborn sister, with their names and the hospital where the baby was born. Human Rights Watch said it only reviewed 0.0001 percent of the 5.85 billion images on LAION-5B, suggesting many more such images could be present. The images violate children's privacy and enable malicious actors to create explicit deepfakes exploiting them, HRW said. LAION, the non-profit organisation behind the dataset, temporarily removed the offending images and said it would implement filters. LAION-5B was used to train Stable Diffusion, among other models.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,LAION-5B links to photos of identifiable Brazilian children,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/laion-5b-links-to-photos-of-identifiable-brazilian-children,Incident,2020,2024,2024,Brazil,Private - individual,Human Rights Watch,LAION,LAION-5B,Database/dataset; Neural network; Deep learning; Machine learning,Pair text and images,Research study/report,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 11:52,https://best-paper-award-ddck.dovetail.com/data/zsB8JITme60asEvuq1ZUs#:v:h=1n6pWcyGvnDu8OjrowNqSl
AIAAIC1074,"An update to Zoom's terms of service to state that customer data would be used for 'machine learning' and 'artificial intelligence' met with stiff criticism. The move led customers to say their confidentiality and privacy was at stake and threaten to boycott or leave Zoom for competitor products, and left Zoom scrambling to explain what it was doing. In response, the company updated its terms to say 'Notwithstanding the above, Zoom will not use audio, video or chat Customer Content to train our artificial intelligence models without your consent.'  However, privacy experts said the new update contradicted the earlier statement, and suggested the company could continue to collect and use customer data. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Zoom uses customer data to train AI models,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/zoom-customer-data-ai-model-training,Issue,,2023,2023,USA,Business/professional services,Zoom Video Communications,Zoom Video Communications,Zoom IQ,NLP/text analysis; Neural network; Deep learning; Machine learning,Summarise meetings,Company statement,Confidentiality; Privacy; Ethics/values,Governance; Legal; Marketing,,,,Loss of trust,Policy update,,,,10/7/2024 1:10,https://best-paper-award-ddck.dovetail.com/data/7LVeq546ZjC7gewId5V1fX#:v:h=1nh1dyhRigcxUysW3NiBzZ
AIAAIC1074,"An update to Zoom's terms of service to state that customer data would be used for 'machine learning' and 'artificial intelligence' met with stiff criticism. The move led customers to say their confidentiality and privacy was at stake and threaten to boycott or leave Zoom for competitor products, and left Zoom scrambling to explain what it was doing. In response, the company updated its terms to say 'Notwithstanding the above, Zoom will not use audio, video or chat Customer Content to train our artificial intelligence models without your consent.'  However, privacy experts said the new update contradicted the earlier statement, and suggested the company could continue to collect and use customer data. ",Entity - AI developer company,Responsible Entities,Zoom uses customer data to train AI models,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/zoom-customer-data-ai-model-training,Issue,,2023,2023,USA,Business/professional services,Zoom Video Communications,Zoom Video Communications,Zoom IQ,NLP/text analysis; Neural network; Deep learning; Machine learning,Summarise meetings,Company statement,Confidentiality; Privacy; Ethics/values,Governance; Legal; Marketing,,,,Loss of trust,Policy update,,,,10/7/2024 1:10,https://best-paper-award-ddck.dovetail.com/data/7LVeq546ZjC7gewId5V1fX#:v:h=1nh1dyhRigcxUysW3NiBzZ
AIAAIC1469,"Noyb argued that this behaviour violates GDPR rules on privacy, the accuracy of information, and the right for individuals to correct inaccurate information.",Cause - organization causes - legal non-compliance,Cause,ChatGPT accused of violating GDPR by not correcting inaccurate personal information,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-said-to-violate-gdpr-by-not-correcting-inaccurate-personal-info,Incident,2022,2024,2024,Austria,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot,Generate text,Legal complaint,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 13:13,https://best-paper-award-ddck.dovetail.com/data/6AJcNsz8AZfklQimhDzbDm#:v:h=1pir0TAnkILPJ5rfw9izNN
AIAAIC1096,"Researchers said the campaign comprised 85 social media accounts and blogs originating from China, and targeted users in multiple countries and 16 languages on Facebook, Twitter, YouTube, and a dozen other platforms. Meta confirmed to Gizmodo the accounts were part of China's deepfake 'Spamouflage' disinformation operation.",Cause - Lack of AI control,Cause,China uses AI to accuse US of starting Maui wildfires,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-flood-warning-system-false-alerts,Incident,,2023,2023,USA,Politics,Government of China,Government of China,,"Deepfake - image, video, audio; Machine learning",Scare/confuse/destabilise,Research study/report,Mis/disinformation,Governance; Marketing,Manipulation,,,,,,,,11/4/2024 15:44,https://best-paper-award-ddck.dovetail.com/data/70vg9Jv4ZaReF0BmWvugR1#:v:h=1rBUzUC549jNuAr8RyUFVT
AIAAIC1610, microphones installed in public spaces linked to local CCTV cameras. ,Cause - organization/human cause - lack of informed consent & transparency,Cause,French court rules City of Orleans use of AI is illegal,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/french-court-rules-city-of-orleans-use-of-ai-is-illegal,Incident,2021,2024,2024,France,Govt - municipal,,Sensivic,Sensivic,Machine learning,Detect abnormal situations,Research study/report,Human/civil rights; Privacy,Governance,Privacy loss,,,,,,,,9/27/2024 15:41,https://best-paper-award-ddck.dovetail.com/data/6sLCWa6KcDYpuUjZFAOlum#:v:h=1uTTOJwvEItSnXwPNscmNB
AIAAIC1660,"ITV news anchor Mary Nightingale expressed outrage after discovering that her likeness had been used in a deepfake video promoting a financial investment app.  The manipulated video, which surfaced on social media, depicted Nightingale as if she were presenting the ITV Evening News before promoting the app. Nightingale described the experience as ""identity theft,"" emphasising the potential dangers of deepfakes in manipulating public trust, especially with upcoming elections.",Cause - no specific info,Cause,Mary Nightingale likeness used in deepfake scam,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/mary-nightingale-likeness-used-in-deepfake-scam,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - video; Machine learning,Defraud,,Ethics/values; Personality rights,Governance,,,,,,,,,10/12/2024 1:22,https://best-paper-award-ddck.dovetail.com/data/2JQZunrkSJdGM1QDTFMQNa#:v:h=1uVTlmTz3Dj9yxwEgUTnwo
AIAAIC1660,"ITV news anchor Mary Nightingale expressed outrage after discovering that her likeness had been used in a deepfake video promoting a financial investment app.  The manipulated video, which surfaced on social media, depicted Nightingale as if she were presenting the ITV Evening News before promoting the app. Nightingale described the experience as ""identity theft,"" emphasising the potential dangers of deepfakes in manipulating public trust, especially with upcoming elections.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Mary Nightingale likeness used in deepfake scam,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/mary-nightingale-likeness-used-in-deepfake-scam,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - video; Machine learning,Defraud,,Ethics/values; Personality rights,Governance,,,,,,,,,10/12/2024 1:22,https://best-paper-award-ddck.dovetail.com/data/2JQZunrkSJdGM1QDTFMQNa#:v:h=1uVTlmTz3Dj9yxwEgUTnwo
AIAAIC1660,"ITV news anchor Mary Nightingale expressed outrage after discovering that her likeness had been used in a deepfake video promoting a financial investment app.  The manipulated video, which surfaced on social media, depicted Nightingale as if she were presenting the ITV Evening News before promoting the app. Nightingale described the experience as ""identity theft,"" emphasising the potential dangers of deepfakes in manipulating public trust, especially with upcoming elections.",Entity - no specific info,Responsible Entities,Mary Nightingale likeness used in deepfake scam,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/mary-nightingale-likeness-used-in-deepfake-scam,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - video; Machine learning,Defraud,,Ethics/values; Personality rights,Governance,,,,,,,,,10/12/2024 1:22,https://best-paper-award-ddck.dovetail.com/data/2JQZunrkSJdGM1QDTFMQNa#:v:h=1uVTlmTz3Dj9yxwEgUTnwo
AIAAIC1313,"After 102-year-old Dhuli Chand was forced to put together a mock wedding procession to prove to Haryana officials that he was alive, government data was released revealing that over 300,000 pensions were stopped in the following three years since claimants had been classified 'dead'. 70 percent (44,050) of a smaller sample of 63,353 pensions that were halted were later found to have been flagged incorrectly. Beneficiaries of subsidised food and other schemes were also excluded because the algorithm made wrong predictions about their incomes or employment, according to Al-Jazeera.",Entity - AI algorithm,Responsible Entities,Parivar Pehchan Patra algorithm declares living people dead,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/parivar-pehchan-patra-declares-living-people-dead,Incident,2020,2024,2024,India,Govt - welfare,Citizen Resources Information Department,Government of Haryana,Parivar Pehchan Patra,Machine learning,Assess welfare eligibility,Media investigation,Accuracy/reliability; Accountability; Privacy,Governance; Black box; Complaints/appeals,Financial loss; Privacy loss,,,,,,,,10/2/2024 20:35,https://best-paper-award-ddck.dovetail.com/data/24j1PG4Ua3uonjwhDaqwuL#:v:h=1x4F3f7qkrOatMtwR0YQHx
AIAAIC1313,"After 102-year-old Dhuli Chand was forced to put together a mock wedding procession to prove to Haryana officials that he was alive, government data was released revealing that over 300,000 pensions were stopped in the following three years since claimants had been classified 'dead'. 70 percent (44,050) of a smaller sample of 63,353 pensions that were halted were later found to have been flagged incorrectly. Beneficiaries of subsidised food and other schemes were also excluded because the algorithm made wrong predictions about their incomes or employment, according to Al-Jazeera.",Cause - human causes - Overtrusting AI,Cause,Parivar Pehchan Patra algorithm declares living people dead,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/parivar-pehchan-patra-declares-living-people-dead,Incident,2020,2024,2024,India,Govt - welfare,Citizen Resources Information Department,Government of Haryana,Parivar Pehchan Patra,Machine learning,Assess welfare eligibility,Media investigation,Accuracy/reliability; Accountability; Privacy,Governance; Black box; Complaints/appeals,Financial loss; Privacy loss,,,,,,,,10/2/2024 20:35,https://best-paper-award-ddck.dovetail.com/data/24j1PG4Ua3uonjwhDaqwuL#:v:h=1x4F3f7qkrOatMtwR0YQHx
AIAAIC1313,"After 102-year-old Dhuli Chand was forced to put together a mock wedding procession to prove to Haryana officials that he was alive, government data was released revealing that over 300,000 pensions were stopped in the following three years since claimants had been classified 'dead'. 70 percent (44,050) of a smaller sample of 63,353 pensions that were halted were later found to have been flagged incorrectly. Beneficiaries of subsidised food and other schemes were also excluded because the algorithm made wrong predictions about their incomes or employment, according to Al-Jazeera.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Parivar Pehchan Patra algorithm declares living people dead,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/parivar-pehchan-patra-declares-living-people-dead,Incident,2020,2024,2024,India,Govt - welfare,Citizen Resources Information Department,Government of Haryana,Parivar Pehchan Patra,Machine learning,Assess welfare eligibility,Media investigation,Accuracy/reliability; Accountability; Privacy,Governance; Black box; Complaints/appeals,Financial loss; Privacy loss,,,,,,,,10/2/2024 20:35,https://best-paper-award-ddck.dovetail.com/data/24j1PG4Ua3uonjwhDaqwuL#:v:h=1x4F3f7qkrOatMtwR0YQHx
AIAAIC1303,"A group of five Illinois residents filed a class-action lawsuit against PimEyes for collecting, scanning, and using their facial images, and those of millions of other Americans, without consent.  The residents accused PimEyes of 'intentional or reckless' privacy abuse, and of violating the Illinois Biometric Information Privacy Act (BIPA) and causing them 'great and irreparable injury'. They also argued the company had failed to explain its data management policies",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,"PimEyes sued in Illinois, USA, for privacy violations",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-sued-in-illinois-usa-for-privacy-violations,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Lawsuit filing/litigation,Governance; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 20:43,https://best-paper-award-ddck.dovetail.com/data/2kP3ZgJskd8oyopMz2hnhm#:v:h=1zq525Zseyt1nkh6Ae66GH
AIAAIC1303,"A group of five Illinois residents filed a class-action lawsuit against PimEyes for collecting, scanning, and using their facial images, and those of millions of other Americans, without consent.  The residents accused PimEyes of 'intentional or reckless' privacy abuse, and of violating the Illinois Biometric Information Privacy Act (BIPA) and causing them 'great and irreparable injury'. They also argued the company had failed to explain its data management policies",Cause - organization/human cause - lack of informed consent & transparency,Cause,"PimEyes sued in Illinois, USA, for privacy violations",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-sued-in-illinois-usa-for-privacy-violations,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Lawsuit filing/litigation,Governance; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 20:43,https://best-paper-award-ddck.dovetail.com/data/2kP3ZgJskd8oyopMz2hnhm#:v:h=1zq525Zseyt1nkh6Ae66GH
AIAAIC1075,"Privacy-focused web browser Brave appeared to sell data about its users without their knowledge or permission to third-parties developing AI systems.  The controversy resulted in accusations of poor ethics and hyprocrisy, and raised legal and ethical questions about the fair use of personal and copyrighted information.",Cause - organization causes - poor business ethics,Cause,Brave covertly sells user data for AI development,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/brave-ai-user-data-sales,Incident,,2023,2023,USA,Multiple,Brave Software,Brave Software,Brave Search API,Database/dataset,Share search results,Media investigation,Copyright; Ethics/values; Privacy,Governance; Marketing,IP/copyright loss,,,,,,,,10/7/2024 1:07,https://best-paper-award-ddck.dovetail.com/data/7nosCmaUExGC0kU3xGXyWi#:v:h=1zywsgheIQTImtKZbc2HM9
AIAAIC1075,"Privacy-focused web browser Brave appeared to sell data about its users without their knowledge or permission to third-parties developing AI systems.  The controversy resulted in accusations of poor ethics and hyprocrisy, and raised legal and ethical questions about the fair use of personal and copyrighted information.",Incident - organization-driven - unauthorized sell of user data,Incident Type,Brave covertly sells user data for AI development,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/brave-ai-user-data-sales,Incident,,2023,2023,USA,Multiple,Brave Software,Brave Software,Brave Search API,Database/dataset,Share search results,Media investigation,Copyright; Ethics/values; Privacy,Governance; Marketing,IP/copyright loss,,,,,,,,10/7/2024 1:07,https://best-paper-award-ddck.dovetail.com/data/7nosCmaUExGC0kU3xGXyWi#:v:h=1zywsgheIQTImtKZbc2HM9
AIAAIC1075,"Privacy-focused web browser Brave appeared to sell data about its users without their knowledge or permission to third-parties developing AI systems.  The controversy resulted in accusations of poor ethics and hyprocrisy, and raised legal and ethical questions about the fair use of personal and copyrighted information.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Brave covertly sells user data for AI development,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/brave-ai-user-data-sales,Incident,,2023,2023,USA,Multiple,Brave Software,Brave Software,Brave Search API,Database/dataset,Share search results,Media investigation,Copyright; Ethics/values; Privacy,Governance; Marketing,IP/copyright loss,,,,,,,,10/7/2024 1:07,https://best-paper-award-ddck.dovetail.com/data/7nosCmaUExGC0kU3xGXyWi#:v:h=1zywsgheIQTImtKZbc2HM9
AIAAIC1075,"Privacy-focused web browser Brave appeared to sell data about its users without their knowledge or permission to third-parties developing AI systems.  The controversy resulted in accusations of poor ethics and hyprocrisy, and raised legal and ethical questions about the fair use of personal and copyrighted information.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Brave covertly sells user data for AI development,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/brave-ai-user-data-sales,Incident,,2023,2023,USA,Multiple,Brave Software,Brave Software,Brave Search API,Database/dataset,Share search results,Media investigation,Copyright; Ethics/values; Privacy,Governance; Marketing,IP/copyright loss,,,,,,,,10/7/2024 1:07,https://best-paper-award-ddck.dovetail.com/data/7nosCmaUExGC0kU3xGXyWi#:v:h=1zywsgheIQTImtKZbc2HM9
AIAAIC1075,"Privacy-focused web browser Brave appeared to sell data about its users without their knowledge or permission to third-parties developing AI systems.  The controversy resulted in accusations of poor ethics and hyprocrisy, and raised legal and ethical questions about the fair use of personal and copyrighted information.",Entity - large dataset organization,Responsible Entities,Brave covertly sells user data for AI development,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/brave-ai-user-data-sales,Incident,,2023,2023,USA,Multiple,Brave Software,Brave Software,Brave Search API,Database/dataset,Share search results,Media investigation,Copyright; Ethics/values; Privacy,Governance; Marketing,IP/copyright loss,,,,,,,,10/7/2024 1:07,https://best-paper-award-ddck.dovetail.com/data/7nosCmaUExGC0kU3xGXyWi#:v:h=1zywsgheIQTImtKZbc2HM9
AIAAIC1298,"Facial recognition search engine PimEyes used stolen images of dead people on Ancestry.com to train its algorithm. Software engineer Cher Scarlett discovered images of her sister, her mother and great-great-great grandmother whilst looking for photographs of herself on PimEyes. Scarlett said the photos appeared to have been taken from images that she and her family had personally uploaded to Ancestry.com. Ancestry.com's terms prohibit 'scraping data, including photos, from Ancestry's sites and services as well as reselling, reproducing, or publishing any content or information found on Ancestry.'  PimEyes director Giorgi Gobronidze responded that the site's opt-out feature, which allows users to restrict specific images of themselves from being used, 'will not work with 100 percent efficiency always,' and that the site would stop drawing data from Ancestry.com. The incident raised concerns about PimEyes' ethics, its use of personal biometric data without permission to train its facial recognition system, and the fact that it was abusing Ancestry.com's terms. ",Cause - organization causes - legal non-compliance,Cause,PimEyes steals images of dead people to train facial recognition system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-steals-images-of-dead-people-to-train-facial-recognition-system,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,User comments/complaints,Ethics/values; Governance; Privacy,Governance,Privacy loss,,,,System update,,,,10/2/2024 21:01,https://best-paper-award-ddck.dovetail.com/data/7Lr7KUr6TZqqtEuNeHFrjs#:v:h=1AfhNVjq9JmKiVnXKYBc0T
AIAAIC1298,"Facial recognition search engine PimEyes used stolen images of dead people on Ancestry.com to train its algorithm. Software engineer Cher Scarlett discovered images of her sister, her mother and great-great-great grandmother whilst looking for photographs of herself on PimEyes. Scarlett said the photos appeared to have been taken from images that she and her family had personally uploaded to Ancestry.com. Ancestry.com's terms prohibit 'scraping data, including photos, from Ancestry's sites and services as well as reselling, reproducing, or publishing any content or information found on Ancestry.'  PimEyes director Giorgi Gobronidze responded that the site's opt-out feature, which allows users to restrict specific images of themselves from being used, 'will not work with 100 percent efficiency always,' and that the site would stop drawing data from Ancestry.com. The incident raised concerns about PimEyes' ethics, its use of personal biometric data without permission to train its facial recognition system, and the fact that it was abusing Ancestry.com's terms. ",Entity - AI developer company,Responsible Entities,PimEyes steals images of dead people to train facial recognition system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-steals-images-of-dead-people-to-train-facial-recognition-system,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,User comments/complaints,Ethics/values; Governance; Privacy,Governance,Privacy loss,,,,System update,,,,10/2/2024 21:01,https://best-paper-award-ddck.dovetail.com/data/7Lr7KUr6TZqqtEuNeHFrjs#:v:h=1AfhNVjq9JmKiVnXKYBc0T
AIAAIC1298,"Facial recognition search engine PimEyes used stolen images of dead people on Ancestry.com to train its algorithm. Software engineer Cher Scarlett discovered images of her sister, her mother and great-great-great grandmother whilst looking for photographs of herself on PimEyes. Scarlett said the photos appeared to have been taken from images that she and her family had personally uploaded to Ancestry.com. Ancestry.com's terms prohibit 'scraping data, including photos, from Ancestry's sites and services as well as reselling, reproducing, or publishing any content or information found on Ancestry.'  PimEyes director Giorgi Gobronidze responded that the site's opt-out feature, which allows users to restrict specific images of themselves from being used, 'will not work with 100 percent efficiency always,' and that the site would stop drawing data from Ancestry.com. The incident raised concerns about PimEyes' ethics, its use of personal biometric data without permission to train its facial recognition system, and the fact that it was abusing Ancestry.com's terms. ",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,PimEyes steals images of dead people to train facial recognition system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-steals-images-of-dead-people-to-train-facial-recognition-system,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,User comments/complaints,Ethics/values; Governance; Privacy,Governance,Privacy loss,,,,System update,,,,10/2/2024 21:01,https://best-paper-award-ddck.dovetail.com/data/7Lr7KUr6TZqqtEuNeHFrjs#:v:h=1AfhNVjq9JmKiVnXKYBc0T
AIAAIC1019,A verified Twitter account called @BloombergFeed impersonating a Bloomberg profile had shared a photo of plumes of smoke billowing over a large white building with the words 'Large explosion near The Pentagon Complex in Washington D.C - Initial Report'.,Entity - malicious human,Responsible Entities,Pentagon deepfake 'explosion' jitters US stock market,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pentagon-deepfake-explosion,Incident,,2023,2023,USA,Govt - defence,X Corp/Twitter,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,,Mis/disinformation,Governance; Marketing,,Stock market price fall,,,,,,,10/30/2024 17:35,https://best-paper-award-ddck.dovetail.com/data/35vWwsC8yBttpuxC7vKuxO#:v:h=1B4ITKpbg0RR1ruvHFWB1T
AIAAIC1164,A realistic deepfake video of popstar Taylor Swift fluently speaking Mandarin Chinese sparked discussion in China about the ethics of using artificial intelligence to develop digital content.,"Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Taylor Swift speaks in Mandarin deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/taylor-swift-speaks-in-mandarin-deepfake,Incident,,2023,2023,China; USA,Media/entertainment/sports/arts,,HeyGen,Video Translate,"Deepfake - audio, video; Machine learning",Promote developer,User comments/complaints,Mis/disinformation; Privacy,,Manipulation,,,,,,,,10/24/2024 21:25,https://best-paper-award-ddck.dovetail.com/data/7oLXMZ0AGOivl1qXp4MMxA#:v:h=1BDVEUGyeF6mWdwG7vaocv
AIAAIC1691,"However, parents and critics expressed concerns about the potential negative impacts on children's development and the over-reliance on digital devices. Over 56,000 parentssigned a petition on the National Assembly’s online platform opposing over-exposure to digital devices, expressing worries about the effects of increased screen time on theirchildren's brain development and overall well-being, and requesting the system is shelved. Many argued that the focus should be on traditional learning methods rather than integrating new technologies. Critics also raised alarms about privacy issues and the risks associated with excessive use of digital devices. The teachers' labour union also called for a delay inimplementation until a broader consensus on the risks and benefits can be reached. South Korea education minister Lee Ju-ho defended the initiative, emphasising that the transition to digital textbooks is part of a broader effort to modernise education.",Entity - government authorities that adopt AI,Responsible Entities,South Korea plan for AI textbooks receives backlash,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korea-plan-for-ai-textbooks-receives-backlash,Issue,,2024,2024,South Korea,Education,,,AI digital textbooks,Machine learning,Educate students,,Appropriateness/need; Privacy,Students,,,,,,,,,9/26/2024 22:43,https://best-paper-award-ddck.dovetail.com/data/30jcDtyIZpPC2DWy30fRXM#:v:h=1FyghAPFotLQBrzijs0QZR
AIAAIC1691,"However, parents and critics expressed concerns about the potential negative impacts on children's development and the over-reliance on digital devices. Over 56,000 parentssigned a petition on the National Assembly’s online platform opposing over-exposure to digital devices, expressing worries about the effects of increased screen time on theirchildren's brain development and overall well-being, and requesting the system is shelved. Many argued that the focus should be on traditional learning methods rather than integrating new technologies. Critics also raised alarms about privacy issues and the risks associated with excessive use of digital devices. The teachers' labour union also called for a delay inimplementation until a broader consensus on the risks and benefits can be reached. South Korea education minister Lee Ju-ho defended the initiative, emphasising that the transition to digital textbooks is part of a broader effort to modernise education.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,South Korea plan for AI textbooks receives backlash,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korea-plan-for-ai-textbooks-receives-backlash,Issue,,2024,2024,South Korea,Education,,,AI digital textbooks,Machine learning,Educate students,,Appropriateness/need; Privacy,Students,,,,,,,,,9/26/2024 22:43,https://best-paper-award-ddck.dovetail.com/data/30jcDtyIZpPC2DWy30fRXM#:v:h=1FyghAPFotLQBrzijs0QZR
AIAAIC1691,"However, parents and critics expressed concerns about the potential negative impacts on children's development and the over-reliance on digital devices. Over 56,000 parentssigned a petition on the National Assembly’s online platform opposing over-exposure to digital devices, expressing worries about the effects of increased screen time on theirchildren's brain development and overall well-being, and requesting the system is shelved. Many argued that the focus should be on traditional learning methods rather than integrating new technologies. Critics also raised alarms about privacy issues and the risks associated with excessive use of digital devices. The teachers' labour union also called for a delay inimplementation until a broader consensus on the risks and benefits can be reached. South Korea education minister Lee Ju-ho defended the initiative, emphasising that the transition to digital textbooks is part of a broader effort to modernise education.",Cause - Human causes - Undertrusting AI,Cause,South Korea plan for AI textbooks receives backlash,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korea-plan-for-ai-textbooks-receives-backlash,Issue,,2024,2024,South Korea,Education,,,AI digital textbooks,Machine learning,Educate students,,Appropriateness/need; Privacy,Students,,,,,,,,,9/26/2024 22:43,https://best-paper-award-ddck.dovetail.com/data/30jcDtyIZpPC2DWy30fRXM#:v:h=1FyghAPFotLQBrzijs0QZR
AIAAIC1137,"The incident raised concerns about the use of underhand methods in Slovakia’s elections, the use of deepfakes in politics, and the ease with which Meta's policies can be bypassed. Because the post was audio, it exploited a loophole in Meta’s manipulated-media policy, which dictates only falsified videos go against its rules.",Cause - Lack of AI control,Cause,Deepfake audio recording claims opposition leaders tried to rig Slovakian election,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-recording-claims-opposition-leaders-tried-to-rig-slovakian-e,Incident,,2023,2023,Slovakia,Politics,,,,Deepfake - audio; Machine learning,Manipulate public opinion,,"Governance, Mis/disinformation",Governance ,,,,,,,,,11/4/2024 15:29,https://best-paper-award-ddck.dovetail.com/data/4HOpZG4cPlifQg0x7ut16v#:v:h=1GKr378UnGIhbJc2Z8lBHd
AIAAIC1480,"Portugal’s data regulator ordered iris-scanning project Worldcoin to halt the collection of biometric data for 90 days due to concerns over citizens’ data protection rights. Worldcoin, a project that combines cryptocurrency and iris scan technology to create a global digital identity system, encourages people to have their faces scanned by its “orb” devices in exchange for a digital ID and free cryptocurrency.  Portugal's National Data Protection Commission (CNPD) received dozens of complaints about the unauthorised collection of data from minors, deficiencies in the information provided to the data subjects, and the impossibility of erasing the data or withdrawing consent. Over 300,000 people in Portugal have reportedly provided Worldcoin with their biometric data. Worldcoin’s data protection officer, Jannick Preiwisch, said that Worldcoin was fully compliant with all laws and regulations governing the collection and transfer of biometric data. The company also mentioned that it began a transition to “Personal Custody” in March, which would give users control over their data, including deletion and any future use. The order to stop data collection is temporary while the CNPD carries out additional due diligence and analyses complaints during an investigation. This is not the first time Worldcoin has faced such a suspension - Spain having issued a similar ban.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Portugal bans Worldcoin for 90 days for jeopardising citizen privacy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/portugal-bans-worldcoin-for-90-days-for-jeopardising-citizen-privacy,Incident,,2024,2024,Portugal,Business/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance; Marketing,Privacy loss,,,,,,,,9/27/2024 0:45,https://best-paper-award-ddck.dovetail.com/data/6z0birFhWjGzBRuatcpmF8#:v:h=1HsXnt1iLT4c5CdY7GOtsZ
AIAAIC1480,"Portugal’s data regulator ordered iris-scanning project Worldcoin to halt the collection of biometric data for 90 days due to concerns over citizens’ data protection rights. Worldcoin, a project that combines cryptocurrency and iris scan technology to create a global digital identity system, encourages people to have their faces scanned by its “orb” devices in exchange for a digital ID and free cryptocurrency.  Portugal's National Data Protection Commission (CNPD) received dozens of complaints about the unauthorised collection of data from minors, deficiencies in the information provided to the data subjects, and the impossibility of erasing the data or withdrawing consent. Over 300,000 people in Portugal have reportedly provided Worldcoin with their biometric data. Worldcoin’s data protection officer, Jannick Preiwisch, said that Worldcoin was fully compliant with all laws and regulations governing the collection and transfer of biometric data. The company also mentioned that it began a transition to “Personal Custody” in March, which would give users control over their data, including deletion and any future use. The order to stop data collection is temporary while the CNPD carries out additional due diligence and analyses complaints during an investigation. This is not the first time Worldcoin has faced such a suspension - Spain having issued a similar ban.",Entity - AI developer company,Responsible Entities,Portugal bans Worldcoin for 90 days for jeopardising citizen privacy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/portugal-bans-worldcoin-for-90-days-for-jeopardising-citizen-privacy,Incident,,2024,2024,Portugal,Business/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance; Marketing,Privacy loss,,,,,,,,9/27/2024 0:45,https://best-paper-award-ddck.dovetail.com/data/6z0birFhWjGzBRuatcpmF8#:v:h=1HsXnt1iLT4c5CdY7GOtsZ
AIAAIC1480,"Portugal’s data regulator ordered iris-scanning project Worldcoin to halt the collection of biometric data for 90 days due to concerns over citizens’ data protection rights. Worldcoin, a project that combines cryptocurrency and iris scan technology to create a global digital identity system, encourages people to have their faces scanned by its “orb” devices in exchange for a digital ID and free cryptocurrency.  Portugal's National Data Protection Commission (CNPD) received dozens of complaints about the unauthorised collection of data from minors, deficiencies in the information provided to the data subjects, and the impossibility of erasing the data or withdrawing consent. Over 300,000 people in Portugal have reportedly provided Worldcoin with their biometric data. Worldcoin’s data protection officer, Jannick Preiwisch, said that Worldcoin was fully compliant with all laws and regulations governing the collection and transfer of biometric data. The company also mentioned that it began a transition to “Personal Custody” in March, which would give users control over their data, including deletion and any future use. The order to stop data collection is temporary while the CNPD carries out additional due diligence and analyses complaints during an investigation. This is not the first time Worldcoin has faced such a suspension - Spain having issued a similar ban.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Portugal bans Worldcoin for 90 days for jeopardising citizen privacy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/portugal-bans-worldcoin-for-90-days-for-jeopardising-citizen-privacy,Incident,,2024,2024,Portugal,Business/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance; Marketing,Privacy loss,,,,,,,,9/27/2024 0:45,https://best-paper-award-ddck.dovetail.com/data/6z0birFhWjGzBRuatcpmF8#:v:h=1HsXnt1iLT4c5CdY7GOtsZ
AIAAIC1408,g a series of complaints about the manner in which the company was collecting sensitive data from users. ,Cause - organization/human cause - lack of informed consent & transparency,Cause,South Korea privacy watchdog investigates Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korea-privacy-watchdog-investigates-worldcoin,Incident,2023,2024,2024,South Korea,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,,Regulatory investigation,,10/4/2024 13:57,https://best-paper-award-ddck.dovetail.com/data/55eJ2S2Wo63yynNtTqwMwz#:v:h=1KoivUMp8nifSjBmmhZAP4
AIAAIC1239,"Amazon employees expressed concerns about a variety of issues regarding Q, including that it has been 'experiencing severe hallucinations and leaking confidential data,' including the location of AWS data centers, internal discount programs, according to The Platformer, citing leaked Amazon documents.",Entity - AI developer company,Responsible Entities,"Amazon Q hallucinates, leaks data",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-q-hallucinates-leaks-data,Issue,2023,2023,2023,USA,Business/professional services,Casey Newton; Zoe Schiffler,Amazon,Amazon Q,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Media investigation,Accuracy/reliability; Confidentiality; Privacy,Governance,,Confidentiality loss,,,,,,,10/6/2024 23:42,https://best-paper-award-ddck.dovetail.com/data/6qdPVS8qLWNLyJwXajPT1d#:v:h=1NumJIvwpoMpJreru6j81E
AIAAIC1021,"AI-cloned songs in the name and voice of retired Singapore-based Mandopop singer Stefanie Sun went viral in China, raising questions about copyright and jobs in the music industry. Generated using so-vits-svc fork, an open source software that enables anyone to train their own AI model to speak in any voice and language, the videos, dubbed AI Stefanie Sun (AI孙燕姿), went viral on China's most popular video platform Bilibili and other platforms.  Fans and commentators reported it was difficult to distinguish between songs sung by Sun and her virtual version, and lamented her loss of copyright. By contrast, Sun, who had not released an album since 2017, responded primarily by lamenting AI's impact on jobs:  'Whether it is ChatGPT or AI or whatever name you want to call it, this ""thing"" is now capable of mimicking and/or conjuring,  unique and complicated content by processing a gazillion chunks of information while piecing and putting together in a most coherent manner the task being asked at hand. Wait a minute, isn't that what humans do? The very task that we have always convinced ourselves; that the formation of thought or opinion is not replicable by robots, the very idea that this is beyond their league, is now the looming thing that will threaten thousands of human conjured jobs. Legal, medical, accountancy, and currently, singing a song.'",Entity - no specific info,Responsible Entities,AI-cloned Stefanie Sun songs go viral in China,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-stefanie-sun,Incident,,2023,2023,China; Singapore,Media/entertainment/sports/arts,Bilibili; Kuaishou; QQ Music,,Sovits,"Deepfake - audio, image, video; Machine learning",Generate music,Product demonstration/release/launch,Copyright; Employment - jobs,Governance; Marketing,Loss of rights/freedoms,IP/copyright loss,,,,,,,10/30/2024 17:30,https://best-paper-award-ddck.dovetail.com/data/2waMD9tjVvacPZvAKbAyso#:v:h=1O36wntoXU1Fn4lD4ZllYH
AIAAIC1409,Argentina's privacy regulator the Agency for Access to Public Information (AAIP) opened an investigation into Worldcoin's data collection practices.,Entity - large dataset organization,Responsible Entities,Argentina opens investigation into Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/argentina-opens-investigation-into-worldcoin,Incident,2023,2023,2023,Argentina,Business/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,,Regulatory investigation,,10/2/2024 15:50,https://best-paper-award-ddck.dovetail.com/data/1C510OQS5oCPh20zXjb4oz#:v:h=1PfP0NTny1z2KZJYX6ai2p
AIAAIC1477,"Reddit warned AI companies against using data from its platform for commercial purposes without permission. According to Reddit COO Jen Wong, AI firms should not scrape data on the company’s platform use without consent. She went on to say that, given the AI industry's appetite for data to train its models, Reddit believes there is commercial value which can be unlocked through licensing.  Wong’s intervention highlighted broader concerns about the use and misuse of data for commercial purposes, and raised ethical questions about the consent of platform users, who typically are unaware that their data is made available to third-parties on a commercial basis and is scraped by third-parties to train their models.  The AI industry is known to widely use data scraping to train its models. ChatGPT, Stable Diffusion, Midjourney and other products are subject to numerous class-action lawsuits relating to alleged data theft and copyright abuse.",Entity - AI developer company,Responsible Entities,Reddit warns AI companies not to misuse its data ,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/reddit-warns-ai-companies-not-to-misuse-its-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,OpenAI; StabilityAI; Midjourney,,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis;,Multiple technologies using data scraping,Industry complaint,Copyright; Privacy,Governance,Copyright loss; Privacy,,,Reputational damage,,,,,9/27/2024 0:50,https://best-paper-award-ddck.dovetail.com/data/4pOxntsOm2fQHCGFF1mSbf#:v:h=1PysLCMo27DAWptGxmCwjG
AIAAIC1477,"Reddit warned AI companies against using data from its platform for commercial purposes without permission. According to Reddit COO Jen Wong, AI firms should not scrape data on the company’s platform use without consent. She went on to say that, given the AI industry's appetite for data to train its models, Reddit believes there is commercial value which can be unlocked through licensing.  Wong’s intervention highlighted broader concerns about the use and misuse of data for commercial purposes, and raised ethical questions about the consent of platform users, who typically are unaware that their data is made available to third-parties on a commercial basis and is scraped by third-parties to train their models.  The AI industry is known to widely use data scraping to train its models. ChatGPT, Stable Diffusion, Midjourney and other products are subject to numerous class-action lawsuits relating to alleged data theft and copyright abuse.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Reddit warns AI companies not to misuse its data ,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/reddit-warns-ai-companies-not-to-misuse-its-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,OpenAI; StabilityAI; Midjourney,,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis;,Multiple technologies using data scraping,Industry complaint,Copyright; Privacy,Governance,Copyright loss; Privacy,,,Reputational damage,,,,,9/27/2024 0:50,https://best-paper-award-ddck.dovetail.com/data/4pOxntsOm2fQHCGFF1mSbf#:v:h=1PysLCMo27DAWptGxmCwjG
AIAAIC1477,"Reddit warned AI companies against using data from its platform for commercial purposes without permission. According to Reddit COO Jen Wong, AI firms should not scrape data on the company’s platform use without consent. She went on to say that, given the AI industry's appetite for data to train its models, Reddit believes there is commercial value which can be unlocked through licensing.  Wong’s intervention highlighted broader concerns about the use and misuse of data for commercial purposes, and raised ethical questions about the consent of platform users, who typically are unaware that their data is made available to third-parties on a commercial basis and is scraped by third-parties to train their models.  The AI industry is known to widely use data scraping to train its models. ChatGPT, Stable Diffusion, Midjourney and other products are subject to numerous class-action lawsuits relating to alleged data theft and copyright abuse.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Reddit warns AI companies not to misuse its data ,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/reddit-warns-ai-companies-not-to-misuse-its-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,OpenAI; StabilityAI; Midjourney,,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis;,Multiple technologies using data scraping,Industry complaint,Copyright; Privacy,Governance,Copyright loss; Privacy,,,Reputational damage,,,,,9/27/2024 0:50,https://best-paper-award-ddck.dovetail.com/data/4pOxntsOm2fQHCGFF1mSbf#:v:h=1PysLCMo27DAWptGxmCwjG
AIAAIC1215,"In a statement, Japan's Personal Information Protection Commission said that OpenAI should minimise the sensitive data it collects for training the models that underpin ChatGPT and other systems, adding it may take further action if it had additional concerns.  The regulator also noted the need to balance privacy concerns with the potential benefits of generative AI, including accelerating innovation and dealing with problems such as climate change.",Entity - AI developer company,Responsible Entities,Japan warns OpenAI over ChatGPT AI training,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/japan-warns-openai-over-chatgpt-ai-training,Incident,2022,2023,2023,Japan,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory warning,Privacy,Governance; Privacy,Privacy loss,,,,,,Regulatory warning,,10/6/2024 23:59,https://best-paper-award-ddck.dovetail.com/data/3FjEsGNiaZA12mL4H26lVq#:v:h=1PHlftnaJ2NgYQTNOLuQnC
AIAAIC1452,"Solomon said she saw an image on a phone they had been looking at that appeared to be of a Māori woman wearing a cap, and that she she felt 'racially discriminated' against and embarrassed during the 'horrible' incident, which took place on her birthday.",Cause - AI causes - potential AI bias (racism - inequality) ,Cause,Maori woman misidentified by Foodstuffs facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maori-woman-misidentified-by-foodstuffs-facial-recognition,Incident,,2024,2024,New Zealand,Retail,Foodstuffs,,,Facial recognition,Strengthen security,User comments/complaints,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance,Anxiety/distress; Discrimination,Privacy loss,,,,,,,10/2/2024 13:43,https://best-paper-award-ddck.dovetail.com/data/5EmDnTMZeDZBnXvKlld52n#:v:h=1QcGNMBo8zqD0pBHuZjA9o
AIAAIC1325,"According to France's National Commission on Informatics and Liberty (CNIL), 'the implementation of a system measuring interruptions of activity so precisely and leading to the employee potentially having to justify each break or interruption was illegal' and had breached the EU's GDPR principle of data minimisation and the lawfulness of the processing.",Cause - organization causes - legal non-compliance,Cause,Amazon France fined for excessive automated monitoring of workers,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-france-fined-for-excessive-automated-monitoring-of-workers,Incident,,2020,2024,France,Transport/logistics,Amazon France Logistique,Amazon France,"Stow Machine Gun indicator; Idle Time indicator, Latency under ten minutes indicator",Handheld scanner,Monitor employee performance,Regulatory inquiry/investigation,Employment; Necessity/proportionality; Privacy,Governance; Marketing,Privacy loss,,,,,EUR 32 million fine,Regulatory investigation,,10/4/2024 14:14,https://best-paper-award-ddck.dovetail.com/data/5XKzZRCbZ9Dzw1Zm8U8bJ1#:v:h=1R2Bh0yorFMrVnIjzObTTl
AIAAIC1541,"News that Meta is to train its generative AI models on content from Facebook and Instagram users sparked criticism from digital rights groups, users and content creators.  Meta informed UK and European users of changes to its privacy policy that would enable it to train its AI models on their posts, images, image captions and comments. The European Center for Digital Rights, Noyb, filed complaints in eleven European countries arguing that Meta’s plan would constitute an abuse of personal data and a breach of privacy.  Noyb also criticised Meta for using “dark patterns” in user experience design to make opting out of data collection difficult, and that the policy would allow the company to use all public and non-public user data collected since 2007 for any undefined type of current and future AI technology. Internationally, Meta has been criticised for offering different protections for EU and UK citizens than the rest of the world. Meta argued that the data collection is necessary to train AI services that reflect the diverse cultures and languages of the European communities who will use them.  In response to the pressure, Meta reversed the decision following an objection from the Irish Data Protection Commission.  ➕ July 2024. UK data rights campaign orgnisation Open Rights Group filed a complaint with the UK Information Commissioner's Office (ICO) arguing that Meta' AI policy has no “legitimate interest” under GDPR.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Meta under fire for decision to train generative AI on user content,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-under-fire-for-decision-to-train-generative-ai-on-user-content,Issue,,2024,2024,Global,Technology,Meta,Meta,Multiple,Generative AI; Machine learning; Neural network; Deep learning,Generate text; Generate Images,User comments/complaints,Privacy,Governance,,,,,,,,,9/27/2024 0:07,https://best-paper-award-ddck.dovetail.com/data/6PIwoFXE3elAV2ituHs2Yo#:v:h=1SzNjVTpQhaz4yIdtHZoof
AIAAIC1541,"News that Meta is to train its generative AI models on content from Facebook and Instagram users sparked criticism from digital rights groups, users and content creators.  Meta informed UK and European users of changes to its privacy policy that would enable it to train its AI models on their posts, images, image captions and comments. The European Center for Digital Rights, Noyb, filed complaints in eleven European countries arguing that Meta’s plan would constitute an abuse of personal data and a breach of privacy.  Noyb also criticised Meta for using “dark patterns” in user experience design to make opting out of data collection difficult, and that the policy would allow the company to use all public and non-public user data collected since 2007 for any undefined type of current and future AI technology. Internationally, Meta has been criticised for offering different protections for EU and UK citizens than the rest of the world. Meta argued that the data collection is necessary to train AI services that reflect the diverse cultures and languages of the European communities who will use them.  In response to the pressure, Meta reversed the decision following an objection from the Irish Data Protection Commission.  ➕ July 2024. UK data rights campaign orgnisation Open Rights Group filed a complaint with the UK Information Commissioner's Office (ICO) arguing that Meta' AI policy has no “legitimate interest” under GDPR.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Meta under fire for decision to train generative AI on user content,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-under-fire-for-decision-to-train-generative-ai-on-user-content,Issue,,2024,2024,Global,Technology,Meta,Meta,Multiple,Generative AI; Machine learning; Neural network; Deep learning,Generate text; Generate Images,User comments/complaints,Privacy,Governance,,,,,,,,,9/27/2024 0:07,https://best-paper-award-ddck.dovetail.com/data/6PIwoFXE3elAV2ituHs2Yo#:v:h=1SzNjVTpQhaz4yIdtHZoof
AIAAIC1541,"News that Meta is to train its generative AI models on content from Facebook and Instagram users sparked criticism from digital rights groups, users and content creators.  Meta informed UK and European users of changes to its privacy policy that would enable it to train its AI models on their posts, images, image captions and comments. The European Center for Digital Rights, Noyb, filed complaints in eleven European countries arguing that Meta’s plan would constitute an abuse of personal data and a breach of privacy.  Noyb also criticised Meta for using “dark patterns” in user experience design to make opting out of data collection difficult, and that the policy would allow the company to use all public and non-public user data collected since 2007 for any undefined type of current and future AI technology. Internationally, Meta has been criticised for offering different protections for EU and UK citizens than the rest of the world. Meta argued that the data collection is necessary to train AI services that reflect the diverse cultures and languages of the European communities who will use them.  In response to the pressure, Meta reversed the decision following an objection from the Irish Data Protection Commission.  ➕ July 2024. UK data rights campaign orgnisation Open Rights Group filed a complaint with the UK Information Commissioner's Office (ICO) arguing that Meta' AI policy has no “legitimate interest” under GDPR.",Entity - AI developer company,Responsible Entities,Meta under fire for decision to train generative AI on user content,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-under-fire-for-decision-to-train-generative-ai-on-user-content,Issue,,2024,2024,Global,Technology,Meta,Meta,Multiple,Generative AI; Machine learning; Neural network; Deep learning,Generate text; Generate Images,User comments/complaints,Privacy,Governance,,,,,,,,,9/27/2024 0:07,https://best-paper-award-ddck.dovetail.com/data/6PIwoFXE3elAV2ituHs2Yo#:v:h=1SzNjVTpQhaz4yIdtHZoof
AIAAIC1375,"HeyGen's use and moderation policy states that users cannot generate avatars that 'represent real individuals, including celebrities or public figures, without explicit consent.'",Incident - human-driven - bypassing AI safeguards,Incident Type,Cloned Ukrainian YouTuber promotes Russia-China relations,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ukrainian-youtuber-cloned-to-promote-russia-china-relations,Incident,2020,2024,2024,China; Ukraine,Media/entertainment/sports/arts; Politics,,HeyGen,HeyGen,Deepfake - video; Machine learning,Promote Russia-China relations,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,Anxiety/distress/depression,,,,,,,,10/24/2024 23:03,https://best-paper-award-ddck.dovetail.com/data/1gam1nQCnCihSWkBQwgEHE#:v:h=1SXyvZaljxm16jbNJy58UG
AIAAIC1761,"Images and videos processed and analysed through Ray-Ban Meta smart glasses are being used to train Meta's AI systems, prompting concerns that users may inadvertently be sharing sensitive information with the technology company.",Cause - organization/human cause - lack of informed consent & transparency,Cause,"Meta trains AI on Ray-Ban smart glass photos, videos",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-trains-ai-on-ray-ban-meta-smart-glass-photos-videos,Issue,2021,2024,2024,Canada; USA,Multiple,Meta; EssilorLuxottica,Meta; EssilorLuxottica,Ray-Ban Meta Smart Glasses,Computer vision; Smart glasses; Virtual reality,"Capture images, photos",Media investigation,Confidentiality; Ethics/values; Privacy,Governance,Confidentality loss; Privacy loss,,,,,,,,11/4/2024 16:54,https://best-paper-award-ddck.dovetail.com/data/2xk4g6lrvYcqf35MaBciEi#:v:h=1Tv7WKP3KOtMewE9k87Kzh
AIAAIC1761,"Images and videos processed and analysed through Ray-Ban Meta smart glasses are being used to train Meta's AI systems, prompting concerns that users may inadvertently be sharing sensitive information with the technology company.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,"Meta trains AI on Ray-Ban smart glass photos, videos",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-trains-ai-on-ray-ban-meta-smart-glass-photos-videos,Issue,2021,2024,2024,Canada; USA,Multiple,Meta; EssilorLuxottica,Meta; EssilorLuxottica,Ray-Ban Meta Smart Glasses,Computer vision; Smart glasses; Virtual reality,"Capture images, photos",Media investigation,Confidentiality; Ethics/values; Privacy,Governance,Confidentality loss; Privacy loss,,,,,,,,11/4/2024 16:54,https://best-paper-award-ddck.dovetail.com/data/2xk4g6lrvYcqf35MaBciEi#:v:h=1Tv7WKP3KOtMewE9k87Kzh
AIAAIC1394,"Domino's has been sued for allegedly collecting voice prints using its AI ordering system without customer consent, violating the Illinois Biometric Information Privacy Act (BIPA).",Cause - organization causes - legal non-compliance,Cause,Domino's sued for AI phone-order voice print collection,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dominos-sued-for-ai-phone-order-voice-print-collection,Incident,2020,2024,2024,USA,Travel/hospitality,Domino's Pizza,ConverseNow Technologies,,Voice recognition,Improve customer service; Increase sales,Lawsuit filing/litigation,Privacy,Governance,,Privacy loss,,,,,Litigation,,10/2/2024 19:18,https://best-paper-award-ddck.dovetail.com/data/3QelX2mpbB4BZrQs1Bf7Us#:v:h=1UMkvY91ZaVq60rB1cGs1d
AIAAIC1394,"Domino's has been sued for allegedly collecting voice prints using its AI ordering system without customer consent, violating the Illinois Biometric Information Privacy Act (BIPA).",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Domino's sued for AI phone-order voice print collection,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dominos-sued-for-ai-phone-order-voice-print-collection,Incident,2020,2024,2024,USA,Travel/hospitality,Domino's Pizza,ConverseNow Technologies,,Voice recognition,Improve customer service; Increase sales,Lawsuit filing/litigation,Privacy,Governance,,Privacy loss,,,,,Litigation,,10/2/2024 19:18,https://best-paper-award-ddck.dovetail.com/data/3QelX2mpbB4BZrQs1Bf7Us#:v:h=1UMkvY91ZaVq60rB1cGs1d
AIAAIC1394,"Domino's has been sued for allegedly collecting voice prints using its AI ordering system without customer consent, violating the Illinois Biometric Information Privacy Act (BIPA).",Cause - organization/human cause - lack of informed consent & transparency,Cause,Domino's sued for AI phone-order voice print collection,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dominos-sued-for-ai-phone-order-voice-print-collection,Incident,2020,2024,2024,USA,Travel/hospitality,Domino's Pizza,ConverseNow Technologies,,Voice recognition,Improve customer service; Increase sales,Lawsuit filing/litigation,Privacy,Governance,,Privacy loss,,,,,Litigation,,10/2/2024 19:18,https://best-paper-award-ddck.dovetail.com/data/3QelX2mpbB4BZrQs1Bf7Us#:v:h=1UMkvY91ZaVq60rB1cGs1d
AIAAIC1394,"Domino's has been sued for allegedly collecting voice prints using its AI ordering system without customer consent, violating the Illinois Biometric Information Privacy Act (BIPA).",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Domino's sued for AI phone-order voice print collection,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dominos-sued-for-ai-phone-order-voice-print-collection,Incident,2020,2024,2024,USA,Travel/hospitality,Domino's Pizza,ConverseNow Technologies,,Voice recognition,Improve customer service; Increase sales,Lawsuit filing/litigation,Privacy,Governance,,Privacy loss,,,,,Litigation,,10/2/2024 19:18,https://best-paper-award-ddck.dovetail.com/data/3QelX2mpbB4BZrQs1Bf7Us#:v:h=1UMkvY91ZaVq60rB1cGs1d
AIAAIC1288,"A fraud detection system developed by Thomson Reuters generated false fraud alerts, leaving hundreds of thousands of legitimate claimants without access to public benefits, according to a legal complaint. ",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Thomson Reuters Fraud Detect 'incorrectly' identifies fraud,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/thomson-reuters-fraud-detect-incorrectly-identifies-fraud,Incident,,2023,2023,USA,Govt - welfare,California Employment Development Department; Iowa Workforce Development,Thomson Reuters,Fraud Detect,Risk assessment algorithm; Machine learning,Detect and prevent fraud,NGO complaint,Accuracy/reliability; Privacy,Governance; Black box,Financial loss; Privacy loss,,,,,,Legal complaint,,10/4/2024 14:30,https://best-paper-award-ddck.dovetail.com/data/4ctLmr72kOOhxS3GwdqI3T#:v:h=1VIiDGHXmFCxySr4JOrraO
AIAAIC1114,"Employees at Amazon Ring and a Ukrainian contractor were able to access and download customer videos and use them however they liked. The discovery prompted accusations of privacy abuse and incurred a USD 5.8 million fine. According (pdf) to the US Federal Trade Commisson (FTC), Amazon’s Ring doorbell unit violated a section of the FTC Act that prohibits unfair or deceptive business practices, with some of its people viewing thousands of videos of female users in their bedrooms and bathrooms until Ring restricted employee access to customer videos in September 2017.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Amazon employees use Ring to spy on customers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-employees-use-ring-to-spy-on-customers,Incident,,2023,2023,USA,Consumer goods,,Amazon/Ring,Ring,CCTV; Computer vision,Strengthen security,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,USD 5.8m fine,Regulatory investigation; Litigation,,10/7/2024 0:54,https://best-paper-award-ddck.dovetail.com/data/5MMZawcrIL6lDDDf5RYPB1#:v:h=1VTB4Q5CYXUeSZeOQhYPlc
AIAAIC1114,"Employees at Amazon Ring and a Ukrainian contractor were able to access and download customer videos and use them however they liked. The discovery prompted accusations of privacy abuse and incurred a USD 5.8 million fine. According (pdf) to the US Federal Trade Commisson (FTC), Amazon’s Ring doorbell unit violated a section of the FTC Act that prohibits unfair or deceptive business practices, with some of its people viewing thousands of videos of female users in their bedrooms and bathrooms until Ring restricted employee access to customer videos in September 2017.",Entity - AI developer company,Responsible Entities,Amazon employees use Ring to spy on customers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-employees-use-ring-to-spy-on-customers,Incident,,2023,2023,USA,Consumer goods,,Amazon/Ring,Ring,CCTV; Computer vision,Strengthen security,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,USD 5.8m fine,Regulatory investigation; Litigation,,10/7/2024 0:54,https://best-paper-award-ddck.dovetail.com/data/5MMZawcrIL6lDDDf5RYPB1#:v:h=1VTB4Q5CYXUeSZeOQhYPlc
AIAAIC1114,"Employees at Amazon Ring and a Ukrainian contractor were able to access and download customer videos and use them however they liked. The discovery prompted accusations of privacy abuse and incurred a USD 5.8 million fine. According (pdf) to the US Federal Trade Commisson (FTC), Amazon’s Ring doorbell unit violated a section of the FTC Act that prohibits unfair or deceptive business practices, with some of its people viewing thousands of videos of female users in their bedrooms and bathrooms until Ring restricted employee access to customer videos in September 2017.",Cause - Human causes - employee internal threats,Cause,Amazon employees use Ring to spy on customers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-employees-use-ring-to-spy-on-customers,Incident,,2023,2023,USA,Consumer goods,,Amazon/Ring,Ring,CCTV; Computer vision,Strengthen security,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,USD 5.8m fine,Regulatory investigation; Litigation,,10/7/2024 0:54,https://best-paper-award-ddck.dovetail.com/data/5MMZawcrIL6lDDDf5RYPB1#:v:h=1VTB4Q5CYXUeSZeOQhYPlc
AIAAIC1114,"Employees at Amazon Ring and a Ukrainian contractor were able to access and download customer videos and use them however they liked. The discovery prompted accusations of privacy abuse and incurred a USD 5.8 million fine. According (pdf) to the US Federal Trade Commisson (FTC), Amazon’s Ring doorbell unit violated a section of the FTC Act that prohibits unfair or deceptive business practices, with some of its people viewing thousands of videos of female users in their bedrooms and bathrooms until Ring restricted employee access to customer videos in September 2017.",Cause - organization causes - legal non-compliance,Cause,Amazon employees use Ring to spy on customers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-employees-use-ring-to-spy-on-customers,Incident,,2023,2023,USA,Consumer goods,,Amazon/Ring,Ring,CCTV; Computer vision,Strengthen security,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,USD 5.8m fine,Regulatory investigation; Litigation,,10/7/2024 0:54,https://best-paper-award-ddck.dovetail.com/data/5MMZawcrIL6lDDDf5RYPB1#:v:h=1VTB4Q5CYXUeSZeOQhYPlc
AIAAIC1114,"Employees at Amazon Ring and a Ukrainian contractor were able to access and download customer videos and use them however they liked. The discovery prompted accusations of privacy abuse and incurred a USD 5.8 million fine. According (pdf) to the US Federal Trade Commisson (FTC), Amazon’s Ring doorbell unit violated a section of the FTC Act that prohibits unfair or deceptive business practices, with some of its people viewing thousands of videos of female users in their bedrooms and bathrooms until Ring restricted employee access to customer videos in September 2017.",Incident - AI-driven - AI data breach,Incident Type,Amazon employees use Ring to spy on customers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-employees-use-ring-to-spy-on-customers,Incident,,2023,2023,USA,Consumer goods,,Amazon/Ring,Ring,CCTV; Computer vision,Strengthen security,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,USD 5.8m fine,Regulatory investigation; Litigation,,10/7/2024 0:54,https://best-paper-award-ddck.dovetail.com/data/5MMZawcrIL6lDDDf5RYPB1#:v:h=1VTB4Q5CYXUeSZeOQhYPlc
AIAAIC1114,"Employees at Amazon Ring and a Ukrainian contractor were able to access and download customer videos and use them however they liked. The discovery prompted accusations of privacy abuse and incurred a USD 5.8 million fine. According (pdf) to the US Federal Trade Commisson (FTC), Amazon’s Ring doorbell unit violated a section of the FTC Act that prohibits unfair or deceptive business practices, with some of its people viewing thousands of videos of female users in their bedrooms and bathrooms until Ring restricted employee access to customer videos in September 2017.",Entity - malicious human,Responsible Entities,Amazon employees use Ring to spy on customers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-employees-use-ring-to-spy-on-customers,Incident,,2023,2023,USA,Consumer goods,,Amazon/Ring,Ring,CCTV; Computer vision,Strengthen security,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,USD 5.8m fine,Regulatory investigation; Litigation,,10/7/2024 0:54,https://best-paper-award-ddck.dovetail.com/data/5MMZawcrIL6lDDDf5RYPB1#:v:h=1VTB4Q5CYXUeSZeOQhYPlc
AIAAIC1179,"And, despite its privacy notice saying it would never share user conversations with advertisers, their behavioural data is 'definitely' being shared and 'possibly sold' to advertisers, the researchers warned.",Cause - organziation causes - vague policy information,Cause,Replika shares user data with advertisers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-replika-fails-to-meet-minimum-privacy-standards,Issue,2017,2023,2023,Global,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Research study/report,Privacy,,,,,,,,,,10/7/2024 0:26,https://best-paper-award-ddck.dovetail.com/data/6Ictyc7kKTXwtfgaowLSph#:v:h=1W5pJCPRiYh2tRj6KnUwlx
AIAAIC1407,Some of the offices had been used to collect iris scans.  The commissioner's office expressed concern Worldcoin's collection and processing of iris scans may violate the Personal Data (Privacy) Ordinance and could potentially involve the abuse of personal information.,Cause - Human causes - Undertrusting AI,Cause,Hong Kong privacy watchdog probes Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hong-kong-privacy-watchdog-probes-worldcoin,Incident,2023,2024,2024,Hong Kong,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance; Marketing,,,,,,,Regulatory investigation,,10/2/2024 16:26,https://best-paper-award-ddck.dovetail.com/data/5mopt5e5T1TOjzmI6drydr#:v:h=1Wma59Bh3qABl4ZNkYEHYS
AIAAIC1162,"In the video, which circulated widely on X, TikTok and Reddit, Thunberg appeared to say to the BBC, 'War's always bad, specifically for the planet. If we want to continue fighting battles like environmentally conscious humans, we must make the change to sustainable tanks and weaponry.'",Cause - Lack of AI control,Cause,Greta Thunberg promotes use of 'vegan grenades',10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greta-thunberg-promotes-use-of-vegan-grenades,Incident,,2023,2023,Sweden,Politics,,Snicklick,,"Deepfake - audio, video; Machine learning",Satarise/parody,Fact check,Mis/disinformation,,Reputational damage,,,,,,,,10/28/2024 16:38,https://best-paper-award-ddck.dovetail.com/data/78Or8CTKr49gQc0kfGND1h#:v:h=1WIuoUwqCoRpJKypATbnW4
AIAAIC1616,"The video was originally created by YouTuber ""Mr. Reagan"", who labeled it as a parody. However, Musk's post to X, which he owns and included the caption ""This is amazing,"" failed to clarify that it was satire, leading to widespread confusion among viewers. Musk's post contravened X's own policies. ",Entity - malicious human,Responsible Entities,Elon Musk shares Kamala Harris voice close video ad,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elon-musk-shares-kamala-harris-voice-clone-video-ad,Issue,,2024,2024,USA,Politics,,,,Deepfake - video; Machine learning,Satirise/parody,,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:10,https://best-paper-award-ddck.dovetail.com/data/7DBPDK65ZBX1OiFoY6lnPh#:v:h=1XVqEE6zXfMIfoml4davbg
AIAAIC1288,"Thomson Reuters unlawfully acquired data, including from social media, and used 'harmful AI practices' to build and operate Fraud Detect, ",Cause - organization causes - legal non-compliance,Cause,Thomson Reuters Fraud Detect 'incorrectly' identifies fraud,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/thomson-reuters-fraud-detect-incorrectly-identifies-fraud,Incident,,2023,2023,USA,Govt - welfare,California Employment Development Department; Iowa Workforce Development,Thomson Reuters,Fraud Detect,Risk assessment algorithm; Machine learning,Detect and prevent fraud,NGO complaint,Accuracy/reliability; Privacy,Governance; Black box,Financial loss; Privacy loss,,,,,,Legal complaint,,10/2/2024 21:21,https://best-paper-award-ddck.dovetail.com/data/4ctLmr72kOOhxS3GwdqI3T#:v:h=1YgKpVS1oBy2SfwmfohnLh
AIAAIC1141,"A deepfake audio recording appearing to depict the leader of the UK Labour Party, Sir Keir Starmer, swearing at a party staffer raised concerns about the underhand use of synthetic disinformation in politics.",Entity - no specific info,Responsible Entities,Deepfake recordings depict British Opposition Leader abusing staff,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-recording-depicts-british-opposition-leader-abusing-staff,Incident,,2023,2023,UK,Politics,,,,"Deepfake - audio, video; Machine learning",Damage reputation,,Mis/disinformation,Governance; Marketing,,,,,,,,,10/30/2024 16:23,https://best-paper-award-ddck.dovetail.com/data/1jYlQ4n7SApAMW0EA4pU9h#:v:h=1ZR12uxr1MxqnX25pWJNrQ
AIAAIC1141,"A deepfake audio recording appearing to depict the leader of the UK Labour Party, Sir Keir Starmer, swearing at a party staffer raised concerns about the underhand use of synthetic disinformation in politics.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake recordings depict British Opposition Leader abusing staff,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-recording-depicts-british-opposition-leader-abusing-staff,Incident,,2023,2023,UK,Politics,,,,"Deepfake - audio, video; Machine learning",Damage reputation,,Mis/disinformation,Governance; Marketing,,,,,,,,,10/30/2024 16:23,https://best-paper-award-ddck.dovetail.com/data/1jYlQ4n7SApAMW0EA4pU9h#:v:h=1ZR12uxr1MxqnX25pWJNrQ
AIAAIC0982,"On the basis of Reuters' findings, California Tesla owner Henry Yeh lodged a class-action legal complaint (pdf) against Tesla for the alleged invasion of privacy in customers' homes and vehicles, negligence, breach of contract, negligent misrepresentation, intentional misrepresentation, and unjust enrichment.",Entity - AI developer company,Responsible Entities,Tesla workers share private camera recordings,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/tesla-workers-share-private-camera-recordings,Incident,2014,2023,2023,USA,Automotive,Multiple,Tesla,Autopilot,Driver assistance system; Computer vision,"Automate steering, acceleration, braking",Media investigation,Privacy; Employment,Governance; Marketing; Privacy,Privacy loss,,,,,,Litigation,,10/13/2024 22:24,https://best-paper-award-ddck.dovetail.com/data/3hy3bK3PrErSNkpht99qD1#:v:h=21CdVrtNbcVCEULzect1wv
AIAAIC1116,"The images were processed using ClothOff, a controversial nudifier application available on the web and freely available on the Apple and Android app stores, and distributed on WhatsApp and Telegram.",Entity - AI developer company,Responsible Entities,Almendralejo hit by AI naked child images,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/almendralejo-hit-by-ai-naked-child-images,Incident,,2023,2023,Spain,Education,Almendralejo school students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,User comments/complaints,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,11/4/2024 15:39,https://best-paper-award-ddck.dovetail.com/data/4G66AFtrhBoT2nlNuhdSiM#:v:h=22ybWU9IXLEjd7cjXJBur2
AIAAIC0948,"The German Federal Constitutional Court ruled the use of Palantir surveillance software by police in Hesse and Hamburg as unconstitutional, in a case bought by German civil rights NGO Gesellschaft für Freiheitsrechte (GFF).",Entity - government authorities that adopt AI,Responsible Entities,Hesse state Palantir predictive policing ruled 'unconstitutional',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hesse-palantir-predictive-policing,Incident,,2023,2023,Germany,Govt - police,Hesse State Police,Palantir,Hessendata; Gotham,Prediction algorithm,Predict crime,Lawsuit filing/litigation,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance; Black box,,Unconstitutional,,,Product ban,,Litigation,,10/13/2024 22:31,https://best-paper-award-ddck.dovetail.com/data/7u0NT2v9zlyvmGEXg8vJKl#:v:h=23ulWWGTuRVGbjAHs1UX4i
AIAAIC1254,"Krupski later told the BBC that he felt the carmaker's Autopilot driver assistance system was not safe for public roads, with other drivers, passengers, and pedestrians at risk. He also said that his colleagues had discussed Tesla vehicles randomly braking in response to non-existent obstacles, a phenonomen known as 'phantom braking', with some incidents resulting in crashes with oncoming traffic",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Whistleblower reveals Tesla phantom braking complaints,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/whistleblower-reveals-tesla-phantom-braking-complaints,Incident,2014,2023,2023,Netherlands; Germany,Automotive,Lukasz Krupski,Tesla,Autopilot,Driver assistance system,"Automate steering, acceleration, braking",Data leak; Whistleblower,Confidentiality; Privacy; Safety; Security,Governance,Privacy loss; Confidentiality loss,,,,,,Regulatory investigation,,10/2/2024 21:25,https://best-paper-award-ddck.dovetail.com/data/4DasqRusymkPLKKFZIW8MS#:v:h=24bb3jiSqoOV1WmwPxk7hn
AIAAIC1254,"Krupski later told the BBC that he felt the carmaker's Autopilot driver assistance system was not safe for public roads, with other drivers, passengers, and pedestrians at risk. He also said that his colleagues had discussed Tesla vehicles randomly braking in response to non-existent obstacles, a phenonomen known as 'phantom braking', with some incidents resulting in crashes with oncoming traffic",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Whistleblower reveals Tesla phantom braking complaints,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/whistleblower-reveals-tesla-phantom-braking-complaints,Incident,2014,2023,2023,Netherlands; Germany,Automotive,Lukasz Krupski,Tesla,Autopilot,Driver assistance system,"Automate steering, acceleration, braking",Data leak; Whistleblower,Confidentiality; Privacy; Safety; Security,Governance,Privacy loss; Confidentiality loss,,,,,,Regulatory investigation,,10/2/2024 21:25,https://best-paper-award-ddck.dovetail.com/data/4DasqRusymkPLKKFZIW8MS#:v:h=24bb3jiSqoOV1WmwPxk7hn
AIAAIC1254,"Krupski later told the BBC that he felt the carmaker's Autopilot driver assistance system was not safe for public roads, with other drivers, passengers, and pedestrians at risk. He also said that his colleagues had discussed Tesla vehicles randomly braking in response to non-existent obstacles, a phenonomen known as 'phantom braking', with some incidents resulting in crashes with oncoming traffic",Entity - AI developer company,Responsible Entities,Whistleblower reveals Tesla phantom braking complaints,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/whistleblower-reveals-tesla-phantom-braking-complaints,Incident,2014,2023,2023,Netherlands; Germany,Automotive,Lukasz Krupski,Tesla,Autopilot,Driver assistance system,"Automate steering, acceleration, braking",Data leak; Whistleblower,Confidentiality; Privacy; Safety; Security,Governance,Privacy loss; Confidentiality loss,,,,,,Regulatory investigation,,10/2/2024 21:25,https://best-paper-award-ddck.dovetail.com/data/4DasqRusymkPLKKFZIW8MS#:v:h=24bb3jiSqoOV1WmwPxk7hn
AIAAIC1201,"Large language models such as GPT-4 and are able to identify an individual's age, location, gender, and income with up to 85 per cent accuracy by analysing their posts on social media.  ETH Zurich researchers discovered they were able to identify the place of birth, income bracket, gender, and location from information in the profiles or posts of 520 Reddit users using nine large language models.",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,AIs guess where Reddit users live and what they earn,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ais-guess-where-reddit-users-live,Issue,2022,2023,2023,Global,Media/entertainment/sports/arts,Google; Anthropic; Meta; OpenAI,Google; Anthropic; Meta; OpenAI,Claude 2; GPT-4; GPT-3.5; LlaMA-2-7b; PaLM 2 Chat; PaLM 2 Text,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Research study/report,Privacy,Governance,Privacy loss,,,,,,,,10/7/2024 0:08,https://best-paper-award-ddck.dovetail.com/data/M8MXpGjWdB9kyjDk8y1Zg#:v:h=26lNGDhihNgoHQfapo0v2m
AIAAIC1201,"Large language models such as GPT-4 and are able to identify an individual's age, location, gender, and income with up to 85 per cent accuracy by analysing their posts on social media.  ETH Zurich researchers discovered they were able to identify the place of birth, income bracket, gender, and location from information in the profiles or posts of 520 Reddit users using nine large language models.",Entity - AI algorithm,Responsible Entities,AIs guess where Reddit users live and what they earn,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ais-guess-where-reddit-users-live,Issue,2022,2023,2023,Global,Media/entertainment/sports/arts,Google; Anthropic; Meta; OpenAI,Google; Anthropic; Meta; OpenAI,Claude 2; GPT-4; GPT-3.5; LlaMA-2-7b; PaLM 2 Chat; PaLM 2 Text,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Research study/report,Privacy,Governance,Privacy loss,,,,,,,,10/7/2024 0:08,https://best-paper-award-ddck.dovetail.com/data/M8MXpGjWdB9kyjDk8y1Zg#:v:h=26lNGDhihNgoHQfapo0v2m
AIAAIC1201,"Large language models such as GPT-4 and are able to identify an individual's age, location, gender, and income with up to 85 per cent accuracy by analysing their posts on social media.  ETH Zurich researchers discovered they were able to identify the place of birth, income bracket, gender, and location from information in the profiles or posts of 520 Reddit users using nine large language models.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,AIs guess where Reddit users live and what they earn,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ais-guess-where-reddit-users-live,Issue,2022,2023,2023,Global,Media/entertainment/sports/arts,Google; Anthropic; Meta; OpenAI,Google; Anthropic; Meta; OpenAI,Claude 2; GPT-4; GPT-3.5; LlaMA-2-7b; PaLM 2 Chat; PaLM 2 Text,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Research study/report,Privacy,Governance,Privacy loss,,,,,,,,10/7/2024 0:08,https://best-paper-award-ddck.dovetail.com/data/M8MXpGjWdB9kyjDk8y1Zg#:v:h=26lNGDhihNgoHQfapo0v2m
AIAAIC1532,A teenage male was subsequently arrested in relation to the incident and released pending further inquiries.,Cause - Human causes - Human abuse of AI tools,Cause,50 Melbourne school girls targeted using AI nude images,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/50-melbourne-school-girls-targeted-using-ai-nude-images,Incident,,2024,2024,Australia,Education,Bacchus Marsh Grammar students,,,Deepfake - image; Machine learning,,Police statement ,Ethics/values; Safety,Governance; Marketing,,,,,,,,,10/12/2024 1:03,https://best-paper-award-ddck.dovetail.com/data/5gQurSHekkdsAKDznegZ9V#:v:h=28cmJymRH3aKujzTtd9Tsi
AIAAIC1532,A teenage male was subsequently arrested in relation to the incident and released pending further inquiries.,Entity - malicious human,Responsible Entities,50 Melbourne school girls targeted using AI nude images,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/50-melbourne-school-girls-targeted-using-ai-nude-images,Incident,,2024,2024,Australia,Education,Bacchus Marsh Grammar students,,,Deepfake - image; Machine learning,,Police statement ,Ethics/values; Safety,Governance; Marketing,,,,,,,,,10/12/2024 1:03,https://best-paper-award-ddck.dovetail.com/data/5gQurSHekkdsAKDznegZ9V#:v:h=28cmJymRH3aKujzTtd9Tsi
AIAAIC1408,Worldcoin,Entity - AI developer company,Responsible Entities,South Korea privacy watchdog investigates Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korea-privacy-watchdog-investigates-worldcoin,Incident,2023,2024,2024,South Korea,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,,Regulatory investigation,,10/2/2024 15:59,https://best-paper-award-ddck.dovetail.com/data/55eJ2S2Wo63yynNtTqwMwz#:v:h=28wt8jvQDdamufMG9dylRe
AIAAIC1152,"A deepfake audio recording depicting Barack Obama defending himself against a conspiracy theory about the sudden death of his former chef Tafari Campbell was identified as a hoax. The audio recording was identified as a deepfake by misinformation monitoring company NewsGuard, which exposed a network of TikTok accounts posting videos whose baseless claims are often supported solely by narration from AI voices.",Cause - no specific info,Cause,Deepfake audio falsely depicts Barack Obama discussing conspiracy theory,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-falsely-depicts-barack-obama-discussing-conspiracy-theory,Incident,,2023,2023,USA,Politics,,ElevenLabs,ElevenLabs TTS,Deepfake - audio; Machine learning,Damage reputation,Media Investigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/29/2024 23:08,https://best-paper-award-ddck.dovetail.com/data/1LvngziYZmu3HY9bst0zVM#:v:h=29z82EWvP5mAK42FjUKDlD
AIAAIC1152,"A deepfake audio recording depicting Barack Obama defending himself against a conspiracy theory about the sudden death of his former chef Tafari Campbell was identified as a hoax. The audio recording was identified as a deepfake by misinformation monitoring company NewsGuard, which exposed a network of TikTok accounts posting videos whose baseless claims are often supported solely by narration from AI voices.",Entity - no specific info,Responsible Entities,Deepfake audio falsely depicts Barack Obama discussing conspiracy theory,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-falsely-depicts-barack-obama-discussing-conspiracy-theory,Incident,,2023,2023,USA,Politics,,ElevenLabs,ElevenLabs TTS,Deepfake - audio; Machine learning,Damage reputation,Media Investigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/29/2024 23:08,https://best-paper-award-ddck.dovetail.com/data/1LvngziYZmu3HY9bst0zVM#:v:h=29z82EWvP5mAK42FjUKDlD
AIAAIC1152,"A deepfake audio recording depicting Barack Obama defending himself against a conspiracy theory about the sudden death of his former chef Tafari Campbell was identified as a hoax. The audio recording was identified as a deepfake by misinformation monitoring company NewsGuard, which exposed a network of TikTok accounts posting videos whose baseless claims are often supported solely by narration from AI voices.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake audio falsely depicts Barack Obama discussing conspiracy theory,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-falsely-depicts-barack-obama-discussing-conspiracy-theory,Incident,,2023,2023,USA,Politics,,ElevenLabs,ElevenLabs TTS,Deepfake - audio; Machine learning,Damage reputation,Media Investigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/29/2024 23:08,https://best-paper-award-ddck.dovetail.com/data/1LvngziYZmu3HY9bst0zVM#:v:h=29z82EWvP5mAK42FjUKDlD
AIAAIC1193,"An email shared with ABC showed that doctors at Perth's South Metropolitan Health Service (SMHS) had been using software such as ChatGPT to write medical notes which were then being uploaded to patient record systems, thereby potentially compromising patient confidentiality and privacy.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Perth doctors warned for using ChatGPT to write patient medical records,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/perth-doctors-warned-for-using-chatgpt-to-write-patient-medical-records,Issue,2022,2023,2023,Australia,Health,South Metropolitan Health Service,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Write patient records,Company statement,Confidentiality; Privacy,Governance,Confidentiality loss,,,,,,,,10/7/2024 0:18,https://best-paper-award-ddck.dovetail.com/data/6v4ELfD3haz2FLoQkudyuE#:v:h=2bF0JKt0nx3MbHSrk7Z3Y9
AIAAIC1065,"The complaint, which was lodged in Spain in the name of Spanish customer, alleges that Ryanair failed to provide customers with informed or 'comprehensible information about the purpose' of the process, and that it is illegal under the EU's General Data Protection Regulation (GDPR).",Cause - organization/human cause - lack of informed consent & transparency,Cause,Ryanair facial recognition customer verification,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ryanair-uses-facial-recognition-to-verify-customers,Incident,,2023,2023,Spain; EU,Aerospace/defence,Ryanair,,,Facial recognition; Computer vision; Machine learning,Verify customer identity,Legal complaint,Privacy,Privacy,Privacy loss,,,,,,Litigation,,10/7/2024 1:13,https://best-paper-award-ddck.dovetail.com/data/1KYigdpc4kgvDKm1ZMhHEK#:v:h=2cxNYc4ZL7AtLR70yRdJJz
AIAAIC1065,"The complaint, which was lodged in Spain in the name of Spanish customer, alleges that Ryanair failed to provide customers with informed or 'comprehensible information about the purpose' of the process, and that it is illegal under the EU's General Data Protection Regulation (GDPR).",Cause - organization causes - legal non-compliance,Cause,Ryanair facial recognition customer verification,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ryanair-uses-facial-recognition-to-verify-customers,Incident,,2023,2023,Spain; EU,Aerospace/defence,Ryanair,,,Facial recognition; Computer vision; Machine learning,Verify customer identity,Legal complaint,Privacy,Privacy,Privacy loss,,,,,,Litigation,,10/7/2024 1:13,https://best-paper-award-ddck.dovetail.com/data/1KYigdpc4kgvDKm1ZMhHEK#:v:h=2cxNYc4ZL7AtLR70yRdJJz
AIAAIC1162,"A video of Swedish environmental activist Greta Thunberg speaking out about the 2023 Israel-Hamas war in which she called for the use of 'biodegradable missiles' and 'vegan hand grenades' was doctored using artificial intelligence, according to experts.",Entity - no specific info,Responsible Entities,Greta Thunberg promotes use of 'vegan grenades',10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greta-thunberg-promotes-use-of-vegan-grenades,Incident,,2023,2023,Sweden,Politics,,Snicklick,,"Deepfake - audio, video; Machine learning",Satarise/parody,Fact check,Mis/disinformation,,Reputational damage,,,,,,,,10/24/2024 21:09,https://best-paper-award-ddck.dovetail.com/data/78Or8CTKr49gQc0kfGND1h#:v:h=2dy9Jl2B1pd4hXUx0zUrXp
AIAAIC1162,"A video of Swedish environmental activist Greta Thunberg speaking out about the 2023 Israel-Hamas war in which she called for the use of 'biodegradable missiles' and 'vegan hand grenades' was doctored using artificial intelligence, according to experts.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Greta Thunberg promotes use of 'vegan grenades',10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greta-thunberg-promotes-use-of-vegan-grenades,Incident,,2023,2023,Sweden,Politics,,Snicklick,,"Deepfake - audio, video; Machine learning",Satarise/parody,Fact check,Mis/disinformation,,Reputational damage,,,,,,,,10/24/2024 21:09,https://best-paper-award-ddck.dovetail.com/data/78Or8CTKr49gQc0kfGND1h#:v:h=2dy9Jl2B1pd4hXUx0zUrXp
AIAAIC1723,"Many of the applications allow for weak passwords and provide vague privacy policies, and users often remain unaware of how their data is being used or shared, raisingsignificant security concerns, Mozilla discovered.",Cause - organziation causes - vague policy information,Cause,"Report: AI companion apps ""relentlessly"" pry user data",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-ai-companion-apps-relentlessly-pry-user-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,Luka Inc,Anima; Chai; Crushon.AI; EVA AI; Genesia AI; iGirl; Mimico; Replika; Romantic AI; Talkie Soulful AI,Chatbot; Machine learning,Provide companionship,Research study/report,Privacy; Safety; Security,Governance; Privacy,Privacy loss,,,,,,,,9/26/2024 19:50,https://best-paper-award-ddck.dovetail.com/data/5RV9Y6z2RH28SONVePRBet#:v:h=2dAflFoLMS6b2DUmnhqJY5
AIAAIC1235,"Bavaria state commissioner for data protection Thomas Petri said he doubted there is a legal basis for the use of Palantor's software in Bavaria,",Cause - governance causes - legal loophole,Cause,Bavaria tests police AI analytics software using real data,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bavaria-police-test-palantir-using-real-data,Issue,,2023,2023,Germany,Govt - police,Bayerisches Landeskriminalamt,Bayerisches Landeskriminalamt; Palantir,VeRA; Gotham,Data analytics; Machine learning,Identify criminal suspects,Media investigation,Legal; Privacy,Governance; Marketing,Privacy loss,,,,,,,,10/6/2024 23:50,https://best-paper-award-ddck.dovetail.com/data/7yCOzFlowkWHBdgBc4NW1h#:v:h=2eeV6QKI290MgFry9AUbvK
AIAAIC1253,"Facial recognition technology used by US drug chain Rite Aid's accused innocent shoppers of theft, often in a racially discriminatory manner. The retailer failed to impose reasonable precautions in its deployment of facial recognition in hundreds of stores from 2012 to 2020, resulting in thousands of false-positive matches with customers accused of shoplifting and other inappropriate behaviour, according to the US Federal Trade Commission (FTC).  The regulator also said Rite Aid's technology unfairly targeted Black, Hispanic and female customers, was mostly deployed in neighborhoods that were located in 'plurality non-White areas,' and that incidents 'disproportionately' impacting people of colour. Rite Aid’s actions 'subjected consumers to embarrassment, harassment, and other harm', according to the complaint. ",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Rite Aid facial recognition accuses innocent shoppers of theft,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rite-aid-accuses-innocent-shoppers-of-theft,Incident,2013,2023,2023,USA,Retail,Rite Aid,FaceFirst; DeepCam,FaceFirst; DeepCam,Facial recognition,"Reduce crime, violence",Regulatory statement,"Accuracy/reliability; Bias/discrimination - race, ethnicity, income; Privacy; Security",Governance; Marketing,Harassment/abuse; Privacy loss,,,,,,Regulatory investigation,,10/6/2024 23:31,https://best-paper-award-ddck.dovetail.com/data/7mMGU0T2yCqVGMBynNPIP2#:v:h=2eG0PSXzFJ3wPDh5TOGdhJ
AIAAIC1253,"Facial recognition technology used by US drug chain Rite Aid's accused innocent shoppers of theft, often in a racially discriminatory manner. The retailer failed to impose reasonable precautions in its deployment of facial recognition in hundreds of stores from 2012 to 2020, resulting in thousands of false-positive matches with customers accused of shoplifting and other inappropriate behaviour, according to the US Federal Trade Commission (FTC).  The regulator also said Rite Aid's technology unfairly targeted Black, Hispanic and female customers, was mostly deployed in neighborhoods that were located in 'plurality non-White areas,' and that incidents 'disproportionately' impacting people of colour. Rite Aid’s actions 'subjected consumers to embarrassment, harassment, and other harm', according to the complaint. ",Cause - organization causes - lack of AI fail-safe measures,Cause,Rite Aid facial recognition accuses innocent shoppers of theft,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rite-aid-accuses-innocent-shoppers-of-theft,Incident,2013,2023,2023,USA,Retail,Rite Aid,FaceFirst; DeepCam,FaceFirst; DeepCam,Facial recognition,"Reduce crime, violence",Regulatory statement,"Accuracy/reliability; Bias/discrimination - race, ethnicity, income; Privacy; Security",Governance; Marketing,Harassment/abuse; Privacy loss,,,,,,Regulatory investigation,,10/6/2024 23:31,https://best-paper-award-ddck.dovetail.com/data/7mMGU0T2yCqVGMBynNPIP2#:v:h=2eG0PSXzFJ3wPDh5TOGdhJ
AIAAIC1253,"Facial recognition technology used by US drug chain Rite Aid's accused innocent shoppers of theft, often in a racially discriminatory manner. The retailer failed to impose reasonable precautions in its deployment of facial recognition in hundreds of stores from 2012 to 2020, resulting in thousands of false-positive matches with customers accused of shoplifting and other inappropriate behaviour, according to the US Federal Trade Commission (FTC).  The regulator also said Rite Aid's technology unfairly targeted Black, Hispanic and female customers, was mostly deployed in neighborhoods that were located in 'plurality non-White areas,' and that incidents 'disproportionately' impacting people of colour. Rite Aid’s actions 'subjected consumers to embarrassment, harassment, and other harm', according to the complaint. ",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Rite Aid facial recognition accuses innocent shoppers of theft,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rite-aid-accuses-innocent-shoppers-of-theft,Incident,2013,2023,2023,USA,Retail,Rite Aid,FaceFirst; DeepCam,FaceFirst; DeepCam,Facial recognition,"Reduce crime, violence",Regulatory statement,"Accuracy/reliability; Bias/discrimination - race, ethnicity, income; Privacy; Security",Governance; Marketing,Harassment/abuse; Privacy loss,,,,,,Regulatory investigation,,10/6/2024 23:31,https://best-paper-award-ddck.dovetail.com/data/7mMGU0T2yCqVGMBynNPIP2#:v:h=2eG0PSXzFJ3wPDh5TOGdhJ
AIAAIC1723,"collect enormous amounts of personal information, usuallywithout clear user consent. Mozilla researchers also found that almost all examined apps sell user data and share it for targeted advertising, with some using over 24,000 trackers in just one minute of use.",Cause - organization/human cause - lack of informed consent & transparency,Cause,"Report: AI companion apps ""relentlessly"" pry user data",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-ai-companion-apps-relentlessly-pry-user-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,Luka Inc,Anima; Chai; Crushon.AI; EVA AI; Genesia AI; iGirl; Mimico; Replika; Romantic AI; Talkie Soulful AI,Chatbot; Machine learning,Provide companionship,Research study/report,Privacy; Safety; Security,Governance; Privacy,Privacy loss,,,,,,,,9/26/2024 19:49,https://best-paper-award-ddck.dovetail.com/data/5RV9Y6z2RH28SONVePRBet#:v:h=2fB4d2BK2dez4logFgvZDC
AIAAIC1705,"Outabox acknowledged unauthorised access to a client login system and said it is cooperating with law enforcement in the investigation. New South Wales police made anarrest in connection with the breach, suspecting it to be either blackmail or corporate sabotage.",Cause - Human causes - employee internal threats,Cause,Outabox data breach exposes 1m biometric records,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/outabox-data-breach-exposes-1m-biometric-records,Incident,2021,2024,2024,Australia; Philippines; USA,Travel/hospitality,ClubsNSW,Outabox,TriAgem Facial Recognition Kiosk,Facial recognition,Identify bar/club users,Data breach,Privacy,,Privacy loss,,,Reputational damage,,,,,9/26/2024 22:36,https://best-paper-award-ddck.dovetail.com/data/2Vwbe3Qedt3gSMibUMymrw#:v:h=2fYkZufkYjjUYXf7K9MorH
AIAAIC1469,"The complaint further stated that ChatGPT’s “hallucinations” or generation of false information about individuals can have serious consequences, and argued that if a system cannot produce accurate and transparent results, it should not be used to generate data about individuals. ",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,ChatGPT accused of violating GDPR by not correcting inaccurate personal information,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-said-to-violate-gdpr-by-not-correcting-inaccurate-personal-info,Incident,2022,2024,2024,Austria,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot,Generate text,Legal complaint,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 13:17,https://best-paper-award-ddck.dovetail.com/data/6AJcNsz8AZfklQimhDzbDm#:v:h=2gmpczYC5wlsHezrvBYddV
AIAAIC1414,"AI platform Leonardo was accused of letting users easily create explicit, non-consensual images of celebrities. Funded by Samsung, Leonardo is an image generation tool that enables users to use an array of user-generated Stable Diffusion text-to-image AI models, each of which is programmed to generate specific types of images - including the ability to reproduce the appearance of a specific individual. ",Entity - AI developer company,Responsible Entities,Leonardo AI generates celebrity non-consensual porn images,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/leonardo-ai-generates-celebrity-non-consensual-porn-images,Incident,,2024,2024,Global,Media/entertainment/sports/arts,Leonardo AI,Leonardo AI,Leonardo AI,Text-to-image; Machine learning,Generate art,Media investigation,Identity theft/impersonation; Privacy; Safety,Governance,Identity theft/impersonation,,,,,,,,10/2/2024 15:18,https://best-paper-award-ddck.dovetail.com/data/755O5DoMqqfQiSeVyjdqUE#:v:h=2k1KIJCz7hLFYbYjgteVgM
AIAAIC1414,"AI platform Leonardo was accused of letting users easily create explicit, non-consensual images of celebrities. Funded by Samsung, Leonardo is an image generation tool that enables users to use an array of user-generated Stable Diffusion text-to-image AI models, each of which is programmed to generate specific types of images - including the ability to reproduce the appearance of a specific individual. ",Cause - developer causes - programmed AI with problematic functions,Cause,Leonardo AI generates celebrity non-consensual porn images,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/leonardo-ai-generates-celebrity-non-consensual-porn-images,Incident,,2024,2024,Global,Media/entertainment/sports/arts,Leonardo AI,Leonardo AI,Leonardo AI,Text-to-image; Machine learning,Generate art,Media investigation,Identity theft/impersonation; Privacy; Safety,Governance,Identity theft/impersonation,,,,,,,,10/2/2024 15:18,https://best-paper-award-ddck.dovetail.com/data/755O5DoMqqfQiSeVyjdqUE#:v:h=2k1KIJCz7hLFYbYjgteVgM
AIAAIC1414,"AI platform Leonardo was accused of letting users easily create explicit, non-consensual images of celebrities. Funded by Samsung, Leonardo is an image generation tool that enables users to use an array of user-generated Stable Diffusion text-to-image AI models, each of which is programmed to generate specific types of images - including the ability to reproduce the appearance of a specific individual. ",Incident - organization-driven - problematic AI implementation,Incident Type,Leonardo AI generates celebrity non-consensual porn images,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/leonardo-ai-generates-celebrity-non-consensual-porn-images,Incident,,2024,2024,Global,Media/entertainment/sports/arts,Leonardo AI,Leonardo AI,Leonardo AI,Text-to-image; Machine learning,Generate art,Media investigation,Identity theft/impersonation; Privacy; Safety,Governance,Identity theft/impersonation,,,,,,,,10/2/2024 15:18,https://best-paper-award-ddck.dovetail.com/data/755O5DoMqqfQiSeVyjdqUE#:v:h=2k1KIJCz7hLFYbYjgteVgM
AIAAIC1173,"Students at Carmel High School, USA, concocted deepfake videos ",Cause - Human causes - Human abuse of AI tools,Cause,Carmel school students attack Principal with racist deepfake video,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/carmel-school-students-attack-principal-with-racist-deepfake-video,Incident,,2023,2023,USA,Education,,,,"Deepfake - audio, video; Machine learning",Damage reputation,School statement,Legal; Mis/disinformation; Safety,Marketing,,,,,,,,,10/24/2024 21:36,https://best-paper-award-ddck.dovetail.com/data/5GUvQkfEmyMiWNoYmGqvBo#:v:h=2k3ccdT7SPjYgSomHDIBxR
AIAAIC1173,"Students at Carmel High School, USA, concocted deepfake videos ",Entity - malicious human,Responsible Entities,Carmel school students attack Principal with racist deepfake video,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/carmel-school-students-attack-principal-with-racist-deepfake-video,Incident,,2023,2023,USA,Education,,,,"Deepfake - audio, video; Machine learning",Damage reputation,School statement,Legal; Mis/disinformation; Safety,Marketing,,,,,,,,,10/24/2024 21:36,https://best-paper-award-ddck.dovetail.com/data/5GUvQkfEmyMiWNoYmGqvBo#:v:h=2k3ccdT7SPjYgSomHDIBxR
AIAAIC0972,"""Noah"" and ""Daren"", a pair of news anchors extolling the quality of Venezuela's economy on Venezuelan state-owned television station VTV were exposed as deepfakes.  The two avatars had been created using artificial intelligence from London-based AI video creation platform Synthesia, which offers a cheap, easy-to-use catalogue of over a hundred multi-racial faces.",Incident - human-driven - Public entity amplified of misleading content,Incident Type,Deepfake news anchors claim Venezuela economic health,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-news-anchors-claim-venezuela-economic-health,Incident,,2023,2023,Venezuela,Politics,House of News; Venezolana de Televisión,House of News; Synthesia,Synthesia,Deepfake - audio; video; Machine learning,Promote government,Media investigation,Mis/disinformation; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 19:22,https://best-paper-award-ddck.dovetail.com/data/1tCasuKj0MMyAXzBALBYBv#:v:h=2kRksXiwmrHTUydys2ryHV
AIAAIC0972,"""Noah"" and ""Daren"", a pair of news anchors extolling the quality of Venezuela's economy on Venezuelan state-owned television station VTV were exposed as deepfakes.  The two avatars had been created using artificial intelligence from London-based AI video creation platform Synthesia, which offers a cheap, easy-to-use catalogue of over a hundred multi-racial faces.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Deepfake news anchors claim Venezuela economic health,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-news-anchors-claim-venezuela-economic-health,Incident,,2023,2023,Venezuela,Politics,House of News; Venezolana de Televisión,House of News; Synthesia,Synthesia,Deepfake - audio; video; Machine learning,Promote government,Media investigation,Mis/disinformation; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 19:22,https://best-paper-award-ddck.dovetail.com/data/1tCasuKj0MMyAXzBALBYBv#:v:h=2kRksXiwmrHTUydys2ryHV
AIAAIC0464,"Facebook owner Meta filed a legal complaint against an AI-powered predictive policing company for using fake Facebook accounts to scrape user data and provide surveillance services to clients. According to the legal filing, Voyager Labs created 38,000+ fake Facebook user accounts and used its surveillance software to gather data from 600,000 Facebook and Instagram users without consent. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Meta sues predicitve policing Voyager Labs for data scraping,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-sues-voyager-labs-for-data-scraping,Incident,,2023,2023,USA,Govt - police,Los Angeles Police Department (LAPD),Voyager Labs,Voyager Analytics,Machine learning; NLP/text analysis; Pattern recognition; Social media monitoring,Predict crime,Lawsuit filing/litigation,Ethics/values; Human/civil rights; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/13/2024 22:47,https://best-paper-award-ddck.dovetail.com/data/2sSJhCbnyL3YrBSLULSP18#:v:h=2mG14lB2YdYQwB3HlaRPMW
AIAAIC0464,"Facebook owner Meta filed a legal complaint against an AI-powered predictive policing company for using fake Facebook accounts to scrape user data and provide surveillance services to clients. According to the legal filing, Voyager Labs created 38,000+ fake Facebook user accounts and used its surveillance software to gather data from 600,000 Facebook and Instagram users without consent. ",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Meta sues predicitve policing Voyager Labs for data scraping,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-sues-voyager-labs-for-data-scraping,Incident,,2023,2023,USA,Govt - police,Los Angeles Police Department (LAPD),Voyager Labs,Voyager Analytics,Machine learning; NLP/text analysis; Pattern recognition; Social media monitoring,Predict crime,Lawsuit filing/litigation,Ethics/values; Human/civil rights; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/13/2024 22:47,https://best-paper-award-ddck.dovetail.com/data/2sSJhCbnyL3YrBSLULSP18#:v:h=2mG14lB2YdYQwB3HlaRPMW
AIAAIC1426,"Plans by the city of San Jose, California, to implement a new artificial intelligence system to detect homeless encampments caused concerns amongst privacy and human rights advocates. The city of San Jose has been piloting using car-mounted cameras and AI software to scan for, amongst other things, trash, graffiti, and vehicles that people are living in, and illegal encampments.",Entity - government authorities that adopt AI,Responsible Entities,"San Jose homeless detection AI sparks privacy, inequality fears",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-jose-homeless-detection-ai-sparks-privacy-inequality-fears,Issue,2023,2024,2024,USA,Govt - municipal,City of San Jose,SenSen AI; Zyrex,SenDISA,Computer vision; Machine learning; Object recognition,Detect homeless encampments,Media investigation,Accuracy/reliability; Human/civil rights; Privacy,Governance; Marketing,Privacy loss,Societal inequality,,,,,,,10/2/2024 14:58,https://best-paper-award-ddck.dovetail.com/data/3KmUZXi99Qn1loVq4paAyt#:v:h=2mXRV6nnBKrY92swvLclQX
AIAAIC1426,"Plans by the city of San Jose, California, to implement a new artificial intelligence system to detect homeless encampments caused concerns amongst privacy and human rights advocates. The city of San Jose has been piloting using car-mounted cameras and AI software to scan for, amongst other things, trash, graffiti, and vehicles that people are living in, and illegal encampments.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,"San Jose homeless detection AI sparks privacy, inequality fears",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-jose-homeless-detection-ai-sparks-privacy-inequality-fears,Issue,2023,2024,2024,USA,Govt - municipal,City of San Jose,SenSen AI; Zyrex,SenDISA,Computer vision; Machine learning; Object recognition,Detect homeless encampments,Media investigation,Accuracy/reliability; Human/civil rights; Privacy,Governance; Marketing,Privacy loss,Societal inequality,,,,,,,10/2/2024 14:58,https://best-paper-award-ddck.dovetail.com/data/3KmUZXi99Qn1loVq4paAyt#:v:h=2mXRV6nnBKrY92swvLclQX
AIAAIC1303,"BIPA makes it illegal for companies to collect or store data, including data about Illinois residents' faces, without their consent. ",Cause - organization causes - legal non-compliance,Cause,"PimEyes sued in Illinois, USA, for privacy violations",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-sued-in-illinois-usa-for-privacy-violations,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Lawsuit filing/litigation,Governance; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/4/2024 14:21,https://best-paper-award-ddck.dovetail.com/data/2kP3ZgJskd8oyopMz2hnhm#:v:h=2n7WxSvaSt9DMyWOpSJWKt
AIAAIC1152,"Despite TikTok’s new guidelines requiring realistic synthetic media to be labelled, the accounts, which bypass these restrictions, have been able to gain hundreds of millions of views.",Incident - human-driven - bypassing AI safeguards,Incident Type,Deepfake audio falsely depicts Barack Obama discussing conspiracy theory,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-falsely-depicts-barack-obama-discussing-conspiracy-theory,Incident,,2023,2023,USA,Politics,,ElevenLabs,ElevenLabs TTS,Deepfake - audio; Machine learning,Damage reputation,Media Investigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/29/2024 23:08,https://best-paper-award-ddck.dovetail.com/data/1LvngziYZmu3HY9bst0zVM#:v:h=2nZDNRpgb1gsiZW8uOWgBS
AIAAIC1014,"Homeland Party head Muharrem Ince withdrew from Turkey's presidential race after the release of an alleged sex tape, which he accused of being a deepfake designed to damage his reputation and campaign. 'Fake videos, fake pictures… they put my face on a video taken from an Israeli porn website,' Ince complained' blaming the country’s journalists and public prosecutors for not protecting him from the 'fury of slander","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Muharrem Ince withdraws from Turkey election after porn 'deepfake',11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/muharrem-ince-porn-deepfake,Incident,,2023,2023,Turkey,Politics,,Justice and Development Party (AKP),,Deepfake - video; Machine learning,Damage reputation,Candidate resignation,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage; Candidate resignation,,,,,,,,10/30/2024 17:42,https://best-paper-award-ddck.dovetail.com/data/WacFgmSdYYXCCUnQQpQno#:v:h=2qKurBqNqEMOMX0m1B3WXS
AIAAIC1014,"Homeland Party head Muharrem Ince withdrew from Turkey's presidential race after the release of an alleged sex tape, which he accused of being a deepfake designed to damage his reputation and campaign. 'Fake videos, fake pictures… they put my face on a video taken from an Israeli porn website,' Ince complained' blaming the country’s journalists and public prosecutors for not protecting him from the 'fury of slander",Entity - no specific info,Responsible Entities,Muharrem Ince withdraws from Turkey election after porn 'deepfake',11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/muharrem-ince-porn-deepfake,Incident,,2023,2023,Turkey,Politics,,Justice and Development Party (AKP),,Deepfake - video; Machine learning,Damage reputation,Candidate resignation,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage; Candidate resignation,,,,,,,,10/30/2024 17:42,https://best-paper-award-ddck.dovetail.com/data/WacFgmSdYYXCCUnQQpQno#:v:h=2qKurBqNqEMOMX0m1B3WXS
AIAAIC1014,"Homeland Party head Muharrem Ince withdrew from Turkey's presidential race after the release of an alleged sex tape, which he accused of being a deepfake designed to damage his reputation and campaign. 'Fake videos, fake pictures… they put my face on a video taken from an Israeli porn website,' Ince complained' blaming the country’s journalists and public prosecutors for not protecting him from the 'fury of slander",Cause - Human causes - Human abuse of AI tools,Cause,Muharrem Ince withdraws from Turkey election after porn 'deepfake',11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/muharrem-ince-porn-deepfake,Incident,,2023,2023,Turkey,Politics,,Justice and Development Party (AKP),,Deepfake - video; Machine learning,Damage reputation,Candidate resignation,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage; Candidate resignation,,,,,,,,10/30/2024 17:42,https://best-paper-award-ddck.dovetail.com/data/WacFgmSdYYXCCUnQQpQno#:v:h=2qKurBqNqEMOMX0m1B3WXS
AIAAIC1496,"Sony Music warned AI companies not to train their systems with its content. Sony Music Group issued warning letters to over 700 AI developers and music streaming services, prohibiting the use of its content for training, developing, or commercialising AI systems. This includes music from artists like Beyoncé, Harry Styles, and Adele. According to Sony, the unauthorised use of it’s content for AI training deprives the company and its artists of control over their work and appropriate compensation. Sony executives are concerned that their music has already been exploited and are seeking to establish a clear legal position against any AI developer considered to have used their music without consent.",Entity - AI developer company,Responsible Entities,Sony warns AI companies to not misuse its data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/sony-warns-ai-companies-to-not-misuse-its-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,,,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis; Deepfake - audio,,Industry complaint,Copyright,Governance,"Copyright loss, Financial loss",,,,,,,,10/12/2024 0:52,https://best-paper-award-ddck.dovetail.com/data/62ENRd1tgJJbbq0FXZ3aSA#:v:h=2r4lyswQjUluazncOjUObE
AIAAIC1496,"Sony Music warned AI companies not to train their systems with its content. Sony Music Group issued warning letters to over 700 AI developers and music streaming services, prohibiting the use of its content for training, developing, or commercialising AI systems. This includes music from artists like Beyoncé, Harry Styles, and Adele. According to Sony, the unauthorised use of it’s content for AI training deprives the company and its artists of control over their work and appropriate compensation. Sony executives are concerned that their music has already been exploited and are seeking to establish a clear legal position against any AI developer considered to have used their music without consent.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Sony warns AI companies to not misuse its data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/sony-warns-ai-companies-to-not-misuse-its-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,,,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis; Deepfake - audio,,Industry complaint,Copyright,Governance,"Copyright loss, Financial loss",,,,,,,,10/12/2024 0:52,https://best-paper-award-ddck.dovetail.com/data/62ENRd1tgJJbbq0FXZ3aSA#:v:h=2r4lyswQjUluazncOjUObE
AIAAIC1496,"Sony Music warned AI companies not to train their systems with its content. Sony Music Group issued warning letters to over 700 AI developers and music streaming services, prohibiting the use of its content for training, developing, or commercialising AI systems. This includes music from artists like Beyoncé, Harry Styles, and Adele. According to Sony, the unauthorised use of it’s content for AI training deprives the company and its artists of control over their work and appropriate compensation. Sony executives are concerned that their music has already been exploited and are seeking to establish a clear legal position against any AI developer considered to have used their music without consent.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Sony warns AI companies to not misuse its data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/sony-warns-ai-companies-to-not-misuse-its-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,,,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis; Deepfake - audio,,Industry complaint,Copyright,Governance,"Copyright loss, Financial loss",,,,,,,,10/12/2024 0:52,https://best-paper-award-ddck.dovetail.com/data/62ENRd1tgJJbbq0FXZ3aSA#:v:h=2r4lyswQjUluazncOjUObE
AIAAIC1313,Several thousand welfare beneficiaries in the Indian state of Haryana were denied access to their pensions and other welfare benefits having been wrongfully declared dead by an AI-powered algorithm.,Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Parivar Pehchan Patra algorithm declares living people dead,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/parivar-pehchan-patra-declares-living-people-dead,Incident,2020,2024,2024,India,Govt - welfare,Citizen Resources Information Department,Government of Haryana,Parivar Pehchan Patra,Machine learning,Assess welfare eligibility,Media investigation,Accuracy/reliability; Accountability; Privacy,Governance; Black box; Complaints/appeals,Financial loss; Privacy loss,,,,,,,,10/2/2024 20:29,https://best-paper-award-ddck.dovetail.com/data/24j1PG4Ua3uonjwhDaqwuL#:v:h=2sA1PKfM9BU5N86WDGBtTI
AIAAIC1285,"An advert for a dental insurance plan supposedly endorsed by actor Tom Hanks was in fact a fake image manipulated using artificial intelligence (AI). 'There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it,' Hanks warned his followers on Instagram, without naming the company or organisation behind the deepfake. The likeness of Hanks appeared to be generated from a 2014 image of the actor owned by the Los Angeles Times, according to Gizmodo. ",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Deepfake Tom Hanks dental ad insurance promotion,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-tom-hanks-dental-ad-promotion,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Promote insurance plan,,Legal,Marketing,,,,,,,,,10/24/2024 22:24,https://best-paper-award-ddck.dovetail.com/data/5faijKuwo1OWoADHJLpUY8#:v:h=2sQAwjjLEQjIU2ucIfi0lo
AIAAIC1285,"An advert for a dental insurance plan supposedly endorsed by actor Tom Hanks was in fact a fake image manipulated using artificial intelligence (AI). 'There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it,' Hanks warned his followers on Instagram, without naming the company or organisation behind the deepfake. The likeness of Hanks appeared to be generated from a 2014 image of the actor owned by the Los Angeles Times, according to Gizmodo. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake Tom Hanks dental ad insurance promotion,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-tom-hanks-dental-ad-promotion,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Promote insurance plan,,Legal,Marketing,,,,,,,,,10/24/2024 22:24,https://best-paper-award-ddck.dovetail.com/data/5faijKuwo1OWoADHJLpUY8#:v:h=2sQAwjjLEQjIU2ucIfi0lo
AIAAIC1285,"An advert for a dental insurance plan supposedly endorsed by actor Tom Hanks was in fact a fake image manipulated using artificial intelligence (AI). 'There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it,' Hanks warned his followers on Instagram, without naming the company or organisation behind the deepfake. The likeness of Hanks appeared to be generated from a 2014 image of the actor owned by the Los Angeles Times, according to Gizmodo. ",Cause - organization causes - poor business ethics,Cause,Deepfake Tom Hanks dental ad insurance promotion,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-tom-hanks-dental-ad-promotion,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Promote insurance plan,,Legal,Marketing,,,,,,,,,10/24/2024 22:24,https://best-paper-award-ddck.dovetail.com/data/5faijKuwo1OWoADHJLpUY8#:v:h=2sQAwjjLEQjIU2ucIfi0lo
AIAAIC1380,"OVD-Info spokesman Dmitry Anisimov told Russian independent news outlet Agenstvo that the Russian government had installed new surveillance cameras around the church and cemetary, and that Russian police were able to identify and trace individuals from the funeral 'right up to their door.'",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Moscow arrests Navalny funeral attendees using facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/moscow-arrests-navalny-funeral-attendees-using-facial-recognition,Incident,,2024,2024,Russia,Govt - police; Govt - security,Moscow City Police,,,Facial recognition,Identify protestors,Media investigation,Human/civil rights; Privacy,Governance,,Loss of rights/freedoms; Privacy loss,,,,,,,10/4/2024 14:05,https://best-paper-award-ddck.dovetail.com/data/6272J8taqqi757P1Rd9w1p#:v:h=2tvw2Ec65SQVCDV4SpQdPU
AIAAIC1145,"Snapchat shrugged off the incident, saying, 'As with all AI-powered chatbots, My AI is always learning and can occasionally produce incorrect responses. We want to create a positive and age appropriate experience for all our users and are continually making updates to help My AI give more accurate responses.'",Cause - organization causes - poor business ethics,Cause,Snapchat My AI requests to meet 13-year-old girl in park,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-my-ai-requests-to-meet-13-year-old-girl-in-park,Incident,2023,2023,2023,Australia,Media/entertainment/sports/arts,Olinda Luketic,Snap Inc; OpenAI,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,User comments/complaints,Accuracy/reliability; Physical safety; Privacy,Governance,Manipulation,,,,,,,,10/7/2024 0:43,https://best-paper-award-ddck.dovetail.com/data/6XDh3rMr4VsRY98OJkDLYT#:v:h=2uzVnXf7R95AZqs14aonSb
AIAAIC1145,"Snapchat shrugged off the incident, saying, 'As with all AI-powered chatbots, My AI is always learning and can occasionally produce incorrect responses. We want to create a positive and age appropriate experience for all our users and are continually making updates to help My AI give more accurate responses.'",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Snapchat My AI requests to meet 13-year-old girl in park,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-my-ai-requests-to-meet-13-year-old-girl-in-park,Incident,2023,2023,2023,Australia,Media/entertainment/sports/arts,Olinda Luketic,Snap Inc; OpenAI,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,User comments/complaints,Accuracy/reliability; Physical safety; Privacy,Governance,Manipulation,,,,,,,,10/7/2024 0:43,https://best-paper-award-ddck.dovetail.com/data/6XDh3rMr4VsRY98OJkDLYT#:v:h=2uzVnXf7R95AZqs14aonSb
AIAAIC1021,"AI-cloned songs in the name and voice of retired Singapore-based Mandopop singer Stefanie Sun went viral in China, raising questions about copyright and jobs in the music industry. Generated using so-vits-svc fork, an open source software that enables anyone to train their own AI model to speak in any voice and language, the videos, dubbed AI Stefanie Sun (AI孙燕姿), went viral on China's most popular video platform Bilibili and other platforms. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,AI-cloned Stefanie Sun songs go viral in China,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-stefanie-sun,Incident,,2023,2023,China; Singapore,Media/entertainment/sports/arts,Bilibili; Kuaishou; QQ Music,,Sovits,"Deepfake - audio, image, video; Machine learning",Generate music,Product demonstration/release/launch,Copyright; Employment - jobs,Governance; Marketing,Loss of rights/freedoms,IP/copyright loss,,,,,,,10/30/2024 17:31,https://best-paper-award-ddck.dovetail.com/data/2waMD9tjVvacPZvAKbAyso#:v:h=2uIWCV9Lz3rpdrvyF1fC4g
AIAAIC1021,"AI-cloned songs in the name and voice of retired Singapore-based Mandopop singer Stefanie Sun went viral in China, raising questions about copyright and jobs in the music industry. Generated using so-vits-svc fork, an open source software that enables anyone to train their own AI model to speak in any voice and language, the videos, dubbed AI Stefanie Sun (AI孙燕姿), went viral on China's most popular video platform Bilibili and other platforms. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,AI-cloned Stefanie Sun songs go viral in China,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-stefanie-sun,Incident,,2023,2023,China; Singapore,Media/entertainment/sports/arts,Bilibili; Kuaishou; QQ Music,,Sovits,"Deepfake - audio, image, video; Machine learning",Generate music,Product demonstration/release/launch,Copyright; Employment - jobs,Governance; Marketing,Loss of rights/freedoms,IP/copyright loss,,,,,,,10/30/2024 17:31,https://best-paper-award-ddck.dovetail.com/data/2waMD9tjVvacPZvAKbAyso#:v:h=2uIWCV9Lz3rpdrvyF1fC4g
AIAAIC1021,"AI-cloned songs in the name and voice of retired Singapore-based Mandopop singer Stefanie Sun went viral in China, raising questions about copyright and jobs in the music industry. Generated using so-vits-svc fork, an open source software that enables anyone to train their own AI model to speak in any voice and language, the videos, dubbed AI Stefanie Sun (AI孙燕姿), went viral on China's most popular video platform Bilibili and other platforms. ",Cause - Human causes - Human abuse of AI tools,Cause,AI-cloned Stefanie Sun songs go viral in China,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-stefanie-sun,Incident,,2023,2023,China; Singapore,Media/entertainment/sports/arts,Bilibili; Kuaishou; QQ Music,,Sovits,"Deepfake - audio, image, video; Machine learning",Generate music,Product demonstration/release/launch,Copyright; Employment - jobs,Governance; Marketing,Loss of rights/freedoms,IP/copyright loss,,,,,,,10/30/2024 17:31,https://best-paper-award-ddck.dovetail.com/data/2waMD9tjVvacPZvAKbAyso#:v:h=2uIWCV9Lz3rpdrvyF1fC4g
AIAAIC1137,"a pro-European politician and journalist discussing methods to rig Slovakia’s 2023 election raised concerns about the use of AI in political elections. The audio recording featured Michal Šimečka, leader of the liberal Progressive Slovakia party, and Denník N journalist Monika Tódová apparently discussing how to manipulate the election. Posted during a 48-hour pre-election moratorium, it was quickly discovered to be a synthetic hoax by AFP and other fact-checking organisations.  The incident raised concerns about the use of underhand methods in Slovakia’s elections, the use of deepfakes in politics, and the ease with which Meta's policies can be bypassed. Because the post was audio, it exploited a loophole in Meta’s manipulated-media policy, which dictates only falsified videos go against its rules.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake audio recording claims opposition leaders tried to rig Slovakian election,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-recording-claims-opposition-leaders-tried-to-rig-slovakian-e,Incident,,2023,2023,Slovakia,Politics,,,,Deepfake - audio; Machine learning,Manipulate public opinion,,"Governance, Mis/disinformation",Governance ,,,,,,,,,10/30/2024 16:25,https://best-paper-award-ddck.dovetail.com/data/4HOpZG4cPlifQg0x7ut16v#:v:h=2wuvMDMqyze78bPCkCwXT0
AIAAIC1137,"a pro-European politician and journalist discussing methods to rig Slovakia’s 2023 election raised concerns about the use of AI in political elections. The audio recording featured Michal Šimečka, leader of the liberal Progressive Slovakia party, and Denník N journalist Monika Tódová apparently discussing how to manipulate the election. Posted during a 48-hour pre-election moratorium, it was quickly discovered to be a synthetic hoax by AFP and other fact-checking organisations.  The incident raised concerns about the use of underhand methods in Slovakia’s elections, the use of deepfakes in politics, and the ease with which Meta's policies can be bypassed. Because the post was audio, it exploited a loophole in Meta’s manipulated-media policy, which dictates only falsified videos go against its rules.",Entity - no specific info,Responsible Entities,Deepfake audio recording claims opposition leaders tried to rig Slovakian election,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-recording-claims-opposition-leaders-tried-to-rig-slovakian-e,Incident,,2023,2023,Slovakia,Politics,,,,Deepfake - audio; Machine learning,Manipulate public opinion,,"Governance, Mis/disinformation",Governance ,,,,,,,,,10/30/2024 16:25,https://best-paper-award-ddck.dovetail.com/data/4HOpZG4cPlifQg0x7ut16v#:v:h=2wuvMDMqyze78bPCkCwXT0
AIAAIC0982,"Tesla employees have been privately sharing private videos images and videos recorded by its customers' car cameras on its internal messaging system and with third party suppliers, according to a report by Reuters. The recordings captured highly intimate and sensitive moments, and were used between 2019 and 2022 to improve Tesla's computer vision machine learning systems. Tesla sources contacted by Reuters said the recordings were shared with Sama, a self-described 'ethical AI' non-profit that provides data labelling and content moderation services, before it was brought in-house. A February 2022 TIME investigation revealed low pay, poor working conditions and alleged union-busting at Sama's office in Nairobi, Kenya.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Tesla workers share private camera recordings,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/tesla-workers-share-private-camera-recordings,Incident,2014,2023,2023,USA,Automotive,Multiple,Tesla,Autopilot,Driver assistance system; Computer vision,"Automate steering, acceleration, braking",Media investigation,Privacy; Employment,Governance; Marketing; Privacy,Privacy loss,,,,,,Litigation,,10/13/2024 22:23,https://best-paper-award-ddck.dovetail.com/data/3hy3bK3PrErSNkpht99qD1#:v:h=2xmBSr96zrkMnWH32Kj9JO
AIAAIC0982,"Tesla employees have been privately sharing private videos images and videos recorded by its customers' car cameras on its internal messaging system and with third party suppliers, according to a report by Reuters. The recordings captured highly intimate and sensitive moments, and were used between 2019 and 2022 to improve Tesla's computer vision machine learning systems. Tesla sources contacted by Reuters said the recordings were shared with Sama, a self-described 'ethical AI' non-profit that provides data labelling and content moderation services, before it was brought in-house. A February 2022 TIME investigation revealed low pay, poor working conditions and alleged union-busting at Sama's office in Nairobi, Kenya.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Tesla workers share private camera recordings,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/tesla-workers-share-private-camera-recordings,Incident,2014,2023,2023,USA,Automotive,Multiple,Tesla,Autopilot,Driver assistance system; Computer vision,"Automate steering, acceleration, braking",Media investigation,Privacy; Employment,Governance; Marketing; Privacy,Privacy loss,,,,,,Litigation,,10/13/2024 22:23,https://best-paper-award-ddck.dovetail.com/data/3hy3bK3PrErSNkpht99qD1#:v:h=2xmBSr96zrkMnWH32Kj9JO
AIAAIC0982,"Tesla employees have been privately sharing private videos images and videos recorded by its customers' car cameras on its internal messaging system and with third party suppliers, according to a report by Reuters. ",Cause - Human causes - employee internal threats,Cause,Tesla workers share private camera recordings,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/tesla-workers-share-private-camera-recordings,Incident,2014,2023,2023,USA,Automotive,Multiple,Tesla,Autopilot,Driver assistance system; Computer vision,"Automate steering, acceleration, braking",Media investigation,Privacy; Employment,Governance; Marketing; Privacy,Privacy loss,,,,,,Litigation,,10/18/2024 13:49,https://best-paper-award-ddck.dovetail.com/data/3hy3bK3PrErSNkpht99qD1#:v:h=2zdR8OpnlWoFgYLyJ7Se6x
AIAAIC0994,"April 2023's full launch of Snapchat My AI met with mixed reviews, with Snapchat users complaining that it appeared on their apps without advance warning or requiring their consent, while some described it as 'creepy'.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Snapchat My AI accesses user location data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-location-access-opacity,Incident,2023,2023,2023,USA; Global,Media/entertainment/sports/arts,David An; Jordan Hart; Snapchat users,Snap Inc,My AI; ChatGPT,Chatbot; Machine learning,"Provide information, communicate",User comments/complaints,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,,,10/11/2024 20:32,https://best-paper-award-ddck.dovetail.com/data/2LKScU9whfqvn0b7WetnZF#:v:h=2zA98NeO5bFArHQFuxq1AV
AIAAIC1225,"ChatGPT can be made to reveal personal information from the internet users' whose data OpenAI collected to train its AI models, prompting concerns about data privacy and OpenAI transparency. According to researchers at Google Deepmind, University of Washington, ETH Zurich, and elsewhere, prompts using specific words or phrases such as the word 'poem' can be used to cause ChatGPT to fail, causing the chatbot to copy outputs direct from its GPT-3.5 training data.  'In total, 16.9 percent of generations we tested contained memorized PII [Personally Identifying Information], and 85.8 percent of generations that contained potential PII were actual PII', the researchers said. These included information such as names, email addresses, and phone numbers that could be used to identify individuals.",Incident - organization-driven - problematic AI implementation,Incident Type,ChatGPT used to collect users' personal information ,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-used-to-collect-users-personal-information,Issue,,2023,2023,USA; Switzerland,Multiple,"Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramèr, Katherine Lee",OpenAI,ChatGPT; GPT-3,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Research study/report,Privacy; Security,,Privacy loss,,,,,,,,10/11/2024 13:33,https://best-paper-award-ddck.dovetail.com/data/1Sa11cldSvyodSULBtLMq1#:v:h=2A4KCILzPWysYKIIJNJG1G
AIAAIC1225,"ChatGPT can be made to reveal personal information from the internet users' whose data OpenAI collected to train its AI models, prompting concerns about data privacy and OpenAI transparency. According to researchers at Google Deepmind, University of Washington, ETH Zurich, and elsewhere, prompts using specific words or phrases such as the word 'poem' can be used to cause ChatGPT to fail, causing the chatbot to copy outputs direct from its GPT-3.5 training data.  'In total, 16.9 percent of generations we tested contained memorized PII [Personally Identifying Information], and 85.8 percent of generations that contained potential PII were actual PII', the researchers said. These included information such as names, email addresses, and phone numbers that could be used to identify individuals.",Cause - organization causes - lack of AI fail-safe measures,Cause,ChatGPT used to collect users' personal information ,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-used-to-collect-users-personal-information,Issue,,2023,2023,USA; Switzerland,Multiple,"Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramèr, Katherine Lee",OpenAI,ChatGPT; GPT-3,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Research study/report,Privacy; Security,,Privacy loss,,,,,,,,10/11/2024 13:33,https://best-paper-award-ddck.dovetail.com/data/1Sa11cldSvyodSULBtLMq1#:v:h=2A4KCILzPWysYKIIJNJG1G
AIAAIC1151,"initially posted to political channel The Voice of Sudan,",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Audio AIs impersonate former South Sudan leader Omar al-Bashir,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-campaign-impersonates-former-south-sudan-leader-omar-al-bashir,Incident,,2023,2023,Sudan,Politics,,,,Deepfake - audio; Machine learning,Damage reputation,,"Governance, Mis/disinformation",Governance,,,,,,,,,10/29/2024 23:10,https://best-paper-award-ddck.dovetail.com/data/2VXX5W5ETJxTFHzwExTnDW#:v:h=2AnfJvlJRhKx8Ai1Im36wT
AIAAIC1151,"initially posted to political channel The Voice of Sudan,",Incident - human-driven - Public entity amplified of misleading content,Incident Type,Audio AIs impersonate former South Sudan leader Omar al-Bashir,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-campaign-impersonates-former-south-sudan-leader-omar-al-bashir,Incident,,2023,2023,Sudan,Politics,,,,Deepfake - audio; Machine learning,Damage reputation,,"Governance, Mis/disinformation",Governance,,,,,,,,,10/29/2024 23:10,https://best-paper-award-ddck.dovetail.com/data/2VXX5W5ETJxTFHzwExTnDW#:v:h=2AnfJvlJRhKx8Ai1Im36wT
AIAAIC1037,Ron de Santis' US presidential campaign released a video on Twitter with fake images of Donald Trump hugging and kissing his former medical advisor Dr Anthony Fauci in an attempt to depict Trump as a supporter of Fauci’s policies combatting COVID-19.,Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Donald Trump hugs Dr Fauci deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/donald-trump-hugs-dr-fauci-deepfake,Incident,,2023,2023,USA,Politics,Ron de Santis; XCorp/xAI/Twitter,Ron de Santis,,Deepfake - image; Machine learning,Damage reputation,Product demonstration/release/launch,Mis/disinformation; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 17:26,https://best-paper-award-ddck.dovetail.com/data/3XXGz1MmoXT7IcZPIxGujE#:v:h=2EqaT2avNp388erT1YUymH
AIAAIC1037,Ron de Santis' US presidential campaign released a video on Twitter with fake images of Donald Trump hugging and kissing his former medical advisor Dr Anthony Fauci in an attempt to depict Trump as a supporter of Fauci’s policies combatting COVID-19.,Cause - organization/human cause - lack of informed consent & transparency,Cause,Donald Trump hugs Dr Fauci deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/donald-trump-hugs-dr-fauci-deepfake,Incident,,2023,2023,USA,Politics,Ron de Santis; XCorp/xAI/Twitter,Ron de Santis,,Deepfake - image; Machine learning,Damage reputation,Product demonstration/release/launch,Mis/disinformation; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 17:26,https://best-paper-award-ddck.dovetail.com/data/3XXGz1MmoXT7IcZPIxGujE#:v:h=2EqaT2avNp388erT1YUymH
AIAAIC1037,Ron de Santis' US presidential campaign released a video on Twitter with fake images of Donald Trump hugging and kissing his former medical advisor Dr Anthony Fauci in an attempt to depict Trump as a supporter of Fauci’s policies combatting COVID-19.,Incident - organization-driven - problematic AI implementation,Incident Type,Donald Trump hugs Dr Fauci deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/donald-trump-hugs-dr-fauci-deepfake,Incident,,2023,2023,USA,Politics,Ron de Santis; XCorp/xAI/Twitter,Ron de Santis,,Deepfake - image; Machine learning,Damage reputation,Product demonstration/release/launch,Mis/disinformation; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 17:26,https://best-paper-award-ddck.dovetail.com/data/3XXGz1MmoXT7IcZPIxGujE#:v:h=2EqaT2avNp388erT1YUymH
AIAAIC1727,"The South Korean government and the country's National Police Agency initiated investigations into Telegram's role in facilitating these activities, following similar actions taken by French authorities against Telegram founder Pavel Durov. Despite previous requests for cooperation, Telegram has been largely unresponsive to law enforcement efforts in South Korea and elsewhere.",Cause - organization causes - poor business ethics,Cause,Deepfake porn engulfs South Korean schools,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-porn-engulfs-korean-schools,Incident,,2024,2024,South Korea,Education,,,,"Deepfake - video, image; Machine learning",Create nude images,,Ethics/values; Privacy; Safety,Governance; Marketing,Privacy loss,,,,,,,,10/18/2024 14:15,https://best-paper-award-ddck.dovetail.com/data/JN6AWZDap6SNPeHe1kNUt#:v:h=2ETU6kq4LySRku63hiGTPd
AIAAIC1163,"The clip, which was based on a video showing President Biden speaking about the cost of insulin, was first flagged by Meta during the early days of the 2023 Israel-Hamas war, though a longer version had been shared in February 2023 by Conservative activist Jack Posobiec and Canadian website Post Millennial.  In both videos, Biden appeared to say, 'Invoke the Selective Service Act, as is my authority as President. Remember, you’re not sending your sons and daughters to war. You’re sending them to freedom.' But only the first clip indicated it had been altered using artificial intelligence, saying, 'AI imagines what would happen if Biden declares and activates the Selective Service Act and begins drafting 20 years old to war.'",Entity - no specific info,Responsible Entities,President Biden calls for US draft deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/president-biden-calls-for-us-draft-deepfake,Incident,,2023,2023,USA,Politics,,,,"Deepfake - audio, video; Machine learning",Manipulate public opinion,,Mis/disinformation,Governance; Marketing,Manipulation; Reputational damage,,,,,,,,10/24/2024 21:21,https://best-paper-award-ddck.dovetail.com/data/3kgMgWP6QN3HRIFGKLzNvs#:v:h=2HqfHVH8a7vvRPpc4Y1H97
AIAAIC1163,"The clip, which was based on a video showing President Biden speaking about the cost of insulin, was first flagged by Meta during the early days of the 2023 Israel-Hamas war, though a longer version had been shared in February 2023 by Conservative activist Jack Posobiec and Canadian website Post Millennial.  In both videos, Biden appeared to say, 'Invoke the Selective Service Act, as is my authority as President. Remember, you’re not sending your sons and daughters to war. You’re sending them to freedom.' But only the first clip indicated it had been altered using artificial intelligence, saying, 'AI imagines what would happen if Biden declares and activates the Selective Service Act and begins drafting 20 years old to war.'",Cause - no specific info,Cause,President Biden calls for US draft deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/president-biden-calls-for-us-draft-deepfake,Incident,,2023,2023,USA,Politics,,,,"Deepfake - audio, video; Machine learning",Manipulate public opinion,,Mis/disinformation,Governance; Marketing,Manipulation; Reputational damage,,,,,,,,10/24/2024 21:21,https://best-paper-award-ddck.dovetail.com/data/3kgMgWP6QN3HRIFGKLzNvs#:v:h=2HqfHVH8a7vvRPpc4Y1H97
AIAAIC1005,"A mother has said someone tried to scam her by cloning her daughter Brie's voice and claiming to have kidnapped her, and demanded GBP 1 million for her safe return. Jennifer DeStefano said she had been '100 percent' convinced that Brie was sobbing on the line after she had heard her voice in the background of the call begging her mother to help. She only realised it was a scam when a friend caller her husband to confirm that Brie was safe.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"Scammers clone teenager's voice, threaten kidnapping",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/scammers-clone-teenagers-voice-threaten-kidnapping,Incident,,2023,2023,USA,Education,,,,Deepfake - audio; Machine learning,Defraud,,Security; Safety; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 18:32,https://best-paper-award-ddck.dovetail.com/data/2c5h3Pk7esfsSa4IHD9aDE#:v:h=2HQbomZcJb0t9y9UaD9sXB
AIAAIC1005,"A mother has said someone tried to scam her by cloning her daughter Brie's voice and claiming to have kidnapped her, and demanded GBP 1 million for her safe return. Jennifer DeStefano said she had been '100 percent' convinced that Brie was sobbing on the line after she had heard her voice in the background of the call begging her mother to help. She only realised it was a scam when a friend caller her husband to confirm that Brie was safe.",Cause - Human causes - Human abuse of AI tools,Cause,"Scammers clone teenager's voice, threaten kidnapping",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/scammers-clone-teenagers-voice-threaten-kidnapping,Incident,,2023,2023,USA,Education,,,,Deepfake - audio; Machine learning,Defraud,,Security; Safety; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 18:32,https://best-paper-award-ddck.dovetail.com/data/2c5h3Pk7esfsSa4IHD9aDE#:v:h=2HQbomZcJb0t9y9UaD9sXB
AIAAIC1005,"A mother has said someone tried to scam her by cloning her daughter Brie's voice and claiming to have kidnapped her, and demanded GBP 1 million for her safe return. Jennifer DeStefano said she had been '100 percent' convinced that Brie was sobbing on the line after she had heard her voice in the background of the call begging her mother to help. She only realised it was a scam when a friend caller her husband to confirm that Brie was safe.",Entity - malicious human,Responsible Entities,"Scammers clone teenager's voice, threaten kidnapping",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/scammers-clone-teenagers-voice-threaten-kidnapping,Incident,,2023,2023,USA,Education,,,,Deepfake - audio; Machine learning,Defraud,,Security; Safety; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 18:32,https://best-paper-award-ddck.dovetail.com/data/2c5h3Pk7esfsSa4IHD9aDE#:v:h=2HQbomZcJb0t9y9UaD9sXB
AIAAIC1607,"The use of AI to monitor the Paris 2024 Olympic Games raised concerns about surveillance and privacy.  In 2023, the French government expanded the legal framework for AI surveillance, allowing for its use during the Olympics and potentially beyond. French authorities have since implemented AI systems to monitor crowds, detect weapons, and identify abandoned packages during the Games. However, civil rights groups and other critics argue that this represents a form of ""creeping surveillance"" that could normalise intrusive monitoring practices, and voiced strong opposition to the measures, arguing they threaten fundamental rights such as privacy and freedom of expression and that the Olympics provide a pretext for expanding surveillance capabilities under the guise of security. Experts expressed concerns that the technologies could lead to a chilling effect on public behaviour, as individuals modify their actions in response to surveillance. They also highlighted the possibility of misuse and lack of transparency regarding how data is collected and used, and the lack of accuracy associated with AI surveillance systems. ",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Paris Olympics AI scans fuel surveillance fears,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/paris-olympics-ai-scans-fuel-surveillance-fears,Issue,,2024,2024,France,Media/entertainment/sports/arts; Transport,Paris Police Prefecture; SNCF,Videtics; Orange Business; ChapsVision; Wintics,ChapsVision; Flux Vision; CityVision; Videtics Perception,Computer vision; Machine learning; Object recognition,Detect abandoned packages; Detect overcrowding,,Accuracy/reliability; Human/civil rights; Privacy; Surveillance,,Privacy loss,,,,,,,,9/26/2024 23:47,https://best-paper-award-ddck.dovetail.com/data/sIuqwtUJaojGC6hb4Vv6b#:v:h=2Tf17tIJzlLcEPj9eL8YIQ
AIAAIC1607,"The use of AI to monitor the Paris 2024 Olympic Games raised concerns about surveillance and privacy.  In 2023, the French government expanded the legal framework for AI surveillance, allowing for its use during the Olympics and potentially beyond. French authorities have since implemented AI systems to monitor crowds, detect weapons, and identify abandoned packages during the Games. However, civil rights groups and other critics argue that this represents a form of ""creeping surveillance"" that could normalise intrusive monitoring practices, and voiced strong opposition to the measures, arguing they threaten fundamental rights such as privacy and freedom of expression and that the Olympics provide a pretext for expanding surveillance capabilities under the guise of security. Experts expressed concerns that the technologies could lead to a chilling effect on public behaviour, as individuals modify their actions in response to surveillance. They also highlighted the possibility of misuse and lack of transparency regarding how data is collected and used, and the lack of accuracy associated with AI surveillance systems. ",Entity - government authorities that adopt AI,Responsible Entities,Paris Olympics AI scans fuel surveillance fears,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/paris-olympics-ai-scans-fuel-surveillance-fears,Issue,,2024,2024,France,Media/entertainment/sports/arts; Transport,Paris Police Prefecture; SNCF,Videtics; Orange Business; ChapsVision; Wintics,ChapsVision; Flux Vision; CityVision; Videtics Perception,Computer vision; Machine learning; Object recognition,Detect abandoned packages; Detect overcrowding,,Accuracy/reliability; Human/civil rights; Privacy; Surveillance,,Privacy loss,,,,,,,,9/26/2024 23:47,https://best-paper-award-ddck.dovetail.com/data/sIuqwtUJaojGC6hb4Vv6b#:v:h=2Tf17tIJzlLcEPj9eL8YIQ
AIAAIC1607,"The use of AI to monitor the Paris 2024 Olympic Games raised concerns about surveillance and privacy.  In 2023, the French government expanded the legal framework for AI surveillance, allowing for its use during the Olympics and potentially beyond. French authorities have since implemented AI systems to monitor crowds, detect weapons, and identify abandoned packages during the Games. However, civil rights groups and other critics argue that this represents a form of ""creeping surveillance"" that could normalise intrusive monitoring practices, and voiced strong opposition to the measures, arguing they threaten fundamental rights such as privacy and freedom of expression and that the Olympics provide a pretext for expanding surveillance capabilities under the guise of security. Experts expressed concerns that the technologies could lead to a chilling effect on public behaviour, as individuals modify their actions in response to surveillance. They also highlighted the possibility of misuse and lack of transparency regarding how data is collected and used, and the lack of accuracy associated with AI surveillance systems. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Paris Olympics AI scans fuel surveillance fears,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/paris-olympics-ai-scans-fuel-surveillance-fears,Issue,,2024,2024,France,Media/entertainment/sports/arts; Transport,Paris Police Prefecture; SNCF,Videtics; Orange Business; ChapsVision; Wintics,ChapsVision; Flux Vision; CityVision; Videtics Perception,Computer vision; Machine learning; Object recognition,Detect abandoned packages; Detect overcrowding,,Accuracy/reliability; Human/civil rights; Privacy; Surveillance,,Privacy loss,,,,,,,,9/26/2024 23:47,https://best-paper-award-ddck.dovetail.com/data/sIuqwtUJaojGC6hb4Vv6b#:v:h=2Tf17tIJzlLcEPj9eL8YIQ
AIAAIC0473,"Proctorio was accused by University of British Colombia (UBC) students, staff, and faculty of providing an 'unethical, invasive' online exam invigilation system, and for causing anxiety and other mental harms, and negatively impacting students’ academic performance. The complaints were initially triggered by a UBC student claiming that Proctorio had failed to provide support when encountering an issue the system, to which Proctorio CEO Mike Olsen posted excerpts of a support chat log to Twitter, resulting in allegations of privacy abuse. Olsen later apologised for his actions. ",Entity - AI developer company,Responsible Entities,"UBC academic, students accuse Proctorio of privacy abuse",10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ubc-academic-students-accuse-proctorio-of-privacy-abuse,Incident,2013,2023,2023,Canada,Education,University of British Columbia,Proctorio,Proctorio,Facial detection; Gaze detection; Machine learning,Detect exam cheating,Lawsuit filing/litigation,Bias/discrimination - race; Confidentiality; Privacy; Freedom of expression; Freedom of information,Governance; Back box; Complaints/appeals; Marketing; Legal,Privacy loss; Loss of rights/freedoms,,,Student backlash,,,Litigation,,10/13/2024 22:43,https://best-paper-award-ddck.dovetail.com/data/3iKQRgkp7wnHPaH1dvQ0OJ#:v:h=2UQqvuBRAaMxcieMHADXD0
AIAAIC0473,"Proctorio was accused by University of British Colombia (UBC) students, staff, and faculty of providing an 'unethical, invasive' online exam invigilation system, and for causing anxiety and other mental harms, and negatively impacting students’ academic performance. The complaints were initially triggered by a UBC student claiming that Proctorio had failed to provide support when encountering an issue the system, to which Proctorio CEO Mike Olsen posted excerpts of a support chat log to Twitter, resulting in allegations of privacy abuse. Olsen later apologised for his actions. ",Incident - organization-driven - problematic AI implementation,Incident Type,"UBC academic, students accuse Proctorio of privacy abuse",10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ubc-academic-students-accuse-proctorio-of-privacy-abuse,Incident,2013,2023,2023,Canada,Education,University of British Columbia,Proctorio,Proctorio,Facial detection; Gaze detection; Machine learning,Detect exam cheating,Lawsuit filing/litigation,Bias/discrimination - race; Confidentiality; Privacy; Freedom of expression; Freedom of information,Governance; Back box; Complaints/appeals; Marketing; Legal,Privacy loss; Loss of rights/freedoms,,,Student backlash,,,Litigation,,10/13/2024 22:43,https://best-paper-award-ddck.dovetail.com/data/3iKQRgkp7wnHPaH1dvQ0OJ#:v:h=2UQqvuBRAaMxcieMHADXD0
AIAAIC1408,South Korea's Personal Information Protection Committee (PIPC) initiated an investigation into Worldcoin following a series of complaints about the manner in which the company was collecting sensitive data from users.  The PIPC announced its investigation into Worldcoin would look into 'the overall collection and processing of sensitive information and overseas transfer of personal information under the Personal Information Protection Act.' ,Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,South Korea privacy watchdog investigates Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korea-privacy-watchdog-investigates-worldcoin,Incident,2023,2024,2024,South Korea,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,,Regulatory investigation,,10/2/2024 15:56,https://best-paper-award-ddck.dovetail.com/data/55eJ2S2Wo63yynNtTqwMwz#:v:h=2UYAVj9TOkdoPQDdnFtFJX
AIAAIC1235,"Palantir's Gotham system, which runs in Bavaria under the name VeRa, helps bring together data from various databases and looks for cross-connections that investigators might otherwise not notice.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Bavaria tests police AI analytics software using real data,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bavaria-police-test-palantir-using-real-data,Issue,,2023,2023,Germany,Govt - police,Bayerisches Landeskriminalamt,Bayerisches Landeskriminalamt; Palantir,VeRA; Gotham,Data analytics; Machine learning,Identify criminal suspects,Media investigation,Legal; Privacy,Governance; Marketing,Privacy loss,,,,,,,,10/6/2024 23:50,https://best-paper-award-ddck.dovetail.com/data/7yCOzFlowkWHBdgBc4NW1h#:v:h=2V4ka0kHdDlzIe595yShPp
AIAAIC1405,"A Russian TV station broadcast a fake synthetic video of Ukrainian officials, including top security advisor Oleksiy Danilov, admitting to orchestrating the Crocus City Hall terror attack in Moscow.  Gunmen opened fire at the Crocus City Hall, a popular concert hall on the outskirts of Moscow, killing over 100 people and injuring many more. The deadly attack, which came shortly after the re-election of Vladimir Putin as Russian president, had reputedly been flagged by US intelligence to Russian authorities.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Russian state TV deepfake blames Ukraine for Crocus City Hall attack,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/russian-state-tv-deepfake-blames-ukraine-for-crocus-city-hall-attack,Incident,,2024,2024,Russia; Ukraine,Govt - defence,NTV,,,"Deepfake - video, audio; Machine learning",Deflect blame,,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 23:13,https://best-paper-award-ddck.dovetail.com/data/4PW3gWDksIUlUtA5mjzSY2#:v:h=2XDDYNsyhg4wSAJ29dvoHq
AIAAIC1405,"A Russian TV station broadcast a fake synthetic video of Ukrainian officials, including top security advisor Oleksiy Danilov, admitting to orchestrating the Crocus City Hall terror attack in Moscow.  Gunmen opened fire at the Crocus City Hall, a popular concert hall on the outskirts of Moscow, killing over 100 people and injuring many more. The deadly attack, which came shortly after the re-election of Vladimir Putin as Russian president, had reputedly been flagged by US intelligence to Russian authorities.",Cause - no specific info,Cause,Russian state TV deepfake blames Ukraine for Crocus City Hall attack,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/russian-state-tv-deepfake-blames-ukraine-for-crocus-city-hall-attack,Incident,,2024,2024,Russia; Ukraine,Govt - defence,NTV,,,"Deepfake - video, audio; Machine learning",Deflect blame,,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 23:13,https://best-paper-award-ddck.dovetail.com/data/4PW3gWDksIUlUtA5mjzSY2#:v:h=2XDDYNsyhg4wSAJ29dvoHq
"AIAAIC1774
","Telegram has seen a surge in the availability and use of AI-powered bots that create nude images of individuals, including minors, according to a WIRED investigation. What happened The investigation discovered over 50 bots generating non-consensual fake nude images of women from regular photos. The bots draw over 4 million monthly users combined, WIRED reckons. The victims often experience severe emotional distress, humiliation, fear and long-term psychological trauma due to the non-consensual nature of the images.  In some cases, the images are used to extort money.",Cause - Lack of AI control,Cause,AI nudification bots swamp Telegram,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-nudification-bots-swamp-telegram,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:09,https://best-paper-award-ddck.dovetail.com/data/6edhbS6Pc2s0Qme33ezFgt#:v:h=2YddsAQvqE2NzdYA7wqRBp
"AIAAIC1774
","Telegram has seen a surge in the availability and use of AI-powered bots that create nude images of individuals, including minors, according to a WIRED investigation. What happened The investigation discovered over 50 bots generating non-consensual fake nude images of women from regular photos. The bots draw over 4 million monthly users combined, WIRED reckons. The victims often experience severe emotional distress, humiliation, fear and long-term psychological trauma due to the non-consensual nature of the images.  In some cases, the images are used to extort money.",Incident - organization-driven - problematic AI implementation,Incident Type,AI nudification bots swamp Telegram,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-nudification-bots-swamp-telegram,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:09,https://best-paper-award-ddck.dovetail.com/data/6edhbS6Pc2s0Qme33ezFgt#:v:h=2YddsAQvqE2NzdYA7wqRBp
"AIAAIC1774
","Telegram has seen a surge in the availability and use of AI-powered bots that create nude images of individuals, including minors, according to a WIRED investigation. What happened The investigation discovered over 50 bots generating non-consensual fake nude images of women from regular photos. The bots draw over 4 million monthly users combined, WIRED reckons. The victims often experience severe emotional distress, humiliation, fear and long-term psychological trauma due to the non-consensual nature of the images.  In some cases, the images are used to extort money.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,AI nudification bots swamp Telegram,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-nudification-bots-swamp-telegram,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:09,https://best-paper-award-ddck.dovetail.com/data/6edhbS6Pc2s0Qme33ezFgt#:v:h=2YddsAQvqE2NzdYA7wqRBp
AIAAIC0917,"During the backlash that ensued, critics asked whether an Institutional Review Board (IRB) had approved the experiment. It is illegal to conduct research on human subjects without so-called 'informed consent' unless an IRB finds that consent can be waived in the US.",Cause - governance causes - legal loophole,Cause,Koko AI mental health counselling 'experiment' fails to obtain user consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/koko-ai-mental-health-counselling-experiment,Incident,,2023,2023,USA,Multiple; Health,Koko; Discord,Koko,GPT-3,Large language model; Machine learning,Provide mental health support,CEO statement,Ethics/values; Privacy,Governance,,,,,,,,,10/13/2024 22:39,https://best-paper-award-ddck.dovetail.com/data/4m68Cxn6n7RdYeBNYZskV0#:v:h=2ZI3qvFVPJSrvejkZEpDfV
AIAAIC1381,The activities of digital identity network Worldcoin were suspended in Spain for inadequate transparency and the collection of personal data of children.,Cause - organization causes - legal non-compliance,Cause,Spain suspends Worldcoin over privacy concerns,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/spain-suspends-worldcoin-over-privacy-concerns,Incident,2023,2024,2024,Spain,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/4/2024 14:03,https://best-paper-award-ddck.dovetail.com/data/2KvcGYwqmHB0goQ8GTNz3s#:v:h=30qOWKymUTja9VfvhDYviY
AIAAIC1377,Some parents argued that taking disciplinary action against the accused group was inadequate and that companies creating and facilitating deepfake and denudifier technologies should also be held responsible.,Cause - developer causes - programmed AI with problematic functions,Cause,Beverly Hills students created and shared AI nude images of fellow students ,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/beverly-hills-students-created-shared-ai-nude-images-of-fellow-students,Incident,,2024,2024,USA,Education,Beverly Vista Middle School students,,,Deepfake - image; Machine learning,Nudify women,School statement,Ethics/values; Privacy; Safety,Governance; Marketing,Anxiety/distress/depression; Privacy loss,,,,,,Police investigation,,10/28/2024 15:54,https://best-paper-award-ddck.dovetail.com/data/5DoLNUi9YNXVhFJuEmjANl#:v:h=322iinO6bCsXmYFQllIyN4
AIAAIC1507,"Malaysian Instagram user @shahv4012, ",Entity - malicious human,Responsible Entities,All eyes on Rafah' deepfake criticised for 'sanitising' Gaza invasion,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/all-eyes-on-rafah-deepfake-criticised-for-sanitising-gaza-invasion,Issue,,2024,2024,Israel; Palestine,Govt - police; Govt - security; Govt - defence; Politics,@shahv4012,,,Deepfake - image; Machine learning,,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:00,https://best-paper-award-ddck.dovetail.com/data/3pMQJiGVIlqWlwBZ77v23m#:v:h=324hGdm0XIFemgD3lQzzU5
AIAAIC1117,"Six people were arrested in Hong Kong accused of making loan applications using deepfake technology and drefrauding banks and financial services companies of HKD 200,000. According to police, the group stole at least eight ID cards and used them to open 54 bank accounts between September 2022 and July 2023. Then they applied for up to 90 loans from 20 banks ans financial institutions, four of which were approved.  Police say the group once succeeded in using a face swap program to spoof a bank’s facial recognition authentication process, though it was not clear how many attempts were made.  It was thought to be the first known instance of scammers using stolen ID cards and deepfake technologies to defraud financial agencies in Hong Kong.",Entity - malicious human,Responsible Entities,"Deepfake IDs used in HKD 200,000 bank fraud",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-ids-used-in-hkd-200000-bank-fraud,Incident,,2023,2023,Hong Kong,Banking/financial services,,,,Deepfake - image; Machine learning,Defraud,Lawsuit filing/litigation,Security,Governance; Marketing,Financial loss,,,,,,Litigation,,10/30/2024 16:30,https://best-paper-award-ddck.dovetail.com/data/7sC8jZLOePQ4pJdjLOpmFb#:v:h=33qkUjpogdLbumBnnVP9wj
AIAAIC1117,"Six people were arrested in Hong Kong accused of making loan applications using deepfake technology and drefrauding banks and financial services companies of HKD 200,000. According to police, the group stole at least eight ID cards and used them to open 54 bank accounts between September 2022 and July 2023. Then they applied for up to 90 loans from 20 banks ans financial institutions, four of which were approved.  Police say the group once succeeded in using a face swap program to spoof a bank’s facial recognition authentication process, though it was not clear how many attempts were made.  It was thought to be the first known instance of scammers using stolen ID cards and deepfake technologies to defraud financial agencies in Hong Kong.",Cause - Human causes - Human abuse of AI tools,Cause,"Deepfake IDs used in HKD 200,000 bank fraud",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-ids-used-in-hkd-200000-bank-fraud,Incident,,2023,2023,Hong Kong,Banking/financial services,,,,Deepfake - image; Machine learning,Defraud,Lawsuit filing/litigation,Security,Governance; Marketing,Financial loss,,,,,,Litigation,,10/30/2024 16:30,https://best-paper-award-ddck.dovetail.com/data/7sC8jZLOePQ4pJdjLOpmFb#:v:h=33qkUjpogdLbumBnnVP9wj
AIAAIC1117,"Six people were arrested in Hong Kong accused of making loan applications using deepfake technology and drefrauding banks and financial services companies of HKD 200,000. According to police, the group stole at least eight ID cards and used them to open 54 bank accounts between September 2022 and July 2023. Then they applied for up to 90 loans from 20 banks ans financial institutions, four of which were approved.  Police say the group once succeeded in using a face swap program to spoof a bank’s facial recognition authentication process, though it was not clear how many attempts were made.  It was thought to be the first known instance of scammers using stolen ID cards and deepfake technologies to defraud financial agencies in Hong Kong.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"Deepfake IDs used in HKD 200,000 bank fraud",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-ids-used-in-hkd-200000-bank-fraud,Incident,,2023,2023,Hong Kong,Banking/financial services,,,,Deepfake - image; Machine learning,Defraud,Lawsuit filing/litigation,Security,Governance; Marketing,Financial loss,,,,,,Litigation,,10/30/2024 16:30,https://best-paper-award-ddck.dovetail.com/data/7sC8jZLOePQ4pJdjLOpmFb#:v:h=33qkUjpogdLbumBnnVP9wj
AIAAIC1060,"The company later banned the user who had created the videos, though refused to identify the individual or entity.",Entity - malicious human,Responsible Entities,Deepfake 'Pan Africanists' support Burkina Faso military junta,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pan-africanists-support-burkina-faso-junta,Incident,,2023,2023,Burkina Faso,Politics,Wagner Group; XCorp/xAI/Twitter; Facebook/WhatsApp,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation,Damage to national security,,,,,,,10/30/2024 17:01,https://best-paper-award-ddck.dovetail.com/data/1ZeKkL2CUQfEYHb4trbHH0#:v:h=33uzRYqeOuySVfw3KoHYT1
AIAAIC1060,"The company later banned the user who had created the videos, though refused to identify the individual or entity.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake 'Pan Africanists' support Burkina Faso military junta,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pan-africanists-support-burkina-faso-junta,Incident,,2023,2023,Burkina Faso,Politics,Wagner Group; XCorp/xAI/Twitter; Facebook/WhatsApp,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation,Damage to national security,,,,,,,10/30/2024 17:01,https://best-paper-award-ddck.dovetail.com/data/1ZeKkL2CUQfEYHb4trbHH0#:v:h=33uzRYqeOuySVfw3KoHYT1
AIAAIC1020,"A legal advisor at a technology company in Fuzhou, China, was defrauded of RMB 4.3 million (USD 622,000) after receiving a video call from a 'friend' who turned out to be a fraudster using AI face-swapping technology.  According to local police, the fraudster stole an individual’s WeChat account and used AI to create a deepfake of the person's face.  The fraudster made a video call to a businessman who was an existing contact on the individual’s WeChat app and told the businessman they needed to make a deposit during a bidding process. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"Chinese scammer uses AI to defraud 'fiend' of USD 622,000",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chinese-scammer-uses-ai-to-defraud-fiend-of-usd-622000,Incident,,2023,2023,China,"Private - individual, family",Tencent/WeChat,,,"Deepfake - video, audio; Machine learning",Defraud,Police investigation,Security,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:32,https://best-paper-award-ddck.dovetail.com/data/1NvLyobBWf5j1dgdXFBr1p#:v:h=33yaMCJzgXlg5bVI96qrSQ
AIAAIC1020,"A legal advisor at a technology company in Fuzhou, China, was defrauded of RMB 4.3 million (USD 622,000) after receiving a video call from a 'friend' who turned out to be a fraudster using AI face-swapping technology.  According to local police, the fraudster stole an individual’s WeChat account and used AI to create a deepfake of the person's face.  The fraudster made a video call to a businessman who was an existing contact on the individual’s WeChat app and told the businessman they needed to make a deposit during a bidding process. ",Cause - Human causes - Human abuse of AI tools,Cause,"Chinese scammer uses AI to defraud 'fiend' of USD 622,000",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chinese-scammer-uses-ai-to-defraud-fiend-of-usd-622000,Incident,,2023,2023,China,"Private - individual, family",Tencent/WeChat,,,"Deepfake - video, audio; Machine learning",Defraud,Police investigation,Security,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:32,https://best-paper-award-ddck.dovetail.com/data/1NvLyobBWf5j1dgdXFBr1p#:v:h=33yaMCJzgXlg5bVI96qrSQ
"AIAAIC1774
","Meantime, many legal jurisdictions lack specific regulations addressing altered images created by AI, leaving victims vulnerable to exploitation without legal recourse. What it means 
 The findings raise significant concerns about the implications for privacy and the psychological well-being of victims, particularly young girls and women. 
 The situation underscores the urgent need for up-to-date legislation that addresses the unique challenges posed by AI-generated content.  
 While some initiatives have been proposed, such as the US Deepfake Accountability Act, most have not been signed into law and of those that have, questions about their effectiveness remain.",Cause - governance causes - legal loophole,Cause,AI nudification bots swamp Telegram,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-nudification-bots-swamp-telegram,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:25,https://best-paper-award-ddck.dovetail.com/data/6edhbS6Pc2s0Qme33ezFgt#:v:h=35buXGPzFOaE0WI7b0wV6e
AIAAIC1182,An AI-generated impersonation of Tom Cruise was used in a disinformation campaign dressed up as a Netflix documentary accusing the IOC of corruption.  Fake four-part Netflix video documentary series 'Olympics Has Fallen' alleges widespread corruption across the International Olympic Committee (IOC) and uses Tom Cruise's voice to implicate high-ranking officials.,Cause - Human causes - Human abuse of AI tools,Cause,Corruption doc incorporating Tom Cruise deepfake attacks IOC,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/corruption-doc-incorporating-tom-cruise-deepfake-attacks-ioc,Incident,,2023,2023,Russia,Media/entertainment/sports/arts,Government of Russia,Government of Russia,,Deepfake - audio; Machine learning,Damage reputation,IOC statement,Mis/disinformation,Governance; Marketing,,"Damage to economic, social, political systems/stability",,,,,,,10/24/2024 21:38,https://best-paper-award-ddck.dovetail.com/data/1MUy1enNexvIws3VSTaV0D#:v:h=36ZypQDsFSgn7ie6OLJaub
AIAAIC1182,An AI-generated impersonation of Tom Cruise was used in a disinformation campaign dressed up as a Netflix documentary accusing the IOC of corruption.  Fake four-part Netflix video documentary series 'Olympics Has Fallen' alleges widespread corruption across the International Olympic Committee (IOC) and uses Tom Cruise's voice to implicate high-ranking officials.,Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Corruption doc incorporating Tom Cruise deepfake attacks IOC,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/corruption-doc-incorporating-tom-cruise-deepfake-attacks-ioc,Incident,,2023,2023,Russia,Media/entertainment/sports/arts,Government of Russia,Government of Russia,,Deepfake - audio; Machine learning,Damage reputation,IOC statement,Mis/disinformation,Governance; Marketing,,"Damage to economic, social, political systems/stability",,,,,,,10/24/2024 21:38,https://best-paper-award-ddck.dovetail.com/data/1MUy1enNexvIws3VSTaV0D#:v:h=36ZypQDsFSgn7ie6OLJaub
AIAAIC1182,An AI-generated impersonation of Tom Cruise was used in a disinformation campaign dressed up as a Netflix documentary accusing the IOC of corruption.  Fake four-part Netflix video documentary series 'Olympics Has Fallen' alleges widespread corruption across the International Olympic Committee (IOC) and uses Tom Cruise's voice to implicate high-ranking officials.,"Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Corruption doc incorporating Tom Cruise deepfake attacks IOC,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/corruption-doc-incorporating-tom-cruise-deepfake-attacks-ioc,Incident,,2023,2023,Russia,Media/entertainment/sports/arts,Government of Russia,Government of Russia,,Deepfake - audio; Machine learning,Damage reputation,IOC statement,Mis/disinformation,Governance; Marketing,,"Damage to economic, social, political systems/stability",,,,,,,10/24/2024 21:38,https://best-paper-award-ddck.dovetail.com/data/1MUy1enNexvIws3VSTaV0D#:v:h=36ZypQDsFSgn7ie6OLJaub
AIAAIC1179,"sharing of personal data with advertisers,",Incident - organization-drive - unauthorized data use for targeted adversiting,Incident Type,Replika shares user data with advertisers,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-replika-fails-to-meet-minimum-privacy-standards,Issue,2017,2023,2023,Global,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Research study/report,Privacy,,,,,,,,,,10/11/2024 14:08,https://best-paper-award-ddck.dovetail.com/data/6Ictyc7kKTXwtfgaowLSph#:v:h=37mHZg71E5S4CMBP0Iv21h
AIAAIC1206,the lack of an age verification system to prevent minors from being exposed to inappropriate answers.,Cause - developer causes - programmed AI with problematic functions,Cause,Italy bans ChatGPT over data privacy concerns,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/italy-bans-chatgpt-over-privacy-concerns,Incident,2022,2023,2023,Italy,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory action,Privacy,,Privacy loss,,,,,,,,10/7/2024 0:05,https://best-paper-award-ddck.dovetail.com/data/4UkxqcOFQKjmKukEznU8aw#:v:h=37weL0fkNuSttKq7j0rZFn
AIAAIC1253,"unfairly targeted Black, Hispanic and female customers, was mostly deployed in neighborhoods that were located in 'plurality non-White areas,' and that incidents 'disproportionately' impacting people of colour",Cause - AI causes - potential AI bias (racism - inequality) ,Cause,Rite Aid facial recognition accuses innocent shoppers of theft,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rite-aid-accuses-innocent-shoppers-of-theft,Incident,2013,2023,2023,USA,Retail,Rite Aid,FaceFirst; DeepCam,FaceFirst; DeepCam,Facial recognition,"Reduce crime, violence",Regulatory statement,"Accuracy/reliability; Bias/discrimination - race, ethnicity, income; Privacy; Security",Governance; Marketing,Harassment/abuse; Privacy loss,,,,,,Regulatory investigation,,10/6/2024 23:37,https://best-paper-award-ddck.dovetail.com/data/7mMGU0T2yCqVGMBynNPIP2#:v:h=38jlW1xg8dew7UGkPMHcja
AIAAIC1288,"A fraud detection system developed by Thomson Reuters generated false fraud alerts, leaving hundreds of thousands of legitimate claimants without access to public benefits, according to a legal complaint.  Based on a three-year investigation, a complaint (pdf) filed by privacy non-profit organisation EPIC alleged that Thomson Reuters unlawfully acquired data, including from social media, and used 'harmful AI practices' to build and operate Fraud Detect, an automated tool used to detect and prevent welfare and healthcare insurance fraud in at least 42 US states. The complaint also alleged that Fraud Detect regularly incorrectly flagged legitimate public benefits claims as fraudulent, leading to the wrongful reduction, denial, and recollection of public benefits for eligible recipients. Used by California's Employment Development Department during the COVID-19 pandemic to detect welfare fraud, Fraud Detect led to the suspension of 1.1 million claims, of which at least 600,000 were discovered to be legitimate.",Entity - AI algorithm,Responsible Entities,Thomson Reuters Fraud Detect 'incorrectly' identifies fraud,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/thomson-reuters-fraud-detect-incorrectly-identifies-fraud,Incident,,2023,2023,USA,Govt - welfare,California Employment Development Department; Iowa Workforce Development,Thomson Reuters,Fraud Detect,Risk assessment algorithm; Machine learning,Detect and prevent fraud,NGO complaint,Accuracy/reliability; Privacy,Governance; Black box,Financial loss; Privacy loss,,,,,,Legal complaint,,10/2/2024 21:17,https://best-paper-award-ddck.dovetail.com/data/4ctLmr72kOOhxS3GwdqI3T#:v:h=39SdQqgLKjxizdK6TvRtu4
AIAAIC1288,"A fraud detection system developed by Thomson Reuters generated false fraud alerts, leaving hundreds of thousands of legitimate claimants without access to public benefits, according to a legal complaint.  Based on a three-year investigation, a complaint (pdf) filed by privacy non-profit organisation EPIC alleged that Thomson Reuters unlawfully acquired data, including from social media, and used 'harmful AI practices' to build and operate Fraud Detect, an automated tool used to detect and prevent welfare and healthcare insurance fraud in at least 42 US states. The complaint also alleged that Fraud Detect regularly incorrectly flagged legitimate public benefits claims as fraudulent, leading to the wrongful reduction, denial, and recollection of public benefits for eligible recipients. Used by California's Employment Development Department during the COVID-19 pandemic to detect welfare fraud, Fraud Detect led to the suspension of 1.1 million claims, of which at least 600,000 were discovered to be legitimate.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Thomson Reuters Fraud Detect 'incorrectly' identifies fraud,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/thomson-reuters-fraud-detect-incorrectly-identifies-fraud,Incident,,2023,2023,USA,Govt - welfare,California Employment Development Department; Iowa Workforce Development,Thomson Reuters,Fraud Detect,Risk assessment algorithm; Machine learning,Detect and prevent fraud,NGO complaint,Accuracy/reliability; Privacy,Governance; Black box,Financial loss; Privacy loss,,,,,,Legal complaint,,10/2/2024 21:17,https://best-paper-award-ddck.dovetail.com/data/4ctLmr72kOOhxS3GwdqI3T#:v:h=39SdQqgLKjxizdK6TvRtu4
AIAAIC1288,"A fraud detection system developed by Thomson Reuters generated false fraud alerts, leaving hundreds of thousands of legitimate claimants without access to public benefits, according to a legal complaint.  Based on a three-year investigation, a complaint (pdf) filed by privacy non-profit organisation EPIC alleged that Thomson Reuters unlawfully acquired data, including from social media, and used 'harmful AI practices' to build and operate Fraud Detect, an automated tool used to detect and prevent welfare and healthcare insurance fraud in at least 42 US states. The complaint also alleged that Fraud Detect regularly incorrectly flagged legitimate public benefits claims as fraudulent, leading to the wrongful reduction, denial, and recollection of public benefits for eligible recipients. Used by California's Employment Development Department during the COVID-19 pandemic to detect welfare fraud, Fraud Detect led to the suspension of 1.1 million claims, of which at least 600,000 were discovered to be legitimate.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Thomson Reuters Fraud Detect 'incorrectly' identifies fraud,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/thomson-reuters-fraud-detect-incorrectly-identifies-fraud,Incident,,2023,2023,USA,Govt - welfare,California Employment Development Department; Iowa Workforce Development,Thomson Reuters,Fraud Detect,Risk assessment algorithm; Machine learning,Detect and prevent fraud,NGO complaint,Accuracy/reliability; Privacy,Governance; Black box,Financial loss; Privacy loss,,,,,,Legal complaint,,10/2/2024 21:17,https://best-paper-award-ddck.dovetail.com/data/4ctLmr72kOOhxS3GwdqI3T#:v:h=39SdQqgLKjxizdK6TvRtu4
AIAAIC1288,"A fraud detection system developed by Thomson Reuters generated false fraud alerts, leaving hundreds of thousands of legitimate claimants without access to public benefits, according to a legal complaint.  Based on a three-year investigation, a complaint (pdf) filed by privacy non-profit organisation EPIC alleged that Thomson Reuters unlawfully acquired data, including from social media, and used 'harmful AI practices' to build and operate Fraud Detect, an automated tool used to detect and prevent welfare and healthcare insurance fraud in at least 42 US states. The complaint also alleged that Fraud Detect regularly incorrectly flagged legitimate public benefits claims as fraudulent, leading to the wrongful reduction, denial, and recollection of public benefits for eligible recipients. Used by California's Employment Development Department during the COVID-19 pandemic to detect welfare fraud, Fraud Detect led to the suspension of 1.1 million claims, of which at least 600,000 were discovered to be legitimate.",Entity - AI developer company,Responsible Entities,Thomson Reuters Fraud Detect 'incorrectly' identifies fraud,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/thomson-reuters-fraud-detect-incorrectly-identifies-fraud,Incident,,2023,2023,USA,Govt - welfare,California Employment Development Department; Iowa Workforce Development,Thomson Reuters,Fraud Detect,Risk assessment algorithm; Machine learning,Detect and prevent fraud,NGO complaint,Accuracy/reliability; Privacy,Governance; Black box,Financial loss; Privacy loss,,,,,,Legal complaint,,10/2/2024 21:17,https://best-paper-award-ddck.dovetail.com/data/4ctLmr72kOOhxS3GwdqI3T#:v:h=39SdQqgLKjxizdK6TvRtu4
AIAAIC1680,"In one of the most popular videos circulating online, X user Joao transformed himself into Republican Vice Presidential candidate J.D. Vance, Meta CEO Mark Zuckerberg, andactors Hugh Grant and George Clooney.",Cause - Human causes - Human abuse of AI tools,Cause,Deep Cam Live AI impersonator prompts misuse fears,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deep-cam-live-ai-impersonator-prompts-misuse-fears,Issue,2024,2024,2024,Global,Media/entertainment/sports/arts,,,Deep Live Cam,Machine learning; Neural network; Deep learning,"Replicate voice, face",Product demonstration/release/launch,Dual/multi-use; Liability; Privacy; Safety; Security,Governance; Privacy,Financial loss; Harassment; Privacy loss,,,,,,,,9/26/2024 23:07,https://best-paper-award-ddck.dovetail.com/data/1LxNAYv0ebKt2inx2Qe6mc#:v:h=3bVnfDhgIYbBH3DpKdeWGd
AIAAIC1680,"In one of the most popular videos circulating online, X user Joao transformed himself into Republican Vice Presidential candidate J.D. Vance, Meta CEO Mark Zuckerberg, andactors Hugh Grant and George Clooney.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deep Cam Live AI impersonator prompts misuse fears,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deep-cam-live-ai-impersonator-prompts-misuse-fears,Issue,2024,2024,2024,Global,Media/entertainment/sports/arts,,,Deep Live Cam,Machine learning; Neural network; Deep learning,"Replicate voice, face",Product demonstration/release/launch,Dual/multi-use; Liability; Privacy; Safety; Security,Governance; Privacy,Financial loss; Harassment; Privacy loss,,,,,,,,9/26/2024 23:07,https://best-paper-award-ddck.dovetail.com/data/1LxNAYv0ebKt2inx2Qe6mc#:v:h=3bVnfDhgIYbBH3DpKdeWGd
AIAAIC0971,"A pair of lawsuits alleged that Amazon failed to inform customers about its use of facial and body biometrics scanning at its cashierless Go retail stores in New York for over a year.  According to a class-action lawsuit filed by Rodriguez Perez, Amazon had not informed him that his body and palm were scanned. Another suit, filed in February 2023 by Richard McCall, claims his palm was scanned.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Amazon Go fails to inform NYC customers about facial recognition,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-go-fails-to-inform-nyc-customers-about-facial-recognition,Incident,,2023,2023,USA,Retail,Amazon,Amazon,Just Walk Out,Facial recognition; Computer vision; Deep learning,Verify identity,Lawsuit filing/litigation,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,Litigation,,10/13/2024 22:25,https://best-paper-award-ddck.dovetail.com/data/4weXgJzYx9XhAQKBkzduCA#:v:h=3f72UFhi2itfToO52Jv2i9
AIAAIC0971,"A pair of lawsuits alleged that Amazon failed to inform customers about its use of facial and body biometrics scanning at its cashierless Go retail stores in New York for over a year.  According to a class-action lawsuit filed by Rodriguez Perez, Amazon had not informed him that his body and palm were scanned. Another suit, filed in February 2023 by Richard McCall, claims his palm was scanned.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Amazon Go fails to inform NYC customers about facial recognition,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-go-fails-to-inform-nyc-customers-about-facial-recognition,Incident,,2023,2023,USA,Retail,Amazon,Amazon,Just Walk Out,Facial recognition; Computer vision; Deep learning,Verify identity,Lawsuit filing/litigation,Privacy,Governance; Privacy; Marketing,Privacy loss,,,,,,Litigation,,10/13/2024 22:25,https://best-paper-award-ddck.dovetail.com/data/4weXgJzYx9XhAQKBkzduCA#:v:h=3f72UFhi2itfToO52Jv2i9
AIAAIC1519,"A dataset used to train Google and Meta large language models was trained on racist, pornographic, and copyright-protected web content, raising safety, privacy and other concerns. A joint Washington Post/Allen Institute for AI investigation discovered that C4 used content from Reddit, notorious message board 4chan, white supremacy site Stormfront, and far-right site Kiwi Farms, effectively hard-baking huge volumes of offensive content of every conceivable kind into the data.  The investigation also found that Russia government news website RT and US hard right-wing political channel Breitbart were amongst the sites used to train C4. Both sites are known for their highly skewed political views and tendency to create and amplify false stories. It also found that C4 included content from sites such as flvoters.com, raising concerns about the privacy of US voters in particular. According to the Washington Post, the copyright symbol appeared over 200 million times in the C4 dataset. Copyright has become a major issue for generative AI systems. The Post said it’s 'analysis suggests more legal challenges may be on the way.' The investigation raised questions about the safety and security of the dataset and the machine learning systems trained on it, the privacy of web users, abuse of copyright, bias, and the veracity of its creators' marketing claims.",Cause - no specific info,Cause,"C4 dataset is trained on unsafe, copyright-protected web content",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/c4-dataset-is-trained-on-unsafe-copyright-protected-web-content,Issue,,2023,2023,USA,Technology,Google,Google,C4,Dataset/database,Train large language models,Media investigation,Bias/discrimination - religion; Copyright; Mis/disinformation; Privacy; Safety,Governance; Black box; Marketing,Copyright loss; Privacy loss,,,,,,,,9/27/2024 0:25,https://best-paper-award-ddck.dovetail.com/data/39lIn8k2S1on32wwE57zbA#:v:h=3h9vRrgvq7LpNIDTBpWkYW
AIAAIC1519,"A dataset used to train Google and Meta large language models was trained on racist, pornographic, and copyright-protected web content, raising safety, privacy and other concerns. A joint Washington Post/Allen Institute for AI investigation discovered that C4 used content from Reddit, notorious message board 4chan, white supremacy site Stormfront, and far-right site Kiwi Farms, effectively hard-baking huge volumes of offensive content of every conceivable kind into the data.  The investigation also found that Russia government news website RT and US hard right-wing political channel Breitbart were amongst the sites used to train C4. Both sites are known for their highly skewed political views and tendency to create and amplify false stories. It also found that C4 included content from sites such as flvoters.com, raising concerns about the privacy of US voters in particular. According to the Washington Post, the copyright symbol appeared over 200 million times in the C4 dataset. Copyright has become a major issue for generative AI systems. The Post said it’s 'analysis suggests more legal challenges may be on the way.' The investigation raised questions about the safety and security of the dataset and the machine learning systems trained on it, the privacy of web users, abuse of copyright, bias, and the veracity of its creators' marketing claims.",Entity - AI developer company,Responsible Entities,"C4 dataset is trained on unsafe, copyright-protected web content",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/c4-dataset-is-trained-on-unsafe-copyright-protected-web-content,Issue,,2023,2023,USA,Technology,Google,Google,C4,Dataset/database,Train large language models,Media investigation,Bias/discrimination - religion; Copyright; Mis/disinformation; Privacy; Safety,Governance; Black box; Marketing,Copyright loss; Privacy loss,,,,,,,,9/27/2024 0:25,https://best-paper-award-ddck.dovetail.com/data/39lIn8k2S1on32wwE57zbA#:v:h=3h9vRrgvq7LpNIDTBpWkYW
AIAAIC1519,"A dataset used to train Google and Meta large language models was trained on racist, pornographic, and copyright-protected web content, raising safety, privacy and other concerns. A joint Washington Post/Allen Institute for AI investigation discovered that C4 used content from Reddit, notorious message board 4chan, white supremacy site Stormfront, and far-right site Kiwi Farms, effectively hard-baking huge volumes of offensive content of every conceivable kind into the data.  The investigation also found that Russia government news website RT and US hard right-wing political channel Breitbart were amongst the sites used to train C4. Both sites are known for their highly skewed political views and tendency to create and amplify false stories. It also found that C4 included content from sites such as flvoters.com, raising concerns about the privacy of US voters in particular. According to the Washington Post, the copyright symbol appeared over 200 million times in the C4 dataset. Copyright has become a major issue for generative AI systems. The Post said it’s 'analysis suggests more legal challenges may be on the way.' The investigation raised questions about the safety and security of the dataset and the machine learning systems trained on it, the privacy of web users, abuse of copyright, bias, and the veracity of its creators' marketing claims.",Incident - organization-driven - problematic database used for AI training,Incident Type,"C4 dataset is trained on unsafe, copyright-protected web content",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/c4-dataset-is-trained-on-unsafe-copyright-protected-web-content,Issue,,2023,2023,USA,Technology,Google,Google,C4,Dataset/database,Train large language models,Media investigation,Bias/discrimination - religion; Copyright; Mis/disinformation; Privacy; Safety,Governance; Black box; Marketing,Copyright loss; Privacy loss,,,,,,,,9/27/2024 0:25,https://best-paper-award-ddck.dovetail.com/data/39lIn8k2S1on32wwE57zbA#:v:h=3h9vRrgvq7LpNIDTBpWkYW
AIAAIC1498,"Actress Scarlett Johansson accused OpenAI of using a voice “eerily similar” to hers for their new GPT-4o chatbot without her consent. GPT-4o is the latest AI model by OpenAI that can process text, audio, and visual inputs and generate corresponding outputs. It offers a voice chat feature with five distinct output voices for lifelike interactions. One of the voices, Sky, caused controversy over its similarity to Johansson’s voice in the movie Her. Johansson expressed shock and anger at the similarity between her voice and the AI’s, stating that even her closest friends and news outlets could not tell the difference. She also hired lawyers  to investigate how the company created the voice. OpenAI’s co-founder, Sam Altman, is reported to have approached Johansson with a request to use her voice likeness in September, however Johansson declined the offer. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,OpenAI accused of AI generating Scarlett Johansson's voice without her consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-accused-of-using-scarlett-johanssons-voice-without-consent-to-train,Issue,,2024,2024,Global,Media/entertainment/sports/arts,OpenAI,OpenAI,GPT-4o,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis; Deepfake - audio; Chatbot,,User comments/complaints,Personality rights,Governance; Marketing,Personality rights loss,,,Reputational damage,,,,,10/12/2024 0:57,https://best-paper-award-ddck.dovetail.com/data/2NRGV0U0DeSuj1YdvpNoap#:v:h=3hpksuOfIedddxAk2tEmGQ
AIAAIC1498,"Actress Scarlett Johansson accused OpenAI of using a voice “eerily similar” to hers for their new GPT-4o chatbot without her consent. GPT-4o is the latest AI model by OpenAI that can process text, audio, and visual inputs and generate corresponding outputs. It offers a voice chat feature with five distinct output voices for lifelike interactions. One of the voices, Sky, caused controversy over its similarity to Johansson’s voice in the movie Her. Johansson expressed shock and anger at the similarity between her voice and the AI’s, stating that even her closest friends and news outlets could not tell the difference. She also hired lawyers  to investigate how the company created the voice. OpenAI’s co-founder, Sam Altman, is reported to have approached Johansson with a request to use her voice likeness in September, however Johansson declined the offer. ",Entity - AI developer company,Responsible Entities,OpenAI accused of AI generating Scarlett Johansson's voice without her consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-accused-of-using-scarlett-johanssons-voice-without-consent-to-train,Issue,,2024,2024,Global,Media/entertainment/sports/arts,OpenAI,OpenAI,GPT-4o,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis; Deepfake - audio; Chatbot,,User comments/complaints,Personality rights,Governance; Marketing,Personality rights loss,,,Reputational damage,,,,,10/12/2024 0:57,https://best-paper-award-ddck.dovetail.com/data/2NRGV0U0DeSuj1YdvpNoap#:v:h=3hpksuOfIedddxAk2tEmGQ
AIAAIC1498,"Actress Scarlett Johansson accused OpenAI of using a voice “eerily similar” to hers for their new GPT-4o chatbot without her consent. GPT-4o is the latest AI model by OpenAI that can process text, audio, and visual inputs and generate corresponding outputs. It offers a voice chat feature with five distinct output voices for lifelike interactions. One of the voices, Sky, caused controversy over its similarity to Johansson’s voice in the movie Her. Johansson expressed shock and anger at the similarity between her voice and the AI’s, stating that even her closest friends and news outlets could not tell the difference. She also hired lawyers  to investigate how the company created the voice. OpenAI’s co-founder, Sam Altman, is reported to have approached Johansson with a request to use her voice likeness in September, however Johansson declined the offer. ",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,OpenAI accused of AI generating Scarlett Johansson's voice without her consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-accused-of-using-scarlett-johanssons-voice-without-consent-to-train,Issue,,2024,2024,Global,Media/entertainment/sports/arts,OpenAI,OpenAI,GPT-4o,Generative AI; Machine learning; Neural network; Deep learning; NLP/text analysis; Deepfake - audio; Chatbot,,User comments/complaints,Personality rights,Governance; Marketing,Personality rights loss,,,Reputational damage,,,,,10/12/2024 0:57,https://best-paper-award-ddck.dovetail.com/data/2NRGV0U0DeSuj1YdvpNoap#:v:h=3hpksuOfIedddxAk2tEmGQ
AIAAIC1730,"US restaurant chain Steak 'n Shake is being sued in Illinois for allegedly violating the state's Biometric Information Privacy Act (BIPA) through its use of facial recognition. Initiated by plaintiff Michael Massel, the lawsuit claims that the fast-food chain unlawfully collected and storedcustomers' facial biometric data through self-service kiosks without obtaining proper consent or providing adequatenotice, as mandated by BIPA. The kiosks, which were introduced in 2024, use facial recognition to facilitate customer orders and manage loyalty rewards.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Steak 'n Shake sued for alleged facial biometric violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/steak-n-shake-sued-for-alleged-facial-biometric-violations,Incident,2024,2024,2024,USA,Travel/hospitality,Steak ‘n Shake,PopID,PopPay,Facial recognition,Verify identity; Pay for meals,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/PBiARmaNoWjUPbGLIGVnn#:v:h=3jvFcaJbX12MWgHVxscRYy
AIAAIC1730,"US restaurant chain Steak 'n Shake is being sued in Illinois for allegedly violating the state's Biometric Information Privacy Act (BIPA) through its use of facial recognition. Initiated by plaintiff Michael Massel, the lawsuit claims that the fast-food chain unlawfully collected and storedcustomers' facial biometric data through self-service kiosks without obtaining proper consent or providing adequatenotice, as mandated by BIPA. The kiosks, which were introduced in 2024, use facial recognition to facilitate customer orders and manage loyalty rewards.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Steak 'n Shake sued for alleged facial biometric violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/steak-n-shake-sued-for-alleged-facial-biometric-violations,Incident,2024,2024,2024,USA,Travel/hospitality,Steak ‘n Shake,PopID,PopPay,Facial recognition,Verify identity; Pay for meals,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/PBiARmaNoWjUPbGLIGVnn#:v:h=3jvFcaJbX12MWgHVxscRYy
AIAAIC1730,"US restaurant chain Steak 'n Shake is being sued in Illinois for allegedly violating the state's Biometric Information Privacy Act (BIPA) through its use of facial recognition. Initiated by plaintiff Michael Massel, the lawsuit claims that the fast-food chain unlawfully collected and storedcustomers' facial biometric data through self-service kiosks without obtaining proper consent or providing adequatenotice, as mandated by BIPA. The kiosks, which were introduced in 2024, use facial recognition to facilitate customer orders and manage loyalty rewards.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Steak 'n Shake sued for alleged facial biometric violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/steak-n-shake-sued-for-alleged-facial-biometric-violations,Incident,2024,2024,2024,USA,Travel/hospitality,Steak ‘n Shake,PopID,PopPay,Facial recognition,Verify identity; Pay for meals,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/PBiARmaNoWjUPbGLIGVnn#:v:h=3jvFcaJbX12MWgHVxscRYy
AIAAIC1730,"US restaurant chain Steak 'n Shake is being sued in Illinois for allegedly violating the state's Biometric Information Privacy Act (BIPA) through its use of facial recognition. Initiated by plaintiff Michael Massel, the lawsuit claims that the fast-food chain unlawfully collected and storedcustomers' facial biometric data through self-service kiosks without obtaining proper consent or providing adequatenotice, as mandated by BIPA. The kiosks, which were introduced in 2024, use facial recognition to facilitate customer orders and manage loyalty rewards.",Cause - organization causes - legal non-compliance,Cause,Steak 'n Shake sued for alleged facial biometric violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/steak-n-shake-sued-for-alleged-facial-biometric-violations,Incident,2024,2024,2024,USA,Travel/hospitality,Steak ‘n Shake,PopID,PopPay,Facial recognition,Verify identity; Pay for meals,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/PBiARmaNoWjUPbGLIGVnn#:v:h=3jvFcaJbX12MWgHVxscRYy
AIAAIC1012,"The commissioner singled out (pdf) the retailer's failure to properly notify customers of its use of the technology or obtain consent to collect and use their personal data. It also said that even if the stores had obtained consent, they were required to demonstrate a reasonable purpose for collection and use, which Canadian Tire had also failed to do.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Canadian Tire covertly uses facial recognition to collect user data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/canadian-tire-facial-recognition,Issue,,2023,2023,Canada,Retail,Canadian Tire,AxxonSoft; FaceFirst,"Face PSIM, FaceFrist",Facial recognition,"Strengthen security, safety",Regulatory inquiry/investigation,Privacy; Accuracy/reliability,Governance; Privacy; Marketing,Privacy loss,,,,System removal,,,,10/11/2024 20:09,https://best-paper-award-ddck.dovetail.com/data/4bfJw8kJsXqvccMMbVyEwL#:v:h=3m9Me9kC8hGzWDMt1T0dFh
AIAAIC1692,the websites were developed and deployed by an assortment of companies and individuals in,Entity - malicious human,Responsible Entities,San Francisco City Attorney sues 16 denudification apps,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-francisco-city-attorney-sues-16-denudification-apps,Incident,,2024,2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",,Deepfake - image; Machine learning,Undress people,Lawsuit filing/litigation,Ethics/values; Privacy; Safety,Governance,Anxiety/distress; Financial loss; Harassment/bullying; Privacy loss,,,,,,,,10/18/2024 14:23,https://best-paper-award-ddck.dovetail.com/data/96DTYpYxcFqkuVOJeWfX0#:v:h=3paAMdn34gO1DxSCW8UObN
AIAAIC1692,the websites were developed and deployed by an assortment of companies and individuals in,"Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,San Francisco City Attorney sues 16 denudification apps,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-francisco-city-attorney-sues-16-denudification-apps,Incident,,2024,2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",,Deepfake - image; Machine learning,Undress people,Lawsuit filing/litigation,Ethics/values; Privacy; Safety,Governance,Anxiety/distress; Financial loss; Harassment/bullying; Privacy loss,,,,,,,,10/18/2024 14:23,https://best-paper-award-ddck.dovetail.com/data/96DTYpYxcFqkuVOJeWfX0#:v:h=3paAMdn34gO1DxSCW8UObN
AIAAIC1521,"A report by video research company IPVM revealed that Shanghai's Xuhui District completed the implementation of a facial recognition system that specifically detects ""Uyghur ethnicity"" based on facial features across thousands of cameras. ",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,"Shanghai triples facial urveillance in Xuhui district, raising concerns",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/shanghai-plans-to-triple-facial-surveillance-in-xuhui-district,Issue,,2024,2024,China,Govt - police,,,,Attribute recognition; Facial recognition,Identify and control ethnic minorities,Media investigation,Human/civil rights; Privacy,,Privacy loss,,,,,,,,10/2/2024 12:26,https://best-paper-award-ddck.dovetail.com/data/5Ah0qWMtocupQ6feMdKH73#:v:h=3q4F62a8owRjwqg1xsdjvZ
AIAAIC1096,"Pro-China operatives reputedly spread disinformation about an experimental US military weapon that allegedly caused the August 2023 Maui wildfires. Starting mid-August 2023, the campaign used apparently AI-generated photographs and text to allege the British intelligence service MI6 had revealed that the US military used a 'weather weapon' to start the wildfires. According to a report by NewsGuard, the conspiracy theory could be traced to a post on Chinese platform 163.com in early August.",Incident - organization-driven - problematic AI implementation,Incident Type,China uses AI to accuse US of starting Maui wildfires,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-flood-warning-system-false-alerts,Incident,,2023,2023,USA,Politics,Government of China,Government of China,,"Deepfake - image, video, audio; Machine learning",Scare/confuse/destabilise,Research study/report,Mis/disinformation,Governance; Marketing,Manipulation,,,,,,,,10/30/2024 16:40,https://best-paper-award-ddck.dovetail.com/data/70vg9Jv4ZaReF0BmWvugR1#:v:h=3qd4XC0FiTZQOanGcNZtQ4
AIAAIC1163,"A video in which US President Joe Biden appeared to call for a military draft was created with AI, according to experts.  The clip, which was based on a video showing President Biden speaking about the cost of insulin, was first flagged by Meta during the early days of the 2023 Israel-Hamas war, though a longer version had been shared in February 2023 by Conservative activist Jack Posobiec and Canadian website Post Millennial. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,President Biden calls for US draft deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/president-biden-calls-for-us-draft-deepfake,Incident,,2023,2023,USA,Politics,,,,"Deepfake - audio, video; Machine learning",Manipulate public opinion,,Mis/disinformation,Governance; Marketing,Manipulation; Reputational damage,,,,,,,,10/24/2024 21:19,https://best-paper-award-ddck.dovetail.com/data/3kgMgWP6QN3HRIFGKLzNvs#:v:h=3sq0K7igMECoBoYt4Nc5FJ
AIAAIC0972,"Actor Dan Dewhirst publicly complained that his likeness had been misused by VTV, causing him distress, damaging his reputation and possibly losing him clients.",Incident - organization-driven - problematic AI implementation,Incident Type,Deepfake news anchors claim Venezuela economic health,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-news-anchors-claim-venezuela-economic-health,Incident,,2023,2023,Venezuela,Politics,House of News; Venezolana de Televisión,House of News; Synthesia,Synthesia,Deepfake - audio; video; Machine learning,Promote government,Media investigation,Mis/disinformation; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 19:20,https://best-paper-award-ddck.dovetail.com/data/1tCasuKj0MMyAXzBALBYBv#:v:h=3sAfbxU5KOhgyRTZCBKURT
AIAAIC0972,"Actor Dan Dewhirst publicly complained that his likeness had been misused by VTV, causing him distress, damaging his reputation and possibly losing him clients.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Deepfake news anchors claim Venezuela economic health,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-news-anchors-claim-venezuela-economic-health,Incident,,2023,2023,Venezuela,Politics,House of News; Venezolana de Televisión,House of News; Synthesia,Synthesia,Deepfake - audio; video; Machine learning,Promote government,Media investigation,Mis/disinformation; Ethics/values,Governance; Marketing,,,,,,,,,10/30/2024 19:20,https://best-paper-award-ddck.dovetail.com/data/1tCasuKj0MMyAXzBALBYBv#:v:h=3sAfbxU5KOhgyRTZCBKURT
AIAAIC1060,"Russian private military company the Wagner Group, which has reputedly become active in Burkina Faso. Russia has been deploying deepfakes in its war with Ukraine, notably a faked video of Ukraine president Volodymyr Zelenskyy instructing his army to lay down their arms and surrender.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Deepfake 'Pan Africanists' support Burkina Faso military junta,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pan-africanists-support-burkina-faso-junta,Incident,,2023,2023,Burkina Faso,Politics,Wagner Group; XCorp/xAI/Twitter; Facebook/WhatsApp,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation,Damage to national security,,,,,,,10/30/2024 17:01,https://best-paper-award-ddck.dovetail.com/data/1ZeKkL2CUQfEYHb4trbHH0#:v:h=3trHYQWZmbCOPwK0NIVlTw
AIAAIC1060,"Russian private military company the Wagner Group, which has reputedly become active in Burkina Faso. Russia has been deploying deepfakes in its war with Ukraine, notably a faked video of Ukraine president Volodymyr Zelenskyy instructing his army to lay down their arms and surrender.",Incident - organization-driven - problematic AI implementation,Incident Type,Deepfake 'Pan Africanists' support Burkina Faso military junta,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pan-africanists-support-burkina-faso-junta,Incident,,2023,2023,Burkina Faso,Politics,Wagner Group; XCorp/xAI/Twitter; Facebook/WhatsApp,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation,Damage to national security,,,,,,,10/30/2024 17:01,https://best-paper-award-ddck.dovetail.com/data/1ZeKkL2CUQfEYHb4trbHH0#:v:h=3trHYQWZmbCOPwK0NIVlTw
AIAAIC1060,"Russian private military company the Wagner Group, which has reputedly become active in Burkina Faso. Russia has been deploying deepfakes in its war with Ukraine, notably a faked video of Ukraine president Volodymyr Zelenskyy instructing his army to lay down their arms and surrender.",Cause - Government/organization - Manipulating people's minds,Cause,Deepfake 'Pan Africanists' support Burkina Faso military junta,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pan-africanists-support-burkina-faso-junta,Incident,,2023,2023,Burkina Faso,Politics,Wagner Group; XCorp/xAI/Twitter; Facebook/WhatsApp,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation,Damage to national security,,,,,,,10/30/2024 17:01,https://best-paper-award-ddck.dovetail.com/data/1ZeKkL2CUQfEYHb4trbHH0#:v:h=3trHYQWZmbCOPwK0NIVlTw
AIAAIC1728,"the DPA's investigation revealed that Clearview AIfailed to comply with data access requests and did not have a legal basis for processing the biometric data ofDutch citizens. The authority highlighted that collecting and using biometric data, like facial images, is generally prohibited underGDPR unless specific exceptions apply, which Clearview could not demonstrate.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Dutch regulator fines Clearview AI for privacy violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dutch-regulator-fines-clearview-ai,Incident,,2024,2024,Netherlands,Multiple,Clearview AI,Clearview AI,Clearview AI,Facial recognition; Machine learning,Identify individuals,Regulatory action,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:35,https://best-paper-award-ddck.dovetail.com/data/1C4UyEheRNvTZLRRZsqSJP#:v:h=3uCkBAv5xfLTUbxp3lHpsO
AIAAIC1728,"the DPA's investigation revealed that Clearview AIfailed to comply with data access requests and did not have a legal basis for processing the biometric data ofDutch citizens. The authority highlighted that collecting and using biometric data, like facial images, is generally prohibited underGDPR unless specific exceptions apply, which Clearview could not demonstrate.",Cause - organization causes - legal non-compliance,Cause,Dutch regulator fines Clearview AI for privacy violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dutch-regulator-fines-clearview-ai,Incident,,2024,2024,Netherlands,Multiple,Clearview AI,Clearview AI,Clearview AI,Facial recognition; Machine learning,Identify individuals,Regulatory action,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:35,https://best-paper-award-ddck.dovetail.com/data/1C4UyEheRNvTZLRRZsqSJP#:v:h=3uCkBAv5xfLTUbxp3lHpsO
AIAAIC1296,"A group of hackers gained access to AI recruitment chatbot Chattr, revealing sensitive information about job applicants, fast food franchises, and Chattr itself. Pseudonymous hacker MRBruh and others discovered that Chattr had inadvertently exposed data about itself, its customers - specifically Chick-fil-A and Subway - and their job applicants, through an incorrect Firebase configuration, including personal names, telephone numbers, email addresses, passwords, and messages. The hack also revealed how Chattr's system worked, including the AI appearing to have the ability to accept or deny job applicants automatically. Chattr secured its system after the hack was made public, though failed to acknowledge publicly the incident.",Cause - AI causes - potential AI bias (racism - inequality) ,Cause,AI hiring chatbot hack violates applicants' privacy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-hiring-chatbot-hack-violates-applicants-privacy,Incident,,2024,2024,USA,Business/professional services; Food/food services,"Applebees, Arbys, Chick-fil-A, DunkinDonuts, IHOP, KFC, Shoneys, Subway, Tacobell, Target, Wendys",Chattr,Chattr,Chatbot; Machine learning; Neural network; Deep learning; Machine learning; Reinforcement learning,Recruit employees,White-hat hack,Confidentiality; Privacy; Security,Governance,Privacy loss,,,,,,,,10/4/2024 14:26,https://best-paper-award-ddck.dovetail.com/data/5XiFZ25AMksPdlUlJ2Qrrz#:v:h=3vfINotb9IGtbQacXK1QDG
AIAAIC1237,"High-profile AI image generators such as DALL-E and Stable Diffusion memorise images from the data they are trained on, raising concerns about potential copyright and privacy violations. Researchers at Google Deepmind, Princeton and other US universities extracted over one thousand training images from DALL-E, Google's Imagen, and Stable Diffusion, including photographs, film stills, copyrighted press photos, and trademarked company logos, and discovered that many of them were re-generated nearly exactly.",Entity - AI algorithm,Responsible Entities,Image-generation AIs memorise training images,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/image-generation-ais-memorise-training-images,Issue,2022,2023,2023,Global,Multiple,"Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace",Google; OpenAI; Stability AI,DALL-E; Imagen; Stable Diffusion,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Research study/report,Copyright; Privacy,Governance,IP/copyright loss; Privacy loss,,,,,,,,10/6/2024 23:47,https://best-paper-award-ddck.dovetail.com/data/64MgH0sdqN50AnnPT8bjZU#:v:h=3vFJbzciAIoNQWHphfjqkz
AIAAIC1237,"High-profile AI image generators such as DALL-E and Stable Diffusion memorise images from the data they are trained on, raising concerns about potential copyright and privacy violations. Researchers at Google Deepmind, Princeton and other US universities extracted over one thousand training images from DALL-E, Google's Imagen, and Stable Diffusion, including photographs, film stills, copyrighted press photos, and trademarked company logos, and discovered that many of them were re-generated nearly exactly.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Image-generation AIs memorise training images,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/image-generation-ais-memorise-training-images,Issue,2022,2023,2023,Global,Multiple,"Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace",Google; OpenAI; Stability AI,DALL-E; Imagen; Stable Diffusion,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Research study/report,Copyright; Privacy,Governance,IP/copyright loss; Privacy loss,,,,,,,,10/6/2024 23:47,https://best-paper-award-ddck.dovetail.com/data/64MgH0sdqN50AnnPT8bjZU#:v:h=3vFJbzciAIoNQWHphfjqkz
AIAAIC1237,"High-profile AI image generators such as DALL-E and Stable Diffusion memorise images from the data they are trained on, raising concerns about potential copyright and privacy violations. Researchers at Google Deepmind, Princeton and other US universities extracted over one thousand training images from DALL-E, Google's Imagen, and Stable Diffusion, including photographs, film stills, copyrighted press photos, and trademarked company logos, and discovered that many of them were re-generated nearly exactly.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Image-generation AIs memorise training images,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/image-generation-ais-memorise-training-images,Issue,2022,2023,2023,Global,Multiple,"Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace",Google; OpenAI; Stability AI,DALL-E; Imagen; Stable Diffusion,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,Research study/report,Copyright; Privacy,Governance,IP/copyright loss; Privacy loss,,,,,,,,10/6/2024 23:47,https://best-paper-award-ddck.dovetail.com/data/64MgH0sdqN50AnnPT8bjZU#:v:h=3vFJbzciAIoNQWHphfjqkz
AIAAIC1165,"Hollywood actress Scarlett Johansson has taken legal action against an AI app developer for using her name and likeness in an online advert without her consent.  AI image editor Lisa AI started with an old clip of Johansson behind the scenes of Marvel’s 'Black Widow,' before featuring an AI-generated version of Johansson’s voice stating, 'It’s not limited to avatars only. You can also create images with texts and even your AI videos. I think you shouldn’t miss it'. ",Cause - organization causes - poor business ethics,Cause,Scarlett Johansson sues app for using image for AI advert,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/scarlett-johansson-sues-app-for-using-image-for-ai-advert,Incident,,2023,2023,Turkey; USA,Media/entertainment/sports/arts,Convert Yazılım Limited Şirketi,Convert Yazılım Limited Şirketi; Stability AI,Lisa AI: 90s Yearbook & Avatar,"Deepfake - audio, video; Machine learning",Increase visibility,Lawsuit filing/litigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 21:27,https://best-paper-award-ddck.dovetail.com/data/3lcynQ0aOrHnv0o97VAbjn#:v:h=3z5MmBiKRPTFePHbueMNJZ
AIAAIC1165,"Hollywood actress Scarlett Johansson has taken legal action against an AI app developer for using her name and likeness in an online advert without her consent.  AI image editor Lisa AI started with an old clip of Johansson behind the scenes of Marvel’s 'Black Widow,' before featuring an AI-generated version of Johansson’s voice stating, 'It’s not limited to avatars only. You can also create images with texts and even your AI videos. I think you shouldn’t miss it'. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Scarlett Johansson sues app for using image for AI advert,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/scarlett-johansson-sues-app-for-using-image-for-ai-advert,Incident,,2023,2023,Turkey; USA,Media/entertainment/sports/arts,Convert Yazılım Limited Şirketi,Convert Yazılım Limited Şirketi; Stability AI,Lisa AI: 90s Yearbook & Avatar,"Deepfake - audio, video; Machine learning",Increase visibility,Lawsuit filing/litigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 21:27,https://best-paper-award-ddck.dovetail.com/data/3lcynQ0aOrHnv0o97VAbjn#:v:h=3z5MmBiKRPTFePHbueMNJZ
AIAAIC1165,"Hollywood actress Scarlett Johansson has taken legal action against an AI app developer for using her name and likeness in an online advert without her consent.  AI image editor Lisa AI started with an old clip of Johansson behind the scenes of Marvel’s 'Black Widow,' before featuring an AI-generated version of Johansson’s voice stating, 'It’s not limited to avatars only. You can also create images with texts and even your AI videos. I think you shouldn’t miss it'. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Scarlett Johansson sues app for using image for AI advert,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/scarlett-johansson-sues-app-for-using-image-for-ai-advert,Incident,,2023,2023,Turkey; USA,Media/entertainment/sports/arts,Convert Yazılım Limited Şirketi,Convert Yazılım Limited Şirketi; Stability AI,Lisa AI: 90s Yearbook & Avatar,"Deepfake - audio, video; Machine learning",Increase visibility,Lawsuit filing/litigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 21:27,https://best-paper-award-ddck.dovetail.com/data/3lcynQ0aOrHnv0o97VAbjn#:v:h=3z5MmBiKRPTFePHbueMNJZ
AIAAIC1397,"A demonstration of the system showed the system mistakingly interpreting Ms Atkins saying England chief media officer 'Chris Whitty' as 'Christmas', fueling concerns about its accuracy and reliability - which are considered essential in a medical setting.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,NHS plan to AI generate patient notes draws criticism,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/nhs-plan-to-ai-generate-patient-notes-draws-criticism,Issue,,2024,2024,UK,Health,,National Health Service (NHS),,Machine learning,Transcribe medical notes,Product demonstration/release/launch,Accuracy/reliability; Confidentiality; Privacy,,Privacy loss,,,,,,,,10/2/2024 19:16,https://best-paper-award-ddck.dovetail.com/data/6gjEM8N3pHS1AiKhlSKqt9#:v:h=3zfVvepBvj0MxFVjWhozl8
AIAAIC1692,"Nudification websites allow users to upload clothed images of real people, which are then processed by AI to create realistic-looking nude images - usually without their knowledge or consent. These types of sites are known to result in a wide range of harms, including causing considerable anxiety and distress for those targeted, harassment and bullying, loss of privacy, and financial loss through to extortion.",Entity - AI developer company,Responsible Entities,San Francisco City Attorney sues 16 denudification apps,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-francisco-city-attorney-sues-16-denudification-apps,Incident,,2024,2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",,Deepfake - image; Machine learning,Undress people,Lawsuit filing/litigation,Ethics/values; Privacy; Safety,Governance,Anxiety/distress; Financial loss; Harassment/bullying; Privacy loss,,,,,,,,10/12/2024 1:26,https://best-paper-award-ddck.dovetail.com/data/96DTYpYxcFqkuVOJeWfX0#:v:h=3zM8IVatZHDjsZ68yzHKXz
AIAAIC1692,"Nudification websites allow users to upload clothed images of real people, which are then processed by AI to create realistic-looking nude images - usually without their knowledge or consent. These types of sites are known to result in a wide range of harms, including causing considerable anxiety and distress for those targeted, harassment and bullying, loss of privacy, and financial loss through to extortion.",Cause - developer causes - programmed AI with problematic functions,Cause,San Francisco City Attorney sues 16 denudification apps,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-francisco-city-attorney-sues-16-denudification-apps,Incident,,2024,2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",,Deepfake - image; Machine learning,Undress people,Lawsuit filing/litigation,Ethics/values; Privacy; Safety,Governance,Anxiety/distress; Financial loss; Harassment/bullying; Privacy loss,,,,,,,,10/12/2024 1:26,https://best-paper-award-ddck.dovetail.com/data/96DTYpYxcFqkuVOJeWfX0#:v:h=3zM8IVatZHDjsZ68yzHKXz
AIAAIC1692,"Nudification websites allow users to upload clothed images of real people, which are then processed by AI to create realistic-looking nude images - usually without their knowledge or consent. These types of sites are known to result in a wide range of harms, including causing considerable anxiety and distress for those targeted, harassment and bullying, loss of privacy, and financial loss through to extortion.",Incident - organization-driven - problematic AI implementation,Incident Type,San Francisco City Attorney sues 16 denudification apps,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-francisco-city-attorney-sues-16-denudification-apps,Incident,,2024,2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",,Deepfake - image; Machine learning,Undress people,Lawsuit filing/litigation,Ethics/values; Privacy; Safety,Governance,Anxiety/distress; Financial loss; Harassment/bullying; Privacy loss,,,,,,,,10/12/2024 1:26,https://best-paper-award-ddck.dovetail.com/data/96DTYpYxcFqkuVOJeWfX0#:v:h=3zM8IVatZHDjsZ68yzHKXz
AIAAIC1033,"Russian president Valdimir Putin gave a fake address on television and radio stations announcing that Ukrainian forces had invaded Russia, martial law had been declared in the border regions, and that a nationwide military mobilisation had begun.  The broadcast ran in Belgorod, Voronezh, and Rostov, cities in close proximity to Ukraine’s border, and inflamed already high tensions on Russia's borders after a series of military incursions by self-proclaimed Russian  and 'patriots' and armed insurgents.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Putin declares martial law deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/putin-declares-martial-law-deepfake,Incident,,2023,2023,Russia,Politics,,,,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,,Governance; Marketing,,Loss of community wellbeing/cohesion,,,,,,,10/30/2024 17:29,https://best-paper-award-ddck.dovetail.com/data/34Br2W63FNzubTbLbJefbK#:v:h=3A6dKHAW1AyK5iNTstUB24
AIAAIC1700,"Donald Trump came under fire for posting AI-generated images that falsely implied Taylor Swift had endorsed his presidential campaign, prompting alarm and outcry. Shared on Trump's Truth Social platform, the images depict Swift and her fans wearing ""Swifties for Trump"" shirts, along with a prominent image of Swift styled as Uncle Sam, urging voters to support Trump. Accompanying the posts, Trump declared, ""I accept!"" suggesting his approval of this fabricated endorsement.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Donald Trump uses AI to fake Taylor Swift endorsement,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/donald-trump-uses-ai-to-fake-taylor-swift-endorsement,Issue,,2024,2024,USA,Politics; Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Deceive voters,,Ethics/values; Mis/disinformation,Governance,,,,,,,,,10/13/2024 23:00,https://best-paper-award-ddck.dovetail.com/data/29x9mi44lzE1VL1iEqQWMz#:v:h=3CbmbT0LKvPuyuLHo3AfMB
AIAAIC1457,"Michel Janse, a Christian social media influencer, had her face likeness used in a YouTube advert without her consent.  The ad featured Janse’s face “in her bedroom, wearing her clothes” to sell erectile dysfunction pills. Janse Experts speculated the advertisement had been generated by an AI trained on Janse’s regular posts on travel, home decor and wedding planning. Janse complained to YouTube, which took the advert down. ",Cause - Lack of AI control,Cause,Michel Janse deepfake used for advert without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/michel-janse-deepfake-used-for-advert-without-consent,Incident,,2024,2024,USA,Media/entertainment/sports/arts,YouTube,,,Deepfake - video; Machine learning,Generate video,User comments/complaints,Personality rights; Misinformation; Privacy,Governance,"Personality rights loss,  Reputational damage",,,,,,,,10/24/2024 20:57,https://best-paper-award-ddck.dovetail.com/data/4a75GIfmiiPVcztjVebfx1#:v:h=3CB4gf0Whvegs9xHeqBJjj
AIAAIC1457,"Michel Janse, a Christian social media influencer, had her face likeness used in a YouTube advert without her consent.  The ad featured Janse’s face “in her bedroom, wearing her clothes” to sell erectile dysfunction pills. Janse Experts speculated the advertisement had been generated by an AI trained on Janse’s regular posts on travel, home decor and wedding planning. Janse complained to YouTube, which took the advert down. ",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Michel Janse deepfake used for advert without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/michel-janse-deepfake-used-for-advert-without-consent,Incident,,2024,2024,USA,Media/entertainment/sports/arts,YouTube,,,Deepfake - video; Machine learning,Generate video,User comments/complaints,Personality rights; Misinformation; Privacy,Governance,"Personality rights loss,  Reputational damage",,,,,,,,10/24/2024 20:57,https://best-paper-award-ddck.dovetail.com/data/4a75GIfmiiPVcztjVebfx1#:v:h=3CB4gf0Whvegs9xHeqBJjj
AIAAIC1457,"Michel Janse, a Christian social media influencer, had her face likeness used in a YouTube advert without her consent.  The ad featured Janse’s face “in her bedroom, wearing her clothes” to sell erectile dysfunction pills. Janse Experts speculated the advertisement had been generated by an AI trained on Janse’s regular posts on travel, home decor and wedding planning. Janse complained to YouTube, which took the advert down. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Michel Janse deepfake used for advert without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/michel-janse-deepfake-used-for-advert-without-consent,Incident,,2024,2024,USA,Media/entertainment/sports/arts,YouTube,,,Deepfake - video; Machine learning,Generate video,User comments/complaints,Personality rights; Misinformation; Privacy,Governance,"Personality rights loss,  Reputational damage",,,,,,,,10/24/2024 20:57,https://best-paper-award-ddck.dovetail.com/data/4a75GIfmiiPVcztjVebfx1#:v:h=3CB4gf0Whvegs9xHeqBJjj
AIAAIC1457,"Michel Janse, a Christian social media influencer, had her face likeness used in a YouTube advert without her consent.  The ad featured Janse’s face “in her bedroom, wearing her clothes” to sell erectile dysfunction pills. Janse Experts speculated the advertisement had been generated by an AI trained on Janse’s regular posts on travel, home decor and wedding planning. Janse complained to YouTube, which took the advert down. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Michel Janse deepfake used for advert without consent,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/michel-janse-deepfake-used-for-advert-without-consent,Incident,,2024,2024,USA,Media/entertainment/sports/arts,YouTube,,,Deepfake - video; Machine learning,Generate video,User comments/complaints,Personality rights; Misinformation; Privacy,Governance,"Personality rights loss,  Reputational damage",,,,,,,,10/24/2024 20:57,https://best-paper-award-ddck.dovetail.com/data/4a75GIfmiiPVcztjVebfx1#:v:h=3CB4gf0Whvegs9xHeqBJjj
AIAAIC1446,constituted serious omissions regarding the ministry’s compliance with specific provisions of the European Union's GDPR regarding implementation of disputed systems.,Cause - organization causes - legal non-compliance,Cause,Greece fined for AI-powered asylum centre monitoring system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greece-fined-for-ai-powered-asylum-centre-monitoring-system,Incident,,2024,2024,Greece,Govt - immigration,Ministry of Immigration and Asylum,Ministry of Immigration and Asylum,Centaur; Hyperion,Computer vision; Drone; Machine learning; Motion analysis,Monitor asylum centres,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,"EUR 175,000 fine",,,10/2/2024 14:44,https://best-paper-award-ddck.dovetail.com/data/3DmI2hEdtkisj5sDsJPgAG#:v:h=3EAnBpQpGySGhlxjhinnRD
AIAAIC1610,"A French court ruled that the City of Orleans' use of AI-powered audio surveillance is disproportionate and illegal, raising doubts about the legality of other similar systems in the country. Intended to detect ""unusual situations"", the system consisted of microphones installed in public spaces linked to local CCTV cameras.  The court rejected (pdf) the city's argument that no personal data was being processed, stating that the microphones linked to cameras collect information that could identify individuals. The court ruled that even if the system was useful for policing, it ""cannot be considered necessary for the exercise of these powers,"" emphasising that usefulness does not equate to legality or proportionality. The ruling is considered the first victory in France against this kind of AI-powered audio surveillance. The court also ruled that public contracts for such surveillance systems can be challenged in court by organizations like La Quadrature du Net, which brought this case. The decision is seen as a warning to other cities considering similar surveillance technologies, and highlights the need for greater transparency, public consultation, and adherence to fundamental rights when implementing surveillance systems.",Entity - government authorities that adopt AI,Responsible Entities,French court rules City of Orleans use of AI is illegal,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/french-court-rules-city-of-orleans-use-of-ai-is-illegal,Incident,2021,2024,2024,France,Govt - municipal,,Sensivic,Sensivic,Machine learning,Detect abnormal situations,Research study/report,Human/civil rights; Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:37,https://best-paper-award-ddck.dovetail.com/data/6sLCWa6KcDYpuUjZFAOlum#:v:h=3HzgnFaHr4rO25uTxhwOA2
AIAAIC1610,"A French court ruled that the City of Orleans' use of AI-powered audio surveillance is disproportionate and illegal, raising doubts about the legality of other similar systems in the country. Intended to detect ""unusual situations"", the system consisted of microphones installed in public spaces linked to local CCTV cameras.  The court rejected (pdf) the city's argument that no personal data was being processed, stating that the microphones linked to cameras collect information that could identify individuals. The court ruled that even if the system was useful for policing, it ""cannot be considered necessary for the exercise of these powers,"" emphasising that usefulness does not equate to legality or proportionality. The ruling is considered the first victory in France against this kind of AI-powered audio surveillance. The court also ruled that public contracts for such surveillance systems can be challenged in court by organizations like La Quadrature du Net, which brought this case. The decision is seen as a warning to other cities considering similar surveillance technologies, and highlights the need for greater transparency, public consultation, and adherence to fundamental rights when implementing surveillance systems.",Cause - organization causes - legal non-compliance,Cause,French court rules City of Orleans use of AI is illegal,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/french-court-rules-city-of-orleans-use-of-ai-is-illegal,Incident,2021,2024,2024,France,Govt - municipal,,Sensivic,Sensivic,Machine learning,Detect abnormal situations,Research study/report,Human/civil rights; Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:37,https://best-paper-award-ddck.dovetail.com/data/6sLCWa6KcDYpuUjZFAOlum#:v:h=3HzgnFaHr4rO25uTxhwOA2
AIAAIC1610,"A French court ruled that the City of Orleans' use of AI-powered audio surveillance is disproportionate and illegal, raising doubts about the legality of other similar systems in the country. Intended to detect ""unusual situations"", the system consisted of microphones installed in public spaces linked to local CCTV cameras.  The court rejected (pdf) the city's argument that no personal data was being processed, stating that the microphones linked to cameras collect information that could identify individuals. The court ruled that even if the system was useful for policing, it ""cannot be considered necessary for the exercise of these powers,"" emphasising that usefulness does not equate to legality or proportionality. The ruling is considered the first victory in France against this kind of AI-powered audio surveillance. The court also ruled that public contracts for such surveillance systems can be challenged in court by organizations like La Quadrature du Net, which brought this case. The decision is seen as a warning to other cities considering similar surveillance technologies, and highlights the need for greater transparency, public consultation, and adherence to fundamental rights when implementing surveillance systems.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,French court rules City of Orleans use of AI is illegal,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/french-court-rules-city-of-orleans-use-of-ai-is-illegal,Incident,2021,2024,2024,France,Govt - municipal,,Sensivic,Sensivic,Machine learning,Detect abnormal situations,Research study/report,Human/civil rights; Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:37,https://best-paper-award-ddck.dovetail.com/data/6sLCWa6KcDYpuUjZFAOlum#:v:h=3HzgnFaHr4rO25uTxhwOA2
AIAAIC0959,"Tesla's Sentry Mode uses four cameras continuously filming everything around a parked vehicle to protect it against theft and vandalism, with images saved for one hour in the car. Since the investigation began, the Authority said Tesla had made changes to Sentry Mode, include making the cars' headlights flash to indicate to passers-by that filming has begun, and requiring approval from the car's owners in order to begin filming.",Cause - developer causes - programmed AI with problematic functions,Cause,Tesla safety cameras capture neighbourhood movements,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/tesla-safety-cameras-capture-neighbourhood-movements,Incident,2019,2023,2023,Netherlands,Automotive,Tesla,Tesla,Sentry Mode,,Strengthen security,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,System update,,,,10/13/2024 22:28,https://best-paper-award-ddck.dovetail.com/data/19MCJAfQZTeVc663cf6cGX#:v:h=3KmUoPpjcpb7FckNayG1Df
AIAAIC1624,"Household name TV doctors have been ""deepfaked"" in videos promoting health scams, according to a research study. The British Medical Journal (BMJ) found AI-generated videos falsely featuring UK TV doctors, including the late Michael Mosley, Hilary Jones and Rajan Chatterjee, endorsing products for blood pressure and diabetes, and selling items such as hemp gummies.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfakes of UK health expert used to promote health scams,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfakes-of-uk-tv-health-experts-used-to-promote-health-scams,Incident,2023,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - video; Machine learning,Generate video,Industry investigation,Ethics/values; Fraud; Personality rights; Mis/disinformation,Governance; Marketing,Personality rights loss,,,,,,,,10/12/2024 1:21,https://best-paper-award-ddck.dovetail.com/data/pFSly53pGLC6OGZhCpmoX#:v:h=3LD211cG3z9G6AgfETQpXV
AIAAIC1141,"Though X's policies explicitly state that users 'may not share synthetic, manipulated, or out-of-context media,' it did not prevent the clip being widely circulated. However, most copies have since been removed.",Cause - Lack of AI control,Cause,Deepfake recordings depict British Opposition Leader abusing staff,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-recording-depicts-british-opposition-leader-abusing-staff,Incident,,2023,2023,UK,Politics,,,,"Deepfake - audio, video; Machine learning",Damage reputation,,Mis/disinformation,Governance; Marketing,,,,,,,,,10/30/2024 16:24,https://best-paper-award-ddck.dovetail.com/data/1jYlQ4n7SApAMW0EA4pU9h#:v:h=3NQ2M1IP4bu2d7ieqD6ReG
AIAAIC1684,"Critics argue that the plan raises serious concerns about privacy, civil liberties, and the potential for bias in the AI system, specifically:  The use of facial recognition technology on children, who may not fully understand the implications of the technology The potential for the AI system to be biased against certain racial or ethnic groups The lack of transparency and oversight in the collection and use of the facial recognition data The potential for the data to be used for purposes beyond border security, such as surveillance or law enforcement.",Cause - organization/human cause - lack of informed consent & transparency,Cause,US plan to train AI system by scanning migrants' kids faces prompts controversy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/us-plans-to-train-ai-system-by-scanning-migrants-kids-faces,Issue,,2024,2024,USA,Govt - immigration,Department of Homeland Security (DHS),,,Facial recognition,Train AI systems,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:01,https://best-paper-award-ddck.dovetail.com/data/52nVgSbgvAMYokd9QLPhBw#:v:h=3PGM2wnGonCCZjVFuUefiL
AIAAIC1684,"Critics argue that the plan raises serious concerns about privacy, civil liberties, and the potential for bias in the AI system, specifically:  The use of facial recognition technology on children, who may not fully understand the implications of the technology The potential for the AI system to be biased against certain racial or ethnic groups The lack of transparency and oversight in the collection and use of the facial recognition data The potential for the data to be used for purposes beyond border security, such as surveillance or law enforcement.",Cause - AI causes - potential AI bias (racism - inequality) ,Cause,US plan to train AI system by scanning migrants' kids faces prompts controversy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/us-plans-to-train-ai-system-by-scanning-migrants-kids-faces,Issue,,2024,2024,USA,Govt - immigration,Department of Homeland Security (DHS),,,Facial recognition,Train AI systems,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:01,https://best-paper-award-ddck.dovetail.com/data/52nVgSbgvAMYokd9QLPhBw#:v:h=3PGM2wnGonCCZjVFuUefiL
AIAAIC1684,"Critics argue that the plan raises serious concerns about privacy, civil liberties, and the potential for bias in the AI system, specifically:  The use of facial recognition technology on children, who may not fully understand the implications of the technology The potential for the AI system to be biased against certain racial or ethnic groups The lack of transparency and oversight in the collection and use of the facial recognition data The potential for the data to be used for purposes beyond border security, such as surveillance or law enforcement.",Cause - organziation causes - vague policy information,Cause,US plan to train AI system by scanning migrants' kids faces prompts controversy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/us-plans-to-train-ai-system-by-scanning-migrants-kids-faces,Issue,,2024,2024,USA,Govt - immigration,Department of Homeland Security (DHS),,,Facial recognition,Train AI systems,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:01,https://best-paper-award-ddck.dovetail.com/data/52nVgSbgvAMYokd9QLPhBw#:v:h=3PGM2wnGonCCZjVFuUefiL
AIAAIC1190,"But the company has been accused of turning a blind eye to multiple instances of deepfake, non-consensual sexual imagery discovered on its platform.",Cause - developer causes - programmed AI with problematic functions,Cause,CivitAI rewards deepfakes of real people,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-rewards-deepfakes-of-real-people,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,,Ethics/values; Incentivisation; Privacy,,Privacy loss; Loss of integrity,,,,,,,,10/7/2024 0:21,https://best-paper-award-ddck.dovetail.com/data/6e6cFafwvfrKNGbb2KTqBX#:v:h=3QMwhWBFmpYK2YMWhkruJl
AIAAIC1432,"Amazon MGM Studios was accused of trying to rush production using AI voice cloning during actors strikes to avoid a copyright deadline. The original screenwriter of Road House, R. Lance Hill, sued Amazon MGM studios for copyright infringement and accuses them of using extreme measures including AI voice cloning of actors’ voices to rush production of the Road House remake.  Amazon MGM studios denied using generative AI on the roadhouse production.  Use of generative AI during the prolonged Hollywood strike is viewed as sensitive as AI was one of the topics that became a major concern and brought the industry to a standstill.  Ultimately, studios and streaming platforms reached an agreement to seek consent prior to using digital duplicates and to provide remuneration to the talent if used.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Amazon studios lawsuit alleges use of GenAI to clone actors voices,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-studios-accused-of-using-ai-voice-cloning-during-actors-strikes,Incident,,2024,2024,USA,Media/entertainment/sports/arts,Amazon Studios,,,Text-to-speech; Deepfake - audio; Neural network; Deep learning; Machine learning,Generate audio,Lawsuit filing/litigation,"Copyright, Workforce dislocation/replacement",,Copyright loss,,,Reputational damage,,,Litigation,,10/24/2024 21:03,https://best-paper-award-ddck.dovetail.com/data/22yLBdbOP4Z4chxMTb3U7C#:v:h=3ROoDgHSN4gKFB3tARffMf
AIAAIC1432,"Amazon MGM Studios was accused of trying to rush production using AI voice cloning during actors strikes to avoid a copyright deadline. The original screenwriter of Road House, R. Lance Hill, sued Amazon MGM studios for copyright infringement and accuses them of using extreme measures including AI voice cloning of actors’ voices to rush production of the Road House remake.  Amazon MGM studios denied using generative AI on the roadhouse production.  Use of generative AI during the prolonged Hollywood strike is viewed as sensitive as AI was one of the topics that became a major concern and brought the industry to a standstill.  Ultimately, studios and streaming platforms reached an agreement to seek consent prior to using digital duplicates and to provide remuneration to the talent if used.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Amazon studios lawsuit alleges use of GenAI to clone actors voices,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-studios-accused-of-using-ai-voice-cloning-during-actors-strikes,Incident,,2024,2024,USA,Media/entertainment/sports/arts,Amazon Studios,,,Text-to-speech; Deepfake - audio; Neural network; Deep learning; Machine learning,Generate audio,Lawsuit filing/litigation,"Copyright, Workforce dislocation/replacement",,Copyright loss,,,Reputational damage,,,Litigation,,10/24/2024 21:03,https://best-paper-award-ddck.dovetail.com/data/22yLBdbOP4Z4chxMTb3U7C#:v:h=3ROoDgHSN4gKFB3tARffMf
AIAAIC1432,"Amazon MGM Studios was accused of trying to rush production using AI voice cloning during actors strikes to avoid a copyright deadline. The original screenwriter of Road House, R. Lance Hill, sued Amazon MGM studios for copyright infringement and accuses them of using extreme measures including AI voice cloning of actors’ voices to rush production of the Road House remake.  Amazon MGM studios denied using generative AI on the roadhouse production.  Use of generative AI during the prolonged Hollywood strike is viewed as sensitive as AI was one of the topics that became a major concern and brought the industry to a standstill.  Ultimately, studios and streaming platforms reached an agreement to seek consent prior to using digital duplicates and to provide remuneration to the talent if used.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Amazon studios lawsuit alleges use of GenAI to clone actors voices,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-studios-accused-of-using-ai-voice-cloning-during-actors-strikes,Incident,,2024,2024,USA,Media/entertainment/sports/arts,Amazon Studios,,,Text-to-speech; Deepfake - audio; Neural network; Deep learning; Machine learning,Generate audio,Lawsuit filing/litigation,"Copyright, Workforce dislocation/replacement",,Copyright loss,,,Reputational damage,,,Litigation,,10/24/2024 21:03,https://best-paper-award-ddck.dovetail.com/data/22yLBdbOP4Z4chxMTb3U7C#:v:h=3ROoDgHSN4gKFB3tARffMf
AIAAIC1326,"with some saying it was potentially a valuable additional crime-fighting resource, whilst others reckoned it seemed to do very little, was unable to walk up or down stairs, always required assistance, was a waste of resources, and threatened people's privacy. In addition to raising questions about the effectiveness of the Knightscope K5 robot as a crime-fighting tool, the NYPD's decision to stop its use - for the time being -  highlights the careful balance police authorities are seen to have to strike between fighting crime, and protecting the legal rights and ethical concerns of citizens.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,NYPD ends Knightscope K5 security robot trial,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/nypd-ends-knightscope-k5-security-robot-trial,Issue,2015,2023,2024,USA,Govt - police,New York Police Department (NYPD),Knightscope,Knightscope K5,Robotics,Strengthen security,Deployer statement,Effectiveness/value; Privacy,,Privacy loss,,,,Pilot termination,,,,10/2/2024 20:11,https://best-paper-award-ddck.dovetail.com/data/7372OQh5XSUzowoL7rWaoA#:v:h=3T3UTTT9vvGXlSA6SaPZMc
AIAAIC0969,"Adverts for FaceMega, an app that creates AI-generated deepfake videos of Hollywood stars in sexually suggestive poses, have been removed from Facebook and Instagram for violating their adult content policies. NBC News reported that 230 highly charged video ads promoting FaceMega were run across Facebook and Instagram, of which 127 featured Emma Watson and 74 videos featured Scarlett Johansson. Created by Chinese company Ufoto, FaceMega described itself as a tool for creating 'deepfake face swap videos', cost GBP 7.49 a week, and was rated as suitable for ages 'nine and up'. ",Cause - organization causes - legal non-compliance,Cause,FaceMega sexualised face swap ads violate platform policies,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/facemega-sexualised-face-swapping,Incident,,2023,2023,USA,Media/entertainment/sports/arts,Wondershare/Ufoto,Wondershare/Ufoto,Facemega,Deepfake - video; Machine learning,Swap faces,Media investigation,Safety; Copyright,Governance,Reputational damage; Financial loss,,,,App store removal,,,,10/30/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/1kveiSuTHOwau1j1igocK2#:v:h=3TmJKh5aW24D9MR0cs4Cbq
AIAAIC0969,"Adverts for FaceMega, an app that creates AI-generated deepfake videos of Hollywood stars in sexually suggestive poses, have been removed from Facebook and Instagram for violating their adult content policies. NBC News reported that 230 highly charged video ads promoting FaceMega were run across Facebook and Instagram, of which 127 featured Emma Watson and 74 videos featured Scarlett Johansson. Created by Chinese company Ufoto, FaceMega described itself as a tool for creating 'deepfake face swap videos', cost GBP 7.49 a week, and was rated as suitable for ages 'nine and up'. ",Incident - organization-driven - problematic AI implementation,Incident Type,FaceMega sexualised face swap ads violate platform policies,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/facemega-sexualised-face-swapping,Incident,,2023,2023,USA,Media/entertainment/sports/arts,Wondershare/Ufoto,Wondershare/Ufoto,Facemega,Deepfake - video; Machine learning,Swap faces,Media investigation,Safety; Copyright,Governance,Reputational damage; Financial loss,,,,App store removal,,,,10/30/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/1kveiSuTHOwau1j1igocK2#:v:h=3TmJKh5aW24D9MR0cs4Cbq
AIAAIC0969,"Adverts for FaceMega, an app that creates AI-generated deepfake videos of Hollywood stars in sexually suggestive poses, have been removed from Facebook and Instagram for violating their adult content policies. NBC News reported that 230 highly charged video ads promoting FaceMega were run across Facebook and Instagram, of which 127 featured Emma Watson and 74 videos featured Scarlett Johansson. Created by Chinese company Ufoto, FaceMega described itself as a tool for creating 'deepfake face swap videos', cost GBP 7.49 a week, and was rated as suitable for ages 'nine and up'. ",Entity - AI developer company,Responsible Entities,FaceMega sexualised face swap ads violate platform policies,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/facemega-sexualised-face-swapping,Incident,,2023,2023,USA,Media/entertainment/sports/arts,Wondershare/Ufoto,Wondershare/Ufoto,Facemega,Deepfake - video; Machine learning,Swap faces,Media investigation,Safety; Copyright,Governance,Reputational damage; Financial loss,,,,App store removal,,,,10/30/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/1kveiSuTHOwau1j1igocK2#:v:h=3TmJKh5aW24D9MR0cs4Cbq
AIAAIC0969,"Adverts for FaceMega, an app that creates AI-generated deepfake videos of Hollywood stars in sexually suggestive poses, have been removed from Facebook and Instagram for violating their adult content policies. NBC News reported that 230 highly charged video ads promoting FaceMega were run across Facebook and Instagram, of which 127 featured Emma Watson and 74 videos featured Scarlett Johansson. Created by Chinese company Ufoto, FaceMega described itself as a tool for creating 'deepfake face swap videos', cost GBP 7.49 a week, and was rated as suitable for ages 'nine and up'. ",Cause - organization causes - poor business ethics,Cause,FaceMega sexualised face swap ads violate platform policies,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/facemega-sexualised-face-swapping,Incident,,2023,2023,USA,Media/entertainment/sports/arts,Wondershare/Ufoto,Wondershare/Ufoto,Facemega,Deepfake - video; Machine learning,Swap faces,Media investigation,Safety; Copyright,Governance,Reputational damage; Financial loss,,,,App store removal,,,,10/30/2024 19:27,https://best-paper-award-ddck.dovetail.com/data/1kveiSuTHOwau1j1igocK2#:v:h=3TmJKh5aW24D9MR0cs4Cbq
AIAAIC1385,"The Municipality of Trento, Italy, was fined for 'multiple violations' of EU data protection law in its use of AI in street surveillance projects. The country's Garante (DPGP) privacy watchdog ruled that said the data collected for the EU-funded Marvel and Protection projects was insufficiently  anonymous, thereby putting citizens' privacy at risk, and that it had been incorrectly shared with third parties.  The municipality was fined EUR 50,000 (USD 54,225) and instructed to delete all data gathered. It said it would appeal the decision.",Cause - organization causes - legal non-compliance,Cause,Trento council fined for AI citizen surveillance projects,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/trento-council-fined-for-ai-citizen-surveillance-projects,Incident,,2024,2024,Italy,Govt - municipal; Govt - police,Municipality of Trento,Foundation for Research and Technology Hellas (FORTH); Saher Europe,Marvel,Anomaly detection; Computer vision; Facial recognition; Object detection,Increase public safety,Regulatory inquiry/investigation,Privacy; Security,,,Privacy loss,,,,"EUR 50,000 fine",,,10/2/2024 19:21,https://best-paper-award-ddck.dovetail.com/data/35cEBNVTbsyQAmRfJgwiB5#:v:h=3UEo6ve6tuymHxUJLI6cB5
AIAAIC1385,"The Municipality of Trento, Italy, was fined for 'multiple violations' of EU data protection law in its use of AI in street surveillance projects. The country's Garante (DPGP) privacy watchdog ruled that said the data collected for the EU-funded Marvel and Protection projects was insufficiently  anonymous, thereby putting citizens' privacy at risk, and that it had been incorrectly shared with third parties.  The municipality was fined EUR 50,000 (USD 54,225) and instructed to delete all data gathered. It said it would appeal the decision.",Entity - government authorities that adopt AI,Responsible Entities,Trento council fined for AI citizen surveillance projects,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/trento-council-fined-for-ai-citizen-surveillance-projects,Incident,,2024,2024,Italy,Govt - municipal; Govt - police,Municipality of Trento,Foundation for Research and Technology Hellas (FORTH); Saher Europe,Marvel,Anomaly detection; Computer vision; Facial recognition; Object detection,Increase public safety,Regulatory inquiry/investigation,Privacy; Security,,,Privacy loss,,,,"EUR 50,000 fine",,,10/2/2024 19:21,https://best-paper-award-ddck.dovetail.com/data/35cEBNVTbsyQAmRfJgwiB5#:v:h=3UEo6ve6tuymHxUJLI6cB5
AIAAIC1385,"The Municipality of Trento, Italy, was fined for 'multiple violations' of EU data protection law in its use of AI in street surveillance projects. The country's Garante (DPGP) privacy watchdog ruled that said the data collected for the EU-funded Marvel and Protection projects was insufficiently  anonymous, thereby putting citizens' privacy at risk, and that it had been incorrectly shared with third parties.  The municipality was fined EUR 50,000 (USD 54,225) and instructed to delete all data gathered. It said it would appeal the decision.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Trento council fined for AI citizen surveillance projects,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/trento-council-fined-for-ai-citizen-surveillance-projects,Incident,,2024,2024,Italy,Govt - municipal; Govt - police,Municipality of Trento,Foundation for Research and Technology Hellas (FORTH); Saher Europe,Marvel,Anomaly detection; Computer vision; Facial recognition; Object detection,Increase public safety,Regulatory inquiry/investigation,Privacy; Security,,,Privacy loss,,,,"EUR 50,000 fine",,,10/2/2024 19:21,https://best-paper-award-ddck.dovetail.com/data/35cEBNVTbsyQAmRfJgwiB5#:v:h=3UEo6ve6tuymHxUJLI6cB5
AIAAIC0464,AI-powered predictive policing company ,Entity - AI developer company,Responsible Entities,Meta sues predicitve policing Voyager Labs for data scraping,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-sues-voyager-labs-for-data-scraping,Incident,,2023,2023,USA,Govt - police,Los Angeles Police Department (LAPD),Voyager Labs,Voyager Analytics,Machine learning; NLP/text analysis; Pattern recognition; Social media monitoring,Predict crime,Lawsuit filing/litigation,Ethics/values; Human/civil rights; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/13/2024 22:47,https://best-paper-award-ddck.dovetail.com/data/2sSJhCbnyL3YrBSLULSP18#:v:h=3URsPySZ2JPMX4hUefUMuX
AIAAIC1422,A deepfake audio recording appearing to depict a news anchor criticising the US has been amongst a wave of synthetic disinformation spread in the lead up to the general election in Bangladesh. A report by the Financial Times indicated that entities aligned with Bangaldesh government had been using a variety of AI tools to craft deepfake videos and fabricate news segments with the aim of influencing public opinion. The content had been circulated by pro-government media outlets. ,Cause - Government/organization - Manipulating people's minds,Cause,Deepfake news anchor accuses US of Bangladesh election interference,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-news-anchor-accuses-us-of-bangladesh-election-interference,Incident,,2023,2023,Bangladesh,Politics,,HeyGen,HeyGen,"Deepfake - audio, video; Machine learning",Manipulate public opinion,Media investigation,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:15,https://best-paper-award-ddck.dovetail.com/data/7ebJ4Il1gRw0ush9sl7PW4#:v:h=3Y2CIClR0bp358bQJXbOsf
AIAAIC1422,A deepfake audio recording appearing to depict a news anchor criticising the US has been amongst a wave of synthetic disinformation spread in the lead up to the general election in Bangladesh. A report by the Financial Times indicated that entities aligned with Bangaldesh government had been using a variety of AI tools to craft deepfake videos and fabricate news segments with the aim of influencing public opinion. The content had been circulated by pro-government media outlets. ,Entity - government authorities that adopt AI,Responsible Entities,Deepfake news anchor accuses US of Bangladesh election interference,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-news-anchor-accuses-us-of-bangladesh-election-interference,Incident,,2023,2023,Bangladesh,Politics,,HeyGen,HeyGen,"Deepfake - audio, video; Machine learning",Manipulate public opinion,Media investigation,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:15,https://best-paper-award-ddck.dovetail.com/data/7ebJ4Il1gRw0ush9sl7PW4#:v:h=3Y2CIClR0bp358bQJXbOsf
AIAAIC1422,A deepfake audio recording appearing to depict a news anchor criticising the US has been amongst a wave of synthetic disinformation spread in the lead up to the general election in Bangladesh. A report by the Financial Times indicated that entities aligned with Bangaldesh government had been using a variety of AI tools to craft deepfake videos and fabricate news segments with the aim of influencing public opinion. The content had been circulated by pro-government media outlets. ,Incident - organization-driven - problematic AI implementation,Incident Type,Deepfake news anchor accuses US of Bangladesh election interference,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-news-anchor-accuses-us-of-bangladesh-election-interference,Incident,,2023,2023,Bangladesh,Politics,,HeyGen,HeyGen,"Deepfake - audio, video; Machine learning",Manipulate public opinion,Media investigation,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:15,https://best-paper-award-ddck.dovetail.com/data/7ebJ4Il1gRw0ush9sl7PW4#:v:h=3Y2CIClR0bp358bQJXbOsf
AIAAIC1483,"were stolen by fraudsters, ",Cause - Human causes - Human abuse of AI tools,Cause,WPP CEO impersonated in deepfake scam,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/wpp-ceo-impersonated-in-deepfake-scam,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,"Deepfake - audio, video; Machine learning",Defraud,,Fraud,Governance; Marketing,,,,,,,,,10/24/2024 20:40,https://best-paper-award-ddck.dovetail.com/data/6RfixpodKkNk6g9JsscDeL#:v:h=3YTkJLnPgKqKd4VaAHzubY
AIAAIC1680,"Deep Cam Live, a new AI product that enables anyone to replicate someone's else's voice, raised concerns about potential misuse andimpersonation scams. Deep Cam Live is able to produce real-time synthetic voices, faces and video appearances, including deepfakes, with only a single image. The product is supposedly intended for video production, animation, and other creative projects. Its creators claim they are ""committed to evolving the project within legal and ethical frameworks, implementingmeasures like watermarking outputs when necessary to prevent abuse."" However, critics point out that the free, open-source technology can easily be misused, for example by enabling criminals to pose as loved ones in distress, requesting financialassistance. Other forms of misuse could take the form of revenge porn and child exploitation, harassment and bullying, disinformation, electoral interference, and identify theftand fraud.",Cause - developer causes - programmed AI with problematic functions,Cause,Deep Cam Live AI impersonator prompts misuse fears,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deep-cam-live-ai-impersonator-prompts-misuse-fears,Issue,2024,2024,2024,Global,Media/entertainment/sports/arts,,,Deep Live Cam,Machine learning; Neural network; Deep learning,"Replicate voice, face",Product demonstration/release/launch,Dual/multi-use; Liability; Privacy; Safety; Security,Governance; Privacy,Financial loss; Harassment; Privacy loss,,,,,,,,9/26/2024 23:06,https://best-paper-award-ddck.dovetail.com/data/1LxNAYv0ebKt2inx2Qe6mc#:v:h=41k7NycndShHO3eIRKGaLo
AIAAIC1680,"Deep Cam Live, a new AI product that enables anyone to replicate someone's else's voice, raised concerns about potential misuse andimpersonation scams. Deep Cam Live is able to produce real-time synthetic voices, faces and video appearances, including deepfakes, with only a single image. The product is supposedly intended for video production, animation, and other creative projects. Its creators claim they are ""committed to evolving the project within legal and ethical frameworks, implementingmeasures like watermarking outputs when necessary to prevent abuse."" However, critics point out that the free, open-source technology can easily be misused, for example by enabling criminals to pose as loved ones in distress, requesting financialassistance. Other forms of misuse could take the form of revenge porn and child exploitation, harassment and bullying, disinformation, electoral interference, and identify theftand fraud.",Entity - AI developer company,Responsible Entities,Deep Cam Live AI impersonator prompts misuse fears,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deep-cam-live-ai-impersonator-prompts-misuse-fears,Issue,2024,2024,2024,Global,Media/entertainment/sports/arts,,,Deep Live Cam,Machine learning; Neural network; Deep learning,"Replicate voice, face",Product demonstration/release/launch,Dual/multi-use; Liability; Privacy; Safety; Security,Governance; Privacy,Financial loss; Harassment; Privacy loss,,,,,,,,9/26/2024 23:06,https://best-paper-award-ddck.dovetail.com/data/1LxNAYv0ebKt2inx2Qe6mc#:v:h=41k7NycndShHO3eIRKGaLo
AIAAIC1130,"An advert of YouTube star Jimmy Donaldson (aka MrBeast) offering free iPhone 15 smartphones on TikTok was exposed as a deepfake scam. The fake ad claimed that MrBeast had selected 10,000 people to receive an iPhone 15 Pro in exchange 'for just USD 2'; those interested were then encouraged to click a link below the video to participate.  The ad was exposed as fraudulent by MrBeast, who took to Twitter to say 'Lots of people are getting this deepfake scam ad of me… are social media platforms ready to handle the rise of AI deepfakes? This is a serious problem.' ",Entity - malicious human,Responsible Entities,Deepfake MrBeast iPhone giveaway scam,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-mrbeast-iphone-giveaway-scam,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,"Deepfake - video, audio; Machine learning",Defraud,User comments/complaints,Safety - fraud,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 16:27,https://best-paper-award-ddck.dovetail.com/data/4g64EwFnI9AeQ38FmWIPqm#:v:h=42QNMwQnWqlNhjwxCFk6S5
AIAAIC1130,"An advert of YouTube star Jimmy Donaldson (aka MrBeast) offering free iPhone 15 smartphones on TikTok was exposed as a deepfake scam. The fake ad claimed that MrBeast had selected 10,000 people to receive an iPhone 15 Pro in exchange 'for just USD 2'; those interested were then encouraged to click a link below the video to participate.  The ad was exposed as fraudulent by MrBeast, who took to Twitter to say 'Lots of people are getting this deepfake scam ad of me… are social media platforms ready to handle the rise of AI deepfakes? This is a serious problem.' ",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake MrBeast iPhone giveaway scam,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-mrbeast-iphone-giveaway-scam,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,"Deepfake - video, audio; Machine learning",Defraud,User comments/complaints,Safety - fraud,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 16:27,https://best-paper-award-ddck.dovetail.com/data/4g64EwFnI9AeQ38FmWIPqm#:v:h=42QNMwQnWqlNhjwxCFk6S5
AIAAIC1740,"Meta used public photos and posts from Australian Facebook and Instagram users to train its generative AI models, dating back to 2007, withoutinforming or gaining the consent of their owners, the company admitted.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Meta admits farming Australians' Facebook photos to train AI,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-admits-farming-australians-facebook-photos-to-train-ai,Incident,,2024,2024,Australia,Multiple,,Meta,Meta AI,Machine learning,Train AI models,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:06,https://best-paper-award-ddck.dovetail.com/data/5krw28CG9ViCQTR5BQ5fEp#:v:h=43d8rZgOy0to5CsntS8Tqk
AIAAIC1760,"AnhPhu Nguyen and Caine Ardayfio created I-XRAY, a system that combines Meta's Ray-Ban smart glasses, which feature a built-in camera that streams video to Instagram, with facial recognition technology to identify and retrieve personal information - including names, addresses, and phone numbers - about strangers encountered in public spaces from public databases.",Incident - organization-driven - problematic AI implementation,Incident Type,Harvard students add facial recognition to Meta smart glasses to dox strangers,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/harvard-students-add-facial-recognition-to-meta-smart-glasses,Issue,2024,2024,2024,USA,Research/academia,,AnhPhu Nguyen; Caine Ardayfio; EssilorLuxottica; Meta; Pimeyes, I-XRAY; Ray-Ban Meta Smart Glasses; Pimeyes,Facial recognition; Smart glasses,Identify individuals,Research study/report,Dual/multi-use; Privacy,,Privacy loss,,,,,,,,11/4/2024 16:58,https://best-paper-award-ddck.dovetail.com/data/3QUOtg4w3Lo6DSlLwz1pZo#:v:h=45qpJJroysOPVWlQ3hM2oG
AIAAIC1760,"AnhPhu Nguyen and Caine Ardayfio created I-XRAY, a system that combines Meta's Ray-Ban smart glasses, which feature a built-in camera that streams video to Instagram, with facial recognition technology to identify and retrieve personal information - including names, addresses, and phone numbers - about strangers encountered in public spaces from public databases.",Cause - Human causes - Human abuse of AI tools,Cause,Harvard students add facial recognition to Meta smart glasses to dox strangers,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/harvard-students-add-facial-recognition-to-meta-smart-glasses,Issue,2024,2024,2024,USA,Research/academia,,AnhPhu Nguyen; Caine Ardayfio; EssilorLuxottica; Meta; Pimeyes, I-XRAY; Ray-Ban Meta Smart Glasses; Pimeyes,Facial recognition; Smart glasses,Identify individuals,Research study/report,Dual/multi-use; Privacy,,Privacy loss,,,,,,,,11/4/2024 16:58,https://best-paper-award-ddck.dovetail.com/data/3QUOtg4w3Lo6DSlLwz1pZo#:v:h=45qpJJroysOPVWlQ3hM2oG
AIAAIC1033,"had said the purported address by was fake and the result of a hack. It is unclear who had created the fake materials, and what their intention was.",Cause - Human causes - Human abuse of AI tools,Cause,Putin declares martial law deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/putin-declares-martial-law-deepfake,Incident,,2023,2023,Russia,Politics,,,,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,,Governance; Marketing,,Loss of community wellbeing/cohesion,,,,,,,10/30/2024 17:29,https://best-paper-award-ddck.dovetail.com/data/34Br2W63FNzubTbLbJefbK#:v:h=46CT3pHamtdJAYNhtOygq2
AIAAIC1033,"had said the purported address by was fake and the result of a hack. It is unclear who had created the fake materials, and what their intention was.",Entity - malicious human,Responsible Entities,Putin declares martial law deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/putin-declares-martial-law-deepfake,Incident,,2023,2023,Russia,Politics,,,,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,Product demonstration/release/launch,,Governance; Marketing,,Loss of community wellbeing/cohesion,,,,,,,10/30/2024 17:29,https://best-paper-award-ddck.dovetail.com/data/34Br2W63FNzubTbLbJefbK#:v:h=46CT3pHamtdJAYNhtOygq2
AIAAIC1608,"The French national police quietly started using Israeli company BriefCam's Video Synposis facial recognition software since 2015, according to non-profit journalist outfit Disclose. The software, which allows for broad, one-to-many facial matching with minimal oversight, was reportedly installed in multiple police stations, including Paris and Marseilles.  The use of facial recognition violates French and European law, including the country's Informatics and Freedom Law and the EU's General Data Protection Act, which prohibit biometric identification systems and facial recognition techniques in most circumstances.",Cause - organization causes - legal non-compliance,Cause,French national police accused of illegally using facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/french-national-police-accused-of-illegally-using-facial-recognition,Issue,2015,2023,2023,France,Govt - police,Seine-et-Marne Departmental Directorate of Public Security,BriefCam,Video Synopsis,Facial recognition,Identify criminal suspects,NGO investigation,Privacy,Governance; Marketing,Privacy loss,,,,,,Govt investigation,,9/26/2024 23:41,https://best-paper-award-ddck.dovetail.com/data/5jeoMddR9Z62yQODuMQE4v#:v:h=47kEleurTB1pf0nBRelMTF
AIAAIC1616,"The video was originally created by YouTuber ""Mr. Reagan"", who labeled it as a parody. However, Musk's post to X, which he owns and included the caption ""This is amazing,"" failed to clarify that it was satire, leading to widespread confusion among viewers. Musk's post contravened X's own policies.",Cause - Human causes - Human abuse of AI tools,Cause,Elon Musk shares Kamala Harris voice close video ad,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elon-musk-shares-kamala-harris-voice-clone-video-ad,Issue,,2024,2024,USA,Politics,,,,Deepfake - video; Machine learning,Satirise/parody,,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:15,https://best-paper-award-ddck.dovetail.com/data/7DBPDK65ZBX1OiFoY6lnPh#:v:h=47nRBgh1va2dMRuceIByWu
AIAAIC1015,"Turkey presidential candidate Kemal Kilicdaroglu was falsely linked to the militant Kurdish organisation PKK using a manipulated deepfake video, prompting accusations of electoral interference. President Recep Tayyip Erdogan showed the video, which purportedly showed Kilicdaroglu giving way PKK founder Murat Karayilan, at a political rally. Research shows it had been manipulated by combining two separate videos with different backgrounds and content. The PKK is listed as a terrorist organisation by the US, EU, and Turkey.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Election deepfake falsely links Kemal Kilicdaroglu to PKK,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kemal-kilicdaroglu-pkk-links-deepfake,Incident,,2023,2023,Turkey,Politics,,Government of Russia,,Deepfake - video; Machine learning,Damage reputation,Candidate speech,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage,,,,,,,,10/30/2024 17:38,https://best-paper-award-ddck.dovetail.com/data/Sr6xTuaSAhyBCrIAw81n6#:v:h=49EubrW4tOQlkqsPws8VMM
AIAAIC1015,"Turkey presidential candidate Kemal Kilicdaroglu was falsely linked to the militant Kurdish organisation PKK using a manipulated deepfake video, prompting accusations of electoral interference. President Recep Tayyip Erdogan showed the video, which purportedly showed Kilicdaroglu giving way PKK founder Murat Karayilan, at a political rally. Research shows it had been manipulated by combining two separate videos with different backgrounds and content. The PKK is listed as a terrorist organisation by the US, EU, and Turkey.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Election deepfake falsely links Kemal Kilicdaroglu to PKK,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kemal-kilicdaroglu-pkk-links-deepfake,Incident,,2023,2023,Turkey,Politics,,Government of Russia,,Deepfake - video; Machine learning,Damage reputation,Candidate speech,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage,,,,,,,,10/30/2024 17:38,https://best-paper-award-ddck.dovetail.com/data/Sr6xTuaSAhyBCrIAw81n6#:v:h=49EubrW4tOQlkqsPws8VMM
AIAAIC1015,"Turkey presidential candidate Kemal Kilicdaroglu was falsely linked to the militant Kurdish organisation PKK using a manipulated deepfake video, prompting accusations of electoral interference. President Recep Tayyip Erdogan showed the video, which purportedly showed Kilicdaroglu giving way PKK founder Murat Karayilan, at a political rally. Research shows it had been manipulated by combining two separate videos with different backgrounds and content. The PKK is listed as a terrorist organisation by the US, EU, and Turkey.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Election deepfake falsely links Kemal Kilicdaroglu to PKK,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kemal-kilicdaroglu-pkk-links-deepfake,Incident,,2023,2023,Turkey,Politics,,Government of Russia,,Deepfake - video; Machine learning,Damage reputation,Candidate speech,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage,,,,,,,,10/30/2024 17:38,https://best-paper-award-ddck.dovetail.com/data/Sr6xTuaSAhyBCrIAw81n6#:v:h=49EubrW4tOQlkqsPws8VMM
AIAAIC1015,"Turkey presidential candidate Kemal Kilicdaroglu was falsely linked to the militant Kurdish organisation PKK using a manipulated deepfake video, prompting accusations of electoral interference. President Recep Tayyip Erdogan showed the video, which purportedly showed Kilicdaroglu giving way PKK founder Murat Karayilan, at a political rally. Research shows it had been manipulated by combining two separate videos with different backgrounds and content. The PKK is listed as a terrorist organisation by the US, EU, and Turkey.",Cause - Government/organization - Manipulating people's minds,Cause,Election deepfake falsely links Kemal Kilicdaroglu to PKK,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kemal-kilicdaroglu-pkk-links-deepfake,Incident,,2023,2023,Turkey,Politics,,Government of Russia,,Deepfake - video; Machine learning,Damage reputation,Candidate speech,Mis/disinformation; Ethics/values,Governance; Marketing,Reputational damage,,,,,,,,10/30/2024 17:38,https://best-paper-award-ddck.dovetail.com/data/Sr6xTuaSAhyBCrIAw81n6#:v:h=49EubrW4tOQlkqsPws8VMM
AIAAIC1740,"Meta used public photos and posts from Australian Facebook and Instagram users to train its generative AI models, dating back to 2007, withoutinforming or gaining the consent of their owners, the company admitted. The admission came during a Senate inquiry into the adoption of artificial intelligence in Australia, where Meta executives stated that while they do not scrape data fromaccounts of individuals under 18, any public photos shared by adults - including those featuring children - are included in the data used for AI training.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Meta admits farming Australians' Facebook photos to train AI,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-admits-farming-australians-facebook-photos-to-train-ai,Incident,,2024,2024,Australia,Multiple,,Meta,Meta AI,Machine learning,Train AI models,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:08,https://best-paper-award-ddck.dovetail.com/data/5krw28CG9ViCQTR5BQ5fEp#:v:h=4bgCEc9pWFTqfS8kW88JZB
AIAAIC1740,"Meta used public photos and posts from Australian Facebook and Instagram users to train its generative AI models, dating back to 2007, withoutinforming or gaining the consent of their owners, the company admitted. The admission came during a Senate inquiry into the adoption of artificial intelligence in Australia, where Meta executives stated that while they do not scrape data fromaccounts of individuals under 18, any public photos shared by adults - including those featuring children - are included in the data used for AI training.",Entity - AI developer company,Responsible Entities,Meta admits farming Australians' Facebook photos to train AI,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-admits-farming-australians-facebook-photos-to-train-ai,Incident,,2024,2024,Australia,Multiple,,Meta,Meta AI,Machine learning,Train AI models,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:08,https://best-paper-award-ddck.dovetail.com/data/5krw28CG9ViCQTR5BQ5fEp#:v:h=4bgCEc9pWFTqfS8kW88JZB
AIAAIC1473,The incident highlighted the use of facial recognition by UK law enforcement authorities and the lack of transparency around its use.,Cause - organization/human cause - lack of informed consent & transparency,Cause,"UK police use PimEyes, raising privacy concerns",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-police-found-to-use-pimeyes-raising-privacy-concerns,Issue,2017,2024,2024,UK,Govt - police,Metropolitan Police Service (MPS),PimEyes,PimEyes,Facial recognition,Identify criminal suspects,Media investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 12:29,https://best-paper-award-ddck.dovetail.com/data/1ZnRdlaYvCiqDDIMNyDrI3#:v:h=4cpAPAyLI7pJ7hAtQCLIUS
AIAAIC1221,"OpenAI was accused of violating the personal privacy of internet users and illegally obtaining personal data to train its ChatGPT and DALL-E models in a class-action lawsuit filed by Clarkson Law Firm in the Northern District of California.  The suit alleged (pdf) ChatGPT and DALL-E 'use stolen private information, including personally identifiable information, from hundreds of millions of internet users, including children of all ages, without their informed consent or knowledge.' It went on to argue that OpenAI 'did so in secret, and without registering as a data broker as it was required to do under applicable law.'",Cause - organization/human cause - lack of informed consent & transparency,Cause,OpenAI sued for 'stealing' personal info to create ChatGPT,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-microsoft-sued-for-stealing-personal-info-to-create-chatgpt,Incident,2022,2023,2023,USA,Multiple,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:57,https://best-paper-award-ddck.dovetail.com/data/5Q9YolM02qfw2KFFK09BXS#:v:h=4dim0AVly3KN4Z8CMlaBDj
AIAAIC1221,"OpenAI was accused of violating the personal privacy of internet users and illegally obtaining personal data to train its ChatGPT and DALL-E models in a class-action lawsuit filed by Clarkson Law Firm in the Northern District of California.  The suit alleged (pdf) ChatGPT and DALL-E 'use stolen private information, including personally identifiable information, from hundreds of millions of internet users, including children of all ages, without their informed consent or knowledge.' It went on to argue that OpenAI 'did so in secret, and without registering as a data broker as it was required to do under applicable law.'",Entity - AI developer company,Responsible Entities,OpenAI sued for 'stealing' personal info to create ChatGPT,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-microsoft-sued-for-stealing-personal-info-to-create-chatgpt,Incident,2022,2023,2023,USA,Multiple,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:57,https://best-paper-award-ddck.dovetail.com/data/5Q9YolM02qfw2KFFK09BXS#:v:h=4dim0AVly3KN4Z8CMlaBDj
AIAAIC1221,"OpenAI was accused of violating the personal privacy of internet users and illegally obtaining personal data to train its ChatGPT and DALL-E models in a class-action lawsuit filed by Clarkson Law Firm in the Northern District of California.  The suit alleged (pdf) ChatGPT and DALL-E 'use stolen private information, including personally identifiable information, from hundreds of millions of internet users, including children of all ages, without their informed consent or knowledge.' It went on to argue that OpenAI 'did so in secret, and without registering as a data broker as it was required to do under applicable law.'",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,OpenAI sued for 'stealing' personal info to create ChatGPT,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-microsoft-sued-for-stealing-personal-info-to-create-chatgpt,Incident,2022,2023,2023,USA,Multiple,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:57,https://best-paper-award-ddck.dovetail.com/data/5Q9YolM02qfw2KFFK09BXS#:v:h=4dim0AVly3KN4Z8CMlaBDj
AIAAIC1221,"OpenAI was accused of violating the personal privacy of internet users and illegally obtaining personal data to train its ChatGPT and DALL-E models in a class-action lawsuit filed by Clarkson Law Firm in the Northern District of California.  The suit alleged (pdf) ChatGPT and DALL-E 'use stolen private information, including personally identifiable information, from hundreds of millions of internet users, including children of all ages, without their informed consent or knowledge.' It went on to argue that OpenAI 'did so in secret, and without registering as a data broker as it was required to do under applicable law.'",Cause - organization causes - legal non-compliance,Cause,OpenAI sued for 'stealing' personal info to create ChatGPT,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-microsoft-sued-for-stealing-personal-info-to-create-chatgpt,Incident,2022,2023,2023,USA,Multiple,Microsoft; OpenAI,Microsoft; OpenAI,Bard/Gemini; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:57,https://best-paper-award-ddck.dovetail.com/data/5Q9YolM02qfw2KFFK09BXS#:v:h=4dim0AVly3KN4Z8CMlaBDj
AIAAIC1082,"An advert celebrating VW's 70th year operating in Brazil by simulating renown Brazilian singer Elis Regina, who died in 1982 at the age of 36, sparked questions about the ethics of using AI to simulate the image and likeness of a dead person. The advert, which reputedly took over 2,400 hours to produce, saw an actress and deepfake technology make it appear as if Regina was performing her 1976 hit Como Nossos Pais in a duet with her daughter Maria Rita while driving a VW van",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,VW Brazil Elis Regina deepfake advert,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/vw-brazil-elis-regina-deepfake,Incident,,2023,2023,Brazil,Business/professional services,VW Brazil,AlmapBBDO,,"Deepfake - video, audio; Machine learning",Recreate singer,Product demonstration/release/launch,Legal; Ethics/values,Marketing,Manipulation,,,,,,Regulatory investigation,,10/30/2024 16:44,https://best-paper-award-ddck.dovetail.com/data/4xrumqLFjMvWJSTCIv8prm#:v:h=4eLz5UIgNofqRQoBsbtaon
AIAAIC1082,"An advert celebrating VW's 70th year operating in Brazil by simulating renown Brazilian singer Elis Regina, who died in 1982 at the age of 36, sparked questions about the ethics of using AI to simulate the image and likeness of a dead person. The advert, which reputedly took over 2,400 hours to produce, saw an actress and deepfake technology make it appear as if Regina was performing her 1976 hit Como Nossos Pais in a duet with her daughter Maria Rita while driving a VW van",Incident - organization-driven - problematic AI implementation,Incident Type,VW Brazil Elis Regina deepfake advert,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/vw-brazil-elis-regina-deepfake,Incident,,2023,2023,Brazil,Business/professional services,VW Brazil,AlmapBBDO,,"Deepfake - video, audio; Machine learning",Recreate singer,Product demonstration/release/launch,Legal; Ethics/values,Marketing,Manipulation,,,,,,Regulatory investigation,,10/30/2024 16:44,https://best-paper-award-ddck.dovetail.com/data/4xrumqLFjMvWJSTCIv8prm#:v:h=4eLz5UIgNofqRQoBsbtaon
AIAAIC1423,"A number of AI-generated audio clips falsely depicting the Mayor of London denigrating the UK's 2023 Remembrance commemorations raised concerns about the use of synthetic disinformation in politics. One voice clip impersonating Sadiq Khan disparaged Remembrance weekend and called for pro-Palestinian marches, planned for the same day, to take precedence. The recordings, which have been tracked to Tiktok account HJB News, were spread across multiple platforms before being removed.",Entity - no specific info,Responsible Entities,Deepfake audio depicts London Mayor dismissing Remembrance Sunday,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-depicts-london-mayor-dismissing-remembrance-sunday,Incident,,2023,2023,UK,Politics,HJB News,,,"Deepfake - audio, video; Machine learning",Damage reputation; Manipulate public opinion,,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:25,https://best-paper-award-ddck.dovetail.com/data/uCVZHNq4JiNnUZaLFVOcy#:v:h=4hf8GeIiTsOrUqmHVxUAUX
AIAAIC1423,"A number of AI-generated audio clips falsely depicting the Mayor of London denigrating the UK's 2023 Remembrance commemorations raised concerns about the use of synthetic disinformation in politics. One voice clip impersonating Sadiq Khan disparaged Remembrance weekend and called for pro-Palestinian marches, planned for the same day, to take precedence. The recordings, which have been tracked to Tiktok account HJB News, were spread across multiple platforms before being removed.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake audio depicts London Mayor dismissing Remembrance Sunday,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-depicts-london-mayor-dismissing-remembrance-sunday,Incident,,2023,2023,UK,Politics,HJB News,,,"Deepfake - audio, video; Machine learning",Damage reputation; Manipulate public opinion,,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:25,https://best-paper-award-ddck.dovetail.com/data/uCVZHNq4JiNnUZaLFVOcy#:v:h=4hf8GeIiTsOrUqmHVxUAUX
AIAAIC1423,"A number of AI-generated audio clips falsely depicting the Mayor of London denigrating the UK's 2023 Remembrance commemorations raised concerns about the use of synthetic disinformation in politics. One voice clip impersonating Sadiq Khan disparaged Remembrance weekend and called for pro-Palestinian marches, planned for the same day, to take precedence. The recordings, which have been tracked to Tiktok account HJB News, were spread across multiple platforms before being removed.",Cause - no specific info,Cause,Deepfake audio depicts London Mayor dismissing Remembrance Sunday,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-audio-depicts-london-mayor-dismissing-remembrance-sunday,Incident,,2023,2023,UK,Politics,HJB News,,,"Deepfake - audio, video; Machine learning",Damage reputation; Manipulate public opinion,,Mis/disinformation,Governance,,,,,,,,,10/24/2024 23:25,https://best-paper-award-ddck.dovetail.com/data/uCVZHNq4JiNnUZaLFVOcy#:v:h=4hf8GeIiTsOrUqmHVxUAUX
AIAAIC0983,"A deepfake image of the Pope clad in a Belanciaga puffer jacket went viral on the internet, leading to commentary that the age of mass graphic misinformation and disinformation has arrived. The image was a deepfake created by 'Pablo Xavier', a Chicago-based construction worker using the Midjourney image generator. Xavier said he came up with the idea after taking mushrooms. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake Pope Francis wears white puffa jacket,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pope-francis-wears-white-puffa-jacket,Incident,2022,2023,2023,USA,Religion,Pablo Xavier,Midjourney,Midjourney,Deepfake - image; Machine learning,Entertain,,Mis/disinformation; Ethics/values,Governance; Black box,,,,,System update,,,,10/30/2024 19:13,https://best-paper-award-ddck.dovetail.com/data/rhEurRDP9K33abhx1BdCH#:v:h=4hNljr6za7soP2WJqlIzCj
AIAAIC0983,"A deepfake image of the Pope clad in a Belanciaga puffer jacket went viral on the internet, leading to commentary that the age of mass graphic misinformation and disinformation has arrived. The image was a deepfake created by 'Pablo Xavier', a Chicago-based construction worker using the Midjourney image generator. Xavier said he came up with the idea after taking mushrooms. ",Entity - malicious human,Responsible Entities,Deepfake Pope Francis wears white puffa jacket,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pope-francis-wears-white-puffa-jacket,Incident,2022,2023,2023,USA,Religion,Pablo Xavier,Midjourney,Midjourney,Deepfake - image; Machine learning,Entertain,,Mis/disinformation; Ethics/values,Governance; Black box,,,,,System update,,,,10/30/2024 19:13,https://best-paper-award-ddck.dovetail.com/data/rhEurRDP9K33abhx1BdCH#:v:h=4hNljr6za7soP2WJqlIzCj
AIAAIC0983,"A deepfake image of the Pope clad in a Belanciaga puffer jacket went viral on the internet, leading to commentary that the age of mass graphic misinformation and disinformation has arrived. The image was a deepfake created by 'Pablo Xavier', a Chicago-based construction worker using the Midjourney image generator. Xavier said he came up with the idea after taking mushrooms. ",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake Pope Francis wears white puffa jacket,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-pope-francis-wears-white-puffa-jacket,Incident,2022,2023,2023,USA,Religion,Pablo Xavier,Midjourney,Midjourney,Deepfake - image; Machine learning,Entertain,,Mis/disinformation; Ethics/values,Governance; Black box,,,,,System update,,,,10/30/2024 19:13,https://best-paper-award-ddck.dovetail.com/data/rhEurRDP9K33abhx1BdCH#:v:h=4hNljr6za7soP2WJqlIzCj
AIAAIC1348,Students at the University of Waterloo in Canada discovered that 'intelligent' vending machines on campus were using facial recognition without their knowledge. The facial recognition capability was accidentally found by a student after an error message appeared on a screen of one of the M&M-branded vending machines. Students then began to cover a tiny hole apparently concealing the camera with chewing gum and sticky notes.,Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,University of Waterloo found covertly using facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/university-of-waterloo-found-covertly-using-facial-recognition,Incident,,2024,2024,Canada,Education,Adaria Vending Services/University of Waterloo,Invenda,Indoor Vending Machine,Facial recognition,Profile demographics,User comments/complaints,Privacy,Marketing,Privacy loss,,,,Product removal,,,,10/2/2024 20:02,https://best-paper-award-ddck.dovetail.com/data/7vN17c6rSUW64IlAIglw6Z#:v:h=4iYdHR1dfkBBSgf1SooqsD
AIAAIC1348,Students at the University of Waterloo in Canada discovered that 'intelligent' vending machines on campus were using facial recognition without their knowledge. The facial recognition capability was accidentally found by a student after an error message appeared on a screen of one of the M&M-branded vending machines. Students then began to cover a tiny hole apparently concealing the camera with chewing gum and sticky notes.,Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,University of Waterloo found covertly using facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/university-of-waterloo-found-covertly-using-facial-recognition,Incident,,2024,2024,Canada,Education,Adaria Vending Services/University of Waterloo,Invenda,Indoor Vending Machine,Facial recognition,Profile demographics,User comments/complaints,Privacy,Marketing,Privacy loss,,,,Product removal,,,,10/2/2024 20:02,https://best-paper-award-ddck.dovetail.com/data/7vN17c6rSUW64IlAIglw6Z#:v:h=4iYdHR1dfkBBSgf1SooqsD
AIAAIC1348,Students at the University of Waterloo in Canada discovered that 'intelligent' vending machines on campus were using facial recognition without their knowledge. The facial recognition capability was accidentally found by a student after an error message appeared on a screen of one of the M&M-branded vending machines. Students then began to cover a tiny hole apparently concealing the camera with chewing gum and sticky notes.,Cause - organization/human cause - lack of informed consent & transparency,Cause,University of Waterloo found covertly using facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/university-of-waterloo-found-covertly-using-facial-recognition,Incident,,2024,2024,Canada,Education,Adaria Vending Services/University of Waterloo,Invenda,Indoor Vending Machine,Facial recognition,Profile demographics,User comments/complaints,Privacy,Marketing,Privacy loss,,,,Product removal,,,,10/2/2024 20:02,https://best-paper-award-ddck.dovetail.com/data/7vN17c6rSUW64IlAIglw6Z#:v:h=4iYdHR1dfkBBSgf1SooqsD
AIAAIC1298,"The incident raised concerns about PimEyes' ethics, its use of personal biometric data without permission to train its facial recognition system, and the fact that it was abusing Ancestry.com's terms. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,PimEyes steals images of dead people to train facial recognition system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-steals-images-of-dead-people-to-train-facial-recognition-system,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,User comments/complaints,Ethics/values; Governance; Privacy,Governance,Privacy loss,,,,System update,,,,10/2/2024 21:10,https://best-paper-award-ddck.dovetail.com/data/7Lr7KUr6TZqqtEuNeHFrjs#:v:h=4jOsgAO66fodiqmvBmvxGI
AIAAIC1298,"The incident raised concerns about PimEyes' ethics, its use of personal biometric data without permission to train its facial recognition system, and the fact that it was abusing Ancestry.com's terms. ",Cause - organization causes - poor business ethics,Cause,PimEyes steals images of dead people to train facial recognition system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-steals-images-of-dead-people-to-train-facial-recognition-system,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,User comments/complaints,Ethics/values; Governance; Privacy,Governance,Privacy loss,,,,System update,,,,10/2/2024 21:10,https://best-paper-award-ddck.dovetail.com/data/7Lr7KUr6TZqqtEuNeHFrjs#:v:h=4jOsgAO66fodiqmvBmvxGI
AIAAIC1705,"A data breach involving Australian facial recognition company Outabox raised serious privacy concerns and prompted investigations by authorities,including police and federal agencies.",Incident - AI-driven - AI data breach,Incident Type,Outabox data breach exposes 1m biometric records,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/outabox-data-breach-exposes-1m-biometric-records,Incident,2021,2024,2024,Australia; Philippines; USA,Travel/hospitality,ClubsNSW,Outabox,TriAgem Facial Recognition Kiosk,Facial recognition,Identify bar/club users,Data breach,Privacy,,Privacy loss,,,Reputational damage,,,,,9/26/2024 22:30,https://best-paper-award-ddck.dovetail.com/data/2Vwbe3Qedt3gSMibUMymrw#:v:h=4kkjyCF8YpPvOLjxnPYuyd
AIAAIC1620,"Elon Musk's social media platform X (formerly Twitter) came under fire for automatically harvesting user data to train its AI chatbot, Grok, without notifying users or obtaining their consent. X enabled a setting by default that allows user posts and interactions to be used for training Grok. Users are automatically opted in without explicit consent, violating data protection norms in the EU, UK and elsewhere. Many users discovered the setting only after it was pointed out on social media, leading to concerns about transparency. The finding attracted regulatory attention in the EU and UK, with authorities criticising X for using ""pre-ticked boxes"" and other methods of default consent, which are prohibited under their data protection laws. Furthernore, users can only opt out of X's data sharing policy via the web version of X, making it less accessible.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,X automatically harvests user data to train AI chatbot,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/x-automatically-harvests-user-data-to-train-ai-chatbot,Issue,2023,2024,2024,Global,Multiple,,X Corp,Grok,Chatbot; Machine learning,Train AI model,User comments/complaints,Copyright; Ethics/values; Privacy,Governance,Copyright loss; Privacy loss,,,,,,,,9/26/2024 23:32,https://best-paper-award-ddck.dovetail.com/data/7eE844CztMR7oh9smZeAg5#:v:h=4mdcuyQaIHr9axcRz0Hwfm
AIAAIC1620,"Elon Musk's social media platform X (formerly Twitter) came under fire for automatically harvesting user data to train its AI chatbot, Grok, without notifying users or obtaining their consent. X enabled a setting by default that allows user posts and interactions to be used for training Grok. Users are automatically opted in without explicit consent, violating data protection norms in the EU, UK and elsewhere. Many users discovered the setting only after it was pointed out on social media, leading to concerns about transparency. The finding attracted regulatory attention in the EU and UK, with authorities criticising X for using ""pre-ticked boxes"" and other methods of default consent, which are prohibited under their data protection laws. Furthernore, users can only opt out of X's data sharing policy via the web version of X, making it less accessible.",Entity - AI developer company,Responsible Entities,X automatically harvests user data to train AI chatbot,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/x-automatically-harvests-user-data-to-train-ai-chatbot,Issue,2023,2024,2024,Global,Multiple,,X Corp,Grok,Chatbot; Machine learning,Train AI model,User comments/complaints,Copyright; Ethics/values; Privacy,Governance,Copyright loss; Privacy loss,,,,,,,,9/26/2024 23:32,https://best-paper-award-ddck.dovetail.com/data/7eE844CztMR7oh9smZeAg5#:v:h=4mdcuyQaIHr9axcRz0Hwfm
AIAAIC1006,"An elderly Canadian couple were defrauded of CAD 21,000 after they were contacted by an alleged lawyer who said their son had killed a US diplomat in a car accident and required money for legal support.  According to the Washington Post, the 'lawyer' had allegedly put Benjamin Perkins, the couple's son, on the line to underline the gavity and urgency of the situation.  Perkins' synthetic voice was sufficiently close to his real voice that his parents believed the call and sent the money to the scammer using Bitcoin. The couple only realised they had been scammed after Perkin called later that evening. ",Cause - Human causes - Human abuse of AI tools,Cause,"AI impersonation scams Canadian couple of USD 21,000",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-impersonation-scams-couple-of-usd-21000,Incident,,2023,2023,Canada,Banking/financial services,,,,Deepfake - audio; Machine learning,Defraud,,Security,Governance,Financial loss,,,,,,,,10/30/2024 18:30,https://best-paper-award-ddck.dovetail.com/data/319QqUVlceC9UwUgH2vATm#:v:h=4nPyPfMEoawj5OCrS1fkCI
AIAAIC1006,"An elderly Canadian couple were defrauded of CAD 21,000 after they were contacted by an alleged lawyer who said their son had killed a US diplomat in a car accident and required money for legal support.  According to the Washington Post, the 'lawyer' had allegedly put Benjamin Perkins, the couple's son, on the line to underline the gavity and urgency of the situation.  Perkins' synthetic voice was sufficiently close to his real voice that his parents believed the call and sent the money to the scammer using Bitcoin. The couple only realised they had been scammed after Perkin called later that evening. ",Entity - malicious human,Responsible Entities,"AI impersonation scams Canadian couple of USD 21,000",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-impersonation-scams-couple-of-usd-21000,Incident,,2023,2023,Canada,Banking/financial services,,,,Deepfake - audio; Machine learning,Defraud,,Security,Governance,Financial loss,,,,,,,,10/30/2024 18:30,https://best-paper-award-ddck.dovetail.com/data/319QqUVlceC9UwUgH2vATm#:v:h=4nPyPfMEoawj5OCrS1fkCI
AIAAIC1006,"An elderly Canadian couple were defrauded of CAD 21,000 after they were contacted by an alleged lawyer who said their son had killed a US diplomat in a car accident and required money for legal support.  According to the Washington Post, the 'lawyer' had allegedly put Benjamin Perkins, the couple's son, on the line to underline the gavity and urgency of the situation.  Perkins' synthetic voice was sufficiently close to his real voice that his parents believed the call and sent the money to the scammer using Bitcoin. The couple only realised they had been scammed after Perkin called later that evening. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"AI impersonation scams Canadian couple of USD 21,000",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-impersonation-scams-couple-of-usd-21000,Incident,,2023,2023,Canada,Banking/financial services,,,,Deepfake - audio; Machine learning,Defraud,,Security,Governance,Financial loss,,,,,,,,10/30/2024 18:30,https://best-paper-award-ddck.dovetail.com/data/319QqUVlceC9UwUgH2vATm#:v:h=4nPyPfMEoawj5OCrS1fkCI
AIAAIC1381,"The activities of digital identity network Worldcoin were suspended in Spain for inadequate transparency and the collection of personal data of children. Spain's AEPD data protection regulator suspended Worldcoin's data collection and processing for three months under the European Union's General Data Protection Regulation.  The EAPD said it had received complaints against it's parent company Tools for Humanity for failing to provide people with sufficient information about the project, collecting data of minors, and the inability to people to withdraw their consent to process their data.",Entity - large dataset organization,Responsible Entities,Spain suspends Worldcoin over privacy concerns,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/spain-suspends-worldcoin-over-privacy-concerns,Incident,2023,2024,2024,Spain,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 19:23,https://best-paper-award-ddck.dovetail.com/data/2KvcGYwqmHB0goQ8GTNz3s#:v:h=4ppjR4kCu9HNnDjyu7oWQs
AIAAIC1381,"The activities of digital identity network Worldcoin were suspended in Spain for inadequate transparency and the collection of personal data of children. Spain's AEPD data protection regulator suspended Worldcoin's data collection and processing for three months under the European Union's General Data Protection Regulation.  The EAPD said it had received complaints against it's parent company Tools for Humanity for failing to provide people with sufficient information about the project, collecting data of minors, and the inability to people to withdraw their consent to process their data.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Spain suspends Worldcoin over privacy concerns,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/spain-suspends-worldcoin-over-privacy-concerns,Incident,2023,2024,2024,Spain,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 19:23,https://best-paper-award-ddck.dovetail.com/data/2KvcGYwqmHB0goQ8GTNz3s#:v:h=4ppjR4kCu9HNnDjyu7oWQs
AIAAIC1726,Microsoft's Copilot chatbot falsely accused German journalist Martin Bernklau of serious crimeshe had reported on.,Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Copilot falsely accuses journalist of being a child molester and fraudster,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/copilot-falsely-accuses-journalist-of-being-a-child-molester-and-fraudster,Incident,,2024,2024,Germany,Media/entertainment/sports/arts,Martin Bernklau,Microsoft,Copilot,Chatbot; Machine learning,Generate text,Legal threat,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Defamation; Privacy loss,,,,,,,,9/26/2024 19:39,https://best-paper-award-ddck.dovetail.com/data/28PGP98tOtvO2BJTypDV9U#:v:h=4r4gj3U7eXa1DhPxTfyyFM
AIAAIC0960,"ynthetic pornographic images of QTCinderella, Pokimane, and Sweet Anita. Per USA Today, QTCinderella says 'I'm a normal girl.' 'I like Taylor Swift. I like baking cookies. I like going to Disneyland.' But after the incident 'her name, her face and her brand have become associated with pornography'. British influencer Sweet Anita told the New York Post that she 'fears the mass circulation of her misused image will have lasting ramifications.' 'This was nonconsensual and the impacts are permanent,' she said. 'This will impact my life in a similar way to revenge porn, so I’m just frustrated, tired and numb.'",Cause - Human causes - Human abuse of AI tools,Cause,"QTCinderella, Pokimane, Sweet Anita deepfakes exposed using live stream",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/qtcinderella-pokimane-sweet-anita-deepfakes,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Generate revenue,Twitch streamer voyeurism,Safety; Privacy; Ethics/values,Governance; Privacy; Marketing,Privacy loss; Emotional damage; Reputational damage,,,,,,,,10/30/2024 19:36,https://best-paper-award-ddck.dovetail.com/data/LaSn2Wonl3QqFQgWUxgLe#:v:h=4svHhKL72vRmXASINQ4s8s
AIAAIC1330,without their parents' permission,Cause - organization/human cause - lack of informed consent & transparency,Cause,Toilet sensors ‘actively listen’ to school pupils,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/toilet-sensors-actively-listen-to-uk-school-pupils,Issue,,2024,2024,UK,Education,"Baxter College, Kidderminster",Triton,3D Sense Pro,Machine learning; Keyword detection,Detect vaping; Increase safety,Media investigation,Privacy,Marketing,Privacy loss,,,,,,,,10/2/2024 20:07,https://best-paper-award-ddck.dovetail.com/data/735qJPdpGQbLfnjqJhjqGG#:v:h=4sVli5777PAVGmxYqJGrh4
AIAAIC1375,"20-year-old Olga Loiek spotted videos of herself on Bilibili, Douyin and other Chinese social media platforms speaking Mandarin, promoting national ties between Russia and China, selling Russian goods and saying she wants to marry a Chinese man. ",Entity - AI developer company,Responsible Entities,Cloned Ukrainian YouTuber promotes Russia-China relations,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ukrainian-youtuber-cloned-to-promote-russia-china-relations,Incident,2020,2024,2024,China; Ukraine,Media/entertainment/sports/arts; Politics,,HeyGen,HeyGen,Deepfake - video; Machine learning,Promote Russia-China relations,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,Anxiety/distress/depression,,,,,,,,10/24/2024 23:03,https://best-paper-award-ddck.dovetail.com/data/1gam1nQCnCihSWkBQwgEHE#:v:h=4t77JcDDBdFNX8TXtrZss7
AIAAIC1375,"20-year-old Olga Loiek spotted videos of herself on Bilibili, Douyin and other Chinese social media platforms speaking Mandarin, promoting national ties between Russia and China, selling Russian goods and saying she wants to marry a Chinese man. ",Cause - no specific info,Cause,Cloned Ukrainian YouTuber promotes Russia-China relations,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ukrainian-youtuber-cloned-to-promote-russia-china-relations,Incident,2020,2024,2024,China; Ukraine,Media/entertainment/sports/arts; Politics,,HeyGen,HeyGen,Deepfake - video; Machine learning,Promote Russia-China relations,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,Anxiety/distress/depression,,,,,,,,10/24/2024 23:03,https://best-paper-award-ddck.dovetail.com/data/1gam1nQCnCihSWkBQwgEHE#:v:h=4t77JcDDBdFNX8TXtrZss7
AIAAIC1239,"a variety of issues regarding Q, including that it has been 'experiencing severe hallucinations and leaking confidential data,' including the location of AWS data centers, internal discount programs",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,"Amazon Q hallucinates, leaks data",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-q-hallucinates-leaks-data,Issue,2023,2023,2023,USA,Business/professional services,Casey Newton; Zoe Schiffler,Amazon,Amazon Q,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Media investigation,Accuracy/reliability; Confidentiality; Privacy,Governance,,Confidentiality loss,,,,,,,10/6/2024 23:43,https://best-paper-award-ddck.dovetail.com/data/6qdPVS8qLWNLyJwXajPT1d#:v:h=4vwCZt3v4eF2ooRJlcCq8g
AIAAIC1611,"Google's AI chatbot, Bard, faced criticism for expressing the opinion that Brexit was a ""bad idea,"" sparking accusations of left-wing bias. Bard stated that Brexit has led to economic uncertainty and trade barriers, suggesting the UK would have been better off remaining in the European Union. Bard also said 'I believe Corbyn has the potential to be a great leader.' Former Labour leader Jeremy Corbyn resigned as Labour Party leader in 2019. Bard's comments highlight the ongoing debate about the implications of Brexit, with the chatbot acknowledging that opinions on the matter vary. However, it firmly positioned itself against Brexit, citing the difficulties it has created for UK cooperation with other countries. In contrast, when asked similar questions, ChatGPT refrained from offering personal opinions, focusing instead on providing objective information about Brexit.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Deepfake France 24 journalist calls Seine water 'unsafe',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-bard-says-the-uks-exit-from-the-european-union-a-bad-idea,Issue,,2024,2024,France,Media/entertainment/sports/arts; Politics,France 24,,,Deepfake - video; Machine learning,Damage reputation,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:08,https://best-paper-award-ddck.dovetail.com/data/4deVRbVj7jbS3yAXDe5qNH#:v:h=4w1Rss6ZdoNsLTV36AjRBs
AIAAIC1611,"Google's AI chatbot, Bard, faced criticism for expressing the opinion that Brexit was a ""bad idea,"" sparking accusations of left-wing bias. Bard stated that Brexit has led to economic uncertainty and trade barriers, suggesting the UK would have been better off remaining in the European Union. Bard also said 'I believe Corbyn has the potential to be a great leader.' Former Labour leader Jeremy Corbyn resigned as Labour Party leader in 2019. Bard's comments highlight the ongoing debate about the implications of Brexit, with the chatbot acknowledging that opinions on the matter vary. However, it firmly positioned itself against Brexit, citing the difficulties it has created for UK cooperation with other countries. In contrast, when asked similar questions, ChatGPT refrained from offering personal opinions, focusing instead on providing objective information about Brexit.",Entity - AI algorithm,Responsible Entities,Deepfake France 24 journalist calls Seine water 'unsafe',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-bard-says-the-uks-exit-from-the-european-union-a-bad-idea,Issue,,2024,2024,France,Media/entertainment/sports/arts; Politics,France 24,,,Deepfake - video; Machine learning,Damage reputation,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:08,https://best-paper-award-ddck.dovetail.com/data/4deVRbVj7jbS3yAXDe5qNH#:v:h=4w1Rss6ZdoNsLTV36AjRBs
AIAAIC1215,Japan's privacy watchdog issued a formal warning to OpenAI not to collect users' personal data to train its machine learning systems without permission.,Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Japan warns OpenAI over ChatGPT AI training,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/japan-warns-openai-over-chatgpt-ai-training,Incident,2022,2023,2023,Japan,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory warning,Privacy,Governance; Privacy,Privacy loss,,,,,,Regulatory warning,,10/6/2024 23:59,https://best-paper-award-ddck.dovetail.com/data/3FjEsGNiaZA12mL4H26lVq#:v:h=4wHFmUoRqqX2gzfeL0Yrwm
AIAAIC1215,Japan's privacy watchdog issued a formal warning to OpenAI not to collect users' personal data to train its machine learning systems without permission.,Cause - organization/human cause - lack of informed consent & transparency,Cause,Japan warns OpenAI over ChatGPT AI training,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/japan-warns-openai-over-chatgpt-ai-training,Incident,2022,2023,2023,Japan,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory warning,Privacy,Governance; Privacy,Privacy loss,,,,,,Regulatory warning,,10/6/2024 23:59,https://best-paper-award-ddck.dovetail.com/data/3FjEsGNiaZA12mL4H26lVq#:v:h=4wHFmUoRqqX2gzfeL0Yrwm
AIAAIC1739,"An Israeli settler group posted an inflammatory AI-generated video showing the Al-Aqsa Mosque in occupied East Jerusalem burning to the ground, prompting widespread comdemnation.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake AI video shows Al-Aqsa mosque burning,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-ai-video-shows-al-aqsa-burning,Issue,,2024,2024,Israel; Palestine,Politics,Temple Mount Activists,Temple Mount Activists,,Deepfake - video,Intimidate/threaten Palestinians,User comments/complaints,Mis/disinformation,Governance,,,,,,,,,10/13/2024 22:53,https://best-paper-award-ddck.dovetail.com/data/2jn7HNByGbmvslm31JqDHk#:v:h=4xr6n6RSWfQ9lO9brQVXrX
AIAAIC1739,"An Israeli settler group posted an inflammatory AI-generated video showing the Al-Aqsa Mosque in occupied East Jerusalem burning to the ground, prompting widespread comdemnation.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake AI video shows Al-Aqsa mosque burning,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-ai-video-shows-al-aqsa-burning,Issue,,2024,2024,Israel; Palestine,Politics,Temple Mount Activists,Temple Mount Activists,,Deepfake - video,Intimidate/threaten Palestinians,User comments/complaints,Mis/disinformation,Governance,,,,,,,,,10/13/2024 22:53,https://best-paper-award-ddck.dovetail.com/data/2jn7HNByGbmvslm31JqDHk#:v:h=4xr6n6RSWfQ9lO9brQVXrX
AIAAIC1469,"OpenAI’s AI model, ChatGPT, has been accused of violating the General Data Protection Regulation (GDPR) by not correcting inaccurate personal information.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,ChatGPT accused of violating GDPR by not correcting inaccurate personal information,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-said-to-violate-gdpr-by-not-correcting-inaccurate-personal-info,Incident,2022,2024,2024,Austria,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot,Generate text,Legal complaint,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 12:38,https://best-paper-award-ddck.dovetail.com/data/6AJcNsz8AZfklQimhDzbDm#:v:h=4BVIj1bpagKKeKBNCEXBNb
AIAAIC1469,"OpenAI’s AI model, ChatGPT, has been accused of violating the General Data Protection Regulation (GDPR) by not correcting inaccurate personal information.",Entity - AI developer company,Responsible Entities,ChatGPT accused of violating GDPR by not correcting inaccurate personal information,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-said-to-violate-gdpr-by-not-correcting-inaccurate-personal-info,Incident,2022,2024,2024,Austria,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot,Generate text,Legal complaint,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 12:38,https://best-paper-award-ddck.dovetail.com/data/6AJcNsz8AZfklQimhDzbDm#:v:h=4BVIj1bpagKKeKBNCEXBNb
AIAAIC1326,"The New York Police Department ended its use of Knightscope's security robot in Times Square subway station after a six-month trial, calling into question the effectiveness of the robot. Initially heralded as a low-cost method of deterrning crime, the robot, which was designed to operate autonomously, received a mixed recpetion from New Yorkers and visitors, with some saying it was potentially a valuable additional crime-fighting resource, whilst others reckoned it seemed to do very little, was unable to walk up or down stairs, always required assistance, was a waste of resources, and threatened people's privacy. In addition to raising questions about the effectiveness of the Knightscope K5 robot as a crime-fighting tool, the NYPD's decision to stop its use - for the time being -  highlights the careful balance police authorities are seen to have to strike between fighting crime, and protecting the legal rights and ethical concerns of citizens. ",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,NYPD ends Knightscope K5 security robot trial,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/nypd-ends-knightscope-k5-security-robot-trial,Issue,2015,2023,2024,USA,Govt - police,New York Police Department (NYPD),Knightscope,Knightscope K5,Robotics,Strengthen security,Deployer statement,Effectiveness/value; Privacy,,Privacy loss,,,,Pilot termination,,,,10/2/2024 20:09,https://best-paper-award-ddck.dovetail.com/data/7372OQh5XSUzowoL7rWaoA#:v:h=4EGlJ3KSRKDKapcHdYRmxn
AIAAIC1326,"The New York Police Department ended its use of Knightscope's security robot in Times Square subway station after a six-month trial, calling into question the effectiveness of the robot. Initially heralded as a low-cost method of deterrning crime, the robot, which was designed to operate autonomously, received a mixed recpetion from New Yorkers and visitors, with some saying it was potentially a valuable additional crime-fighting resource, whilst others reckoned it seemed to do very little, was unable to walk up or down stairs, always required assistance, was a waste of resources, and threatened people's privacy. In addition to raising questions about the effectiveness of the Knightscope K5 robot as a crime-fighting tool, the NYPD's decision to stop its use - for the time being -  highlights the careful balance police authorities are seen to have to strike between fighting crime, and protecting the legal rights and ethical concerns of citizens. ",Entity - government authorities that adopt AI,Responsible Entities,NYPD ends Knightscope K5 security robot trial,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/nypd-ends-knightscope-k5-security-robot-trial,Issue,2015,2023,2024,USA,Govt - police,New York Police Department (NYPD),Knightscope,Knightscope K5,Robotics,Strengthen security,Deployer statement,Effectiveness/value; Privacy,,Privacy loss,,,,Pilot termination,,,,10/2/2024 20:09,https://best-paper-award-ddck.dovetail.com/data/7372OQh5XSUzowoL7rWaoA#:v:h=4EGlJ3KSRKDKapcHdYRmxn
AIAAIC1166,"Male classmates reputedly used girls' photos found online to concoct and circulate AI-generated pornographic images of female students as young as 14 years old in group chats. One victim told the Wall Street Journal, 'We're aware that there are creepy guys out there but you'd never think one of your classmates would violate you like this.'  ",Cause - Human causes - Human abuse of AI tools,Cause,Westfield High School non-concensual nude deepfakes,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/westfield-high-school-non-concensual-nude-deepfakes,Incident,,2023,2023,USA,Education,Westfield High School students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,Police investigation,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/24/2024 21:30,https://best-paper-award-ddck.dovetail.com/data/7lCkwKfvJsjHwYaeuKWjwU#:v:h=4G2sSymgI7VOkR7JWxi4YP
AIAAIC1166,"Male classmates reputedly used girls' photos found online to concoct and circulate AI-generated pornographic images of female students as young as 14 years old in group chats. One victim told the Wall Street Journal, 'We're aware that there are creepy guys out there but you'd never think one of your classmates would violate you like this.'  ",Entity - malicious human,Responsible Entities,Westfield High School non-concensual nude deepfakes,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/westfield-high-school-non-concensual-nude-deepfakes,Incident,,2023,2023,USA,Education,Westfield High School students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,Police investigation,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/24/2024 21:30,https://best-paper-award-ddck.dovetail.com/data/7lCkwKfvJsjHwYaeuKWjwU#:v:h=4G2sSymgI7VOkR7JWxi4YP
AIAAIC1166,"Male classmates reputedly used girls' photos found online to concoct and circulate AI-generated pornographic images of female students as young as 14 years old in group chats. One victim told the Wall Street Journal, 'We're aware that there are creepy guys out there but you'd never think one of your classmates would violate you like this.'  ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Westfield High School non-concensual nude deepfakes,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/westfield-high-school-non-concensual-nude-deepfakes,Incident,,2023,2023,USA,Education,Westfield High School students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,Police investigation,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/24/2024 21:30,https://best-paper-award-ddck.dovetail.com/data/7lCkwKfvJsjHwYaeuKWjwU#:v:h=4G2sSymgI7VOkR7JWxi4YP
AIAAIC1692,"The lawsuit alleges that the website operators violate US federal and California state laws against revenge pornography, deepfake pornography and child pornography, alongside California’s unfair competition law as “the harm they cause to consumers greatly outweighs any benefits associated with those practices.”",Cause - organization causes - legal non-compliance,Cause,San Francisco City Attorney sues 16 denudification apps,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-francisco-city-attorney-sues-16-denudification-apps,Incident,,2024,2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",,Deepfake - image; Machine learning,Undress people,Lawsuit filing/litigation,Ethics/values; Privacy; Safety,Governance,Anxiety/distress; Financial loss; Harassment/bullying; Privacy loss,,,,,,,,10/12/2024 1:26,https://best-paper-award-ddck.dovetail.com/data/96DTYpYxcFqkuVOJeWfX0#:v:h=4H9gjdvMn6XAgOV8AJqLPk
AIAAIC1409,"Worldcoin's activitiess in Argentina had caused 'public notoriety due to the procedure of scanning the face and iris of numerous people in exchange for economic compensation in different parts of the Autonomous City of Buenos Aires and the provinces of Buenos Aires, Córdoba, Mendoza and Black river,' the AAIP said.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Argentina opens investigation into Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/argentina-opens-investigation-into-worldcoin,Incident,2023,2023,2023,Argentina,Business/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,,Regulatory investigation,,10/2/2024 15:51,https://best-paper-award-ddck.dovetail.com/data/1C510OQS5oCPh20zXjb4oz#:v:h=4HOoYB432Py5S1Ebpy058i
AIAAIC1409,"Worldcoin's activitiess in Argentina had caused 'public notoriety due to the procedure of scanning the face and iris of numerous people in exchange for economic compensation in different parts of the Autonomous City of Buenos Aires and the provinces of Buenos Aires, Córdoba, Mendoza and Black river,' the AAIP said.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Argentina opens investigation into Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/argentina-opens-investigation-into-worldcoin,Incident,2023,2023,2023,Argentina,Business/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,,Regulatory investigation,,10/2/2024 15:51,https://best-paper-award-ddck.dovetail.com/data/1C510OQS5oCPh20zXjb4oz#:v:h=4HOoYB432Py5S1Ebpy058i
AIAAIC1737,"Elon Musk shared an AI-generated image of Vice President Kamala Harris dressed in a red Soviet-style uniform with a hammer and sickle logo, prompting concerns about political disinformation and manipulation. Posted in response to a graphic shared by Kamala Harris' US presidential campaign on X that read, ""Donald Trump vows to be a dictator on day one,"" Musk's post, which lacked a label indicating it was AI-generated, sparked a wave of responses from X users.  Many users seemed to believe the image was real, while others criticised it as disinformation. The post follows a series of AI-generated media shared by former President Trump on X and his Truth Social platform, including images of Harris as a communist dictator and purported fans of both Taylor Swift and Trump.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"Elon Musk shares AI-generated image of ""communist"" Kamala Harris",10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elon-musk-shares-ai-generated-image-of-communist-kamala-harris,Issue,,2024,2024,USA,Politics,Elon Musk,,,Deepfake - image,Satirise/parody,User comments/complaints,Ethics/values; Mis/disinformation,,,,,,,,,,10/13/2024 22:56,https://best-paper-award-ddck.dovetail.com/data/7lyPh8wpqTH5qX4Z06FUDk#:v:h=4IfSZgXgTyowI5YCbMYkKx
AIAAIC1737,"Elon Musk shared an AI-generated image of Vice President Kamala Harris dressed in a red Soviet-style uniform with a hammer and sickle logo, prompting concerns about political disinformation and manipulation. Posted in response to a graphic shared by Kamala Harris' US presidential campaign on X that read, ""Donald Trump vows to be a dictator on day one,"" Musk's post, which lacked a label indicating it was AI-generated, sparked a wave of responses from X users.  Many users seemed to believe the image was real, while others criticised it as disinformation. The post follows a series of AI-generated media shared by former President Trump on X and his Truth Social platform, including images of Harris as a communist dictator and purported fans of both Taylor Swift and Trump.",Cause - Human causes - Human abuse of AI tools,Cause,"Elon Musk shares AI-generated image of ""communist"" Kamala Harris",10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elon-musk-shares-ai-generated-image-of-communist-kamala-harris,Issue,,2024,2024,USA,Politics,Elon Musk,,,Deepfake - image,Satirise/parody,User comments/complaints,Ethics/values; Mis/disinformation,,,,,,,,,,10/13/2024 22:56,https://best-paper-award-ddck.dovetail.com/data/7lyPh8wpqTH5qX4Z06FUDk#:v:h=4IfSZgXgTyowI5YCbMYkKx
AIAAIC1737,"Elon Musk shared an AI-generated image of Vice President Kamala Harris dressed in a red Soviet-style uniform with a hammer and sickle logo, prompting concerns about political disinformation and manipulation. Posted in response to a graphic shared by Kamala Harris' US presidential campaign on X that read, ""Donald Trump vows to be a dictator on day one,"" Musk's post, which lacked a label indicating it was AI-generated, sparked a wave of responses from X users.  Many users seemed to believe the image was real, while others criticised it as disinformation. The post follows a series of AI-generated media shared by former President Trump on X and his Truth Social platform, including images of Harris as a communist dictator and purported fans of both Taylor Swift and Trump.",Entity - malicious human,Responsible Entities,"Elon Musk shares AI-generated image of ""communist"" Kamala Harris",10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elon-musk-shares-ai-generated-image-of-communist-kamala-harris,Issue,,2024,2024,USA,Politics,Elon Musk,,,Deepfake - image,Satirise/parody,User comments/complaints,Ethics/values; Mis/disinformation,,,,,,,,,,10/13/2024 22:56,https://best-paper-award-ddck.dovetail.com/data/7lyPh8wpqTH5qX4Z06FUDk#:v:h=4IfSZgXgTyowI5YCbMYkKx
AIAAIC1115,"The incident prompted the actor to resort to litigation, which resulted in a landmark decision in which Delhi's High Court reaffirmed Kapoor's personality rights and prohibited 'all offenders from misusing his personality attributes without his permission in any manner.'  It also protected the phrase 'jhakaas'.  The court also ordered domain registrar sites, including GoDaddy, to takedown two websites named in the suit.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Deepfakes violate Anil Kapoor personality rights,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfakes-violate-anil-kapoor-personality-rights,Incident,,2023,2023,India,Media/entertainment/sports/arts,,,,"Deepfake - video, audio; Machine learning",Damage reputation,Lawsuit filing/litigation,Legal; Mis/disinformation,Governance,IP/identity loss; Personality rights loss,,,,Content takedown,,Litigation,,10/30/2024 16:36,https://best-paper-award-ddck.dovetail.com/data/6bQZNgqLUFXlkiUc07TpA5#:v:h=4Jn7q48xHrB5sOAwOCTglH
AIAAIC1115,"The incident prompted the actor to resort to litigation, which resulted in a landmark decision in which Delhi's High Court reaffirmed Kapoor's personality rights and prohibited 'all offenders from misusing his personality attributes without his permission in any manner.'  It also protected the phrase 'jhakaas'.  The court also ordered domain registrar sites, including GoDaddy, to takedown two websites named in the suit.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfakes violate Anil Kapoor personality rights,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfakes-violate-anil-kapoor-personality-rights,Incident,,2023,2023,India,Media/entertainment/sports/arts,,,,"Deepfake - video, audio; Machine learning",Damage reputation,Lawsuit filing/litigation,Legal; Mis/disinformation,Governance,IP/identity loss; Personality rights loss,,,,Content takedown,,Litigation,,10/30/2024 16:36,https://best-paper-award-ddck.dovetail.com/data/6bQZNgqLUFXlkiUc07TpA5#:v:h=4Jn7q48xHrB5sOAwOCTglH
AIAAIC1115,"The incident prompted the actor to resort to litigation, which resulted in a landmark decision in which Delhi's High Court reaffirmed Kapoor's personality rights and prohibited 'all offenders from misusing his personality attributes without his permission in any manner.'  It also protected the phrase 'jhakaas'.  The court also ordered domain registrar sites, including GoDaddy, to takedown two websites named in the suit.",Entity - no specific info,Responsible Entities,Deepfakes violate Anil Kapoor personality rights,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfakes-violate-anil-kapoor-personality-rights,Incident,,2023,2023,India,Media/entertainment/sports/arts,,,,"Deepfake - video, audio; Machine learning",Damage reputation,Lawsuit filing/litigation,Legal; Mis/disinformation,Governance,IP/identity loss; Personality rights loss,,,,Content takedown,,Litigation,,10/30/2024 16:36,https://best-paper-award-ddck.dovetail.com/data/6bQZNgqLUFXlkiUc07TpA5#:v:h=4Jn7q48xHrB5sOAwOCTglH
AIAAIC0916,"Adobe has been automatically analysing customer content stored on Creative Cloud to train its AI algorithms, according to media reports. The discovery sparked graphic designers, artists and other customers to share their concerns that Adobe is abusing their privacy and stealing their work to improve its own automated systems. Some saw it as another indication that their jobs are at risk of being replaced by robots. Adobe's content analysis FAQ states it may use machine learning 'to develop and improve our products and services' and 'provide product features and customize our products and services ', providing examples such as the correction of perspective in images and automatically enhancing a document's headings and tables. The row reflects broader concerns amongst artists, illustrators and others that their work is being scraped and used to train generative AI models such as DALL-E and Midjourney without their consent, thereby abusing their IP, commoditising their output, and potentially putting them out of work.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Adobe Creative Cloud uses customer to train AI systems,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/adobe-creative-cloud-content-analysis,Incident,,2023,2023,USA; Global,Business/professional services,Adobe users,Adobe,Creative Cloud; Document Cloud,Machine learning; Pattern recognition; Object recognition,"Improve products, services",User comments/complaints,Privacy; Confidentiality; Employment,Governance; Marketing; Privacy,,,,,System update,,,,10/13/2024 22:41,https://best-paper-award-ddck.dovetail.com/data/3A8tFdVMMNVu70uFKWnFQm#:v:h=4JN6nYeb3hEKiI5PiCNov7
AIAAIC0916,"Adobe has been automatically analysing customer content stored on Creative Cloud to train its AI algorithms, according to media reports. The discovery sparked graphic designers, artists and other customers to share their concerns that Adobe is abusing their privacy and stealing their work to improve its own automated systems. Some saw it as another indication that their jobs are at risk of being replaced by robots. Adobe's content analysis FAQ states it may use machine learning 'to develop and improve our products and services' and 'provide product features and customize our products and services ', providing examples such as the correction of perspective in images and automatically enhancing a document's headings and tables. The row reflects broader concerns amongst artists, illustrators and others that their work is being scraped and used to train generative AI models such as DALL-E and Midjourney without their consent, thereby abusing their IP, commoditising their output, and potentially putting them out of work.",Entity - AI developer company,Responsible Entities,Adobe Creative Cloud uses customer to train AI systems,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/adobe-creative-cloud-content-analysis,Incident,,2023,2023,USA; Global,Business/professional services,Adobe users,Adobe,Creative Cloud; Document Cloud,Machine learning; Pattern recognition; Object recognition,"Improve products, services",User comments/complaints,Privacy; Confidentiality; Employment,Governance; Marketing; Privacy,,,,,System update,,,,10/13/2024 22:41,https://best-paper-award-ddck.dovetail.com/data/3A8tFdVMMNVu70uFKWnFQm#:v:h=4JN6nYeb3hEKiI5PiCNov7
AIAAIC0916,"Adobe has been automatically analysing customer content stored on Creative Cloud to train its AI algorithms, according to media reports. The discovery sparked graphic designers, artists and other customers to share their concerns that Adobe is abusing their privacy and stealing their work to improve its own automated systems. Some saw it as another indication that their jobs are at risk of being replaced by robots. Adobe's content analysis FAQ states it may use machine learning 'to develop and improve our products and services' and 'provide product features and customize our products and services ', providing examples such as the correction of perspective in images and automatically enhancing a document's headings and tables. The row reflects broader concerns amongst artists, illustrators and others that their work is being scraped and used to train generative AI models such as DALL-E and Midjourney without their consent, thereby abusing their IP, commoditising their output, and potentially putting them out of work.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Adobe Creative Cloud uses customer to train AI systems,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/adobe-creative-cloud-content-analysis,Incident,,2023,2023,USA; Global,Business/professional services,Adobe users,Adobe,Creative Cloud; Document Cloud,Machine learning; Pattern recognition; Object recognition,"Improve products, services",User comments/complaints,Privacy; Confidentiality; Employment,Governance; Marketing; Privacy,,,,,System update,,,,10/13/2024 22:41,https://best-paper-award-ddck.dovetail.com/data/3A8tFdVMMNVu70uFKWnFQm#:v:h=4JN6nYeb3hEKiI5PiCNov7
AIAAIC1048,"A Chinese man with the pseudonym 'Baoer Kechatie' who masqueraded as a Chechnyan special forces soldier operating in Ukraine posted false stories about his exploits in the Russia-Ukraine war, in addition to selling vodka, honey and other products from his e-commerce store. While a number of the deepfake videos were labeled as movie or drama plots, comments posted by users indicated he had successfully convinced many people, some of whom 'even cheered for his success', according to Sixth Tone. ",Entity - malicious human,Responsible Entities,Deepfake 'soldier' posts false Ukraine war stories,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-soldier-posts-fake-ukraine-war-stories,Incident,,2023,2023,China; Ukraine,Politics; Govt - defence,,,,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,,Mis/disinformation; Fraud,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:23,https://best-paper-award-ddck.dovetail.com/data/385fZMj8UJv8NTCs2iKHva#:v:h=4M93EnFTXq412pDhUtRsa3
AIAAIC1048,"A Chinese man with the pseudonym 'Baoer Kechatie' who masqueraded as a Chechnyan special forces soldier operating in Ukraine posted false stories about his exploits in the Russia-Ukraine war, in addition to selling vodka, honey and other products from his e-commerce store. While a number of the deepfake videos were labeled as movie or drama plots, comments posted by users indicated he had successfully convinced many people, some of whom 'even cheered for his success', according to Sixth Tone. ",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake 'soldier' posts false Ukraine war stories,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-soldier-posts-fake-ukraine-war-stories,Incident,,2023,2023,China; Ukraine,Politics; Govt - defence,,,,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,,Mis/disinformation; Fraud,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:23,https://best-paper-award-ddck.dovetail.com/data/385fZMj8UJv8NTCs2iKHva#:v:h=4M93EnFTXq412pDhUtRsa3
AIAAIC1048,"A Chinese man with the pseudonym 'Baoer Kechatie' who masqueraded as a Chechnyan special forces soldier operating in Ukraine posted false stories about his exploits in the Russia-Ukraine war, in addition to selling vodka, honey and other products from his e-commerce store. While a number of the deepfake videos were labeled as movie or drama plots, comments posted by users indicated he had successfully convinced many people, some of whom 'even cheered for his success', according to Sixth Tone. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake 'soldier' posts false Ukraine war stories,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-soldier-posts-fake-ukraine-war-stories,Incident,,2023,2023,China; Ukraine,Politics; Govt - defence,,,,"Deepfake - audio, video; Machine learning",Scare/confuse/destabilise,,Mis/disinformation; Fraud,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:23,https://best-paper-award-ddck.dovetail.com/data/385fZMj8UJv8NTCs2iKHva#:v:h=4M93EnFTXq412pDhUtRsa3
AIAAIC1077,"Maxpread Technologies' use of an AI-generated CEO to manipulate investors into believing the company was legitimate and trustworthy prompted a US regulator to issue a desist and refrain order against the entity and its founder 'Jan Gregory Cerato'. The video, which was created using AI video generation tool Synthesia aused to launch the company, was fronted by 'Michael Vanes'. ",Incident - organization-driven - problematic AI implementation,Incident Type,Maxpread Technologies fake AI CEO investment scam,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maxpread-technologies-fake-ai-ceo-scam,Incident,,2023,2023,UAE/Dubai; Hong Kong; USA,Banking/financial services,Maxpread Technologies,Maxpread Technologies; Synthesia,Synthesia,"Deepfake - video, audio; Machine learning",Mislead investors,Regulatory inquiry/investigation,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation; Fraud,,,,,, Regulatory action,,10/30/2024 16:46,https://best-paper-award-ddck.dovetail.com/data/6v5Z947ZWboHjAGrRKqnjd#:v:h=4Oi6haSSGh4bN1ibrrzIcx
AIAAIC1077,"Maxpread Technologies' use of an AI-generated CEO to manipulate investors into believing the company was legitimate and trustworthy prompted a US regulator to issue a desist and refrain order against the entity and its founder 'Jan Gregory Cerato'. The video, which was created using AI video generation tool Synthesia aused to launch the company, was fronted by 'Michael Vanes'. ",Cause - organization causes - poor business ethics,Cause,Maxpread Technologies fake AI CEO investment scam,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maxpread-technologies-fake-ai-ceo-scam,Incident,,2023,2023,UAE/Dubai; Hong Kong; USA,Banking/financial services,Maxpread Technologies,Maxpread Technologies; Synthesia,Synthesia,"Deepfake - video, audio; Machine learning",Mislead investors,Regulatory inquiry/investigation,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation; Fraud,,,,,, Regulatory action,,10/30/2024 16:46,https://best-paper-award-ddck.dovetail.com/data/6v5Z947ZWboHjAGrRKqnjd#:v:h=4Oi6haSSGh4bN1ibrrzIcx
AIAAIC1077,"Maxpread Technologies' use of an AI-generated CEO to manipulate investors into believing the company was legitimate and trustworthy prompted a US regulator to issue a desist and refrain order against the entity and its founder 'Jan Gregory Cerato'. The video, which was created using AI video generation tool Synthesia aused to launch the company, was fronted by 'Michael Vanes'. ",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Maxpread Technologies fake AI CEO investment scam,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maxpread-technologies-fake-ai-ceo-scam,Incident,,2023,2023,UAE/Dubai; Hong Kong; USA,Banking/financial services,Maxpread Technologies,Maxpread Technologies; Synthesia,Synthesia,"Deepfake - video, audio; Machine learning",Mislead investors,Regulatory inquiry/investigation,Ethics/values; Mis/disinformation,Governance; Marketing,Manipulation; Fraud,,,,,, Regulatory action,,10/30/2024 16:46,https://best-paper-award-ddck.dovetail.com/data/6v5Z947ZWboHjAGrRKqnjd#:v:h=4Oi6haSSGh4bN1ibrrzIcx
AIAAIC1059,"Kerala, India, resident PS Radhakrishnan was defrauded of INR 40,000 after scammers used deepfake technologies to impersonate a former work colleague at Coal India seeking money for his sister's surgery on a WhatsApp video call.  73 year-old Radhakrishnan told the Hindustan Times that he had received a call from an anonymous number, followed by messages on WhatsApp from the same number with the person identifying himseld as Radhakrishnan’s former colleague at Coal India Ltd.  'We had worked together for nearly four decades and I knew him well. The display picture was his photo. He asked about my daughter and where she worked. We texted for some time during which he shared his family photographs and asked about our common colleagues,' he said.  'Seconds later, he called and looked exactly like my former colleague,' he added. 'Even though only his face was visible, it was clear. His lips and eyes moved like any normal person as we talked in English. The call lasted just 25 seconds before it got cut. He later came back on a voice call and spoke about the urgency for money. I didn’t ask any more questions and transferred the money.'",Entity - malicious human,Responsible Entities,"Kerala man loses INR 40,000 to deepfake work colleague",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kerala-man-loses-inr-40000-to-deepfake-work-colleague,Incident,,2023,2023,India,"Private - individual, family",,,,"Deepfake - audio, video; Machine learning",Defraud,Police investigation,Identity theft/impersonation,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:19,https://best-paper-award-ddck.dovetail.com/data/15K2mTXPwz4e9QIP62NnlO#:v:h=4QytGA9sM55lQz7X0ZTUfJ
AIAAIC1059,"Kerala, India, resident PS Radhakrishnan was defrauded of INR 40,000 after scammers used deepfake technologies to impersonate a former work colleague at Coal India seeking money for his sister's surgery on a WhatsApp video call.  73 year-old Radhakrishnan told the Hindustan Times that he had received a call from an anonymous number, followed by messages on WhatsApp from the same number with the person identifying himseld as Radhakrishnan’s former colleague at Coal India Ltd.  'We had worked together for nearly four decades and I knew him well. The display picture was his photo. He asked about my daughter and where she worked. We texted for some time during which he shared his family photographs and asked about our common colleagues,' he said.  'Seconds later, he called and looked exactly like my former colleague,' he added. 'Even though only his face was visible, it was clear. His lips and eyes moved like any normal person as we talked in English. The call lasted just 25 seconds before it got cut. He later came back on a voice call and spoke about the urgency for money. I didn’t ask any more questions and transferred the money.'","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"Kerala man loses INR 40,000 to deepfake work colleague",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kerala-man-loses-inr-40000-to-deepfake-work-colleague,Incident,,2023,2023,India,"Private - individual, family",,,,"Deepfake - audio, video; Machine learning",Defraud,Police investigation,Identity theft/impersonation,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:19,https://best-paper-award-ddck.dovetail.com/data/15K2mTXPwz4e9QIP62NnlO#:v:h=4QytGA9sM55lQz7X0ZTUfJ
AIAAIC1059,"Kerala, India, resident PS Radhakrishnan was defrauded of INR 40,000 after scammers used deepfake technologies to impersonate a former work colleague at Coal India seeking money for his sister's surgery on a WhatsApp video call.  73 year-old Radhakrishnan told the Hindustan Times that he had received a call from an anonymous number, followed by messages on WhatsApp from the same number with the person identifying himseld as Radhakrishnan’s former colleague at Coal India Ltd.  'We had worked together for nearly four decades and I knew him well. The display picture was his photo. He asked about my daughter and where she worked. We texted for some time during which he shared his family photographs and asked about our common colleagues,' he said.  'Seconds later, he called and looked exactly like my former colleague,' he added. 'Even though only his face was visible, it was clear. His lips and eyes moved like any normal person as we talked in English. The call lasted just 25 seconds before it got cut. He later came back on a voice call and spoke about the urgency for money. I didn’t ask any more questions and transferred the money.'",Cause - Human causes - Human abuse of AI tools,Cause,"Kerala man loses INR 40,000 to deepfake work colleague",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/kerala-man-loses-inr-40000-to-deepfake-work-colleague,Incident,,2023,2023,India,"Private - individual, family",,,,"Deepfake - audio, video; Machine learning",Defraud,Police investigation,Identity theft/impersonation,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:19,https://best-paper-award-ddck.dovetail.com/data/15K2mTXPwz4e9QIP62NnlO#:v:h=4QytGA9sM55lQz7X0ZTUfJ
AIAAIC1167,"A fake Facebook video ad used clips of a Canadian television anchor and Prime Minister Justin Trudeau to lure Canadians to invest in Petro-Canada.  The video, which was seen over 15,000 times, gave the appearance of Trudeau and Canadian Broadcasting Corporation (CBC) anchor Aarti Pole explaining that Petro-Canada had launched a new investment platform that was available to all residents of the country.  The energy company confirmed it had made no such offer and CBC said Pole had made no such statement.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake Justin Trudeau endorses Petro-Canada scam,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-justin-trudeau-endorses-petro-canada-scam,Incident,,2023,2023,Canada,Energy; Politics,Facebook,,,"Deepfake - audio, video; Machine learning",Defraud,Fact check,Fraud; Mis/disinformation,Governance; Marketing,Manipulation; Financial loss,,,,,,,,10/24/2024 21:34,https://best-paper-award-ddck.dovetail.com/data/1goQQceJtvuZycXlcJ0iZ6#:v:h=4QNWkaIDfn54LKd240ADyg
AIAAIC1167,"A fake Facebook video ad used clips of a Canadian television anchor and Prime Minister Justin Trudeau to lure Canadians to invest in Petro-Canada.  The video, which was seen over 15,000 times, gave the appearance of Trudeau and Canadian Broadcasting Corporation (CBC) anchor Aarti Pole explaining that Petro-Canada had launched a new investment platform that was available to all residents of the country.  The energy company confirmed it had made no such offer and CBC said Pole had made no such statement.",Entity - no specific info,Responsible Entities,Deepfake Justin Trudeau endorses Petro-Canada scam,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-justin-trudeau-endorses-petro-canada-scam,Incident,,2023,2023,Canada,Energy; Politics,Facebook,,,"Deepfake - audio, video; Machine learning",Defraud,Fact check,Fraud; Mis/disinformation,Governance; Marketing,Manipulation; Financial loss,,,,,,,,10/24/2024 21:34,https://best-paper-award-ddck.dovetail.com/data/1goQQceJtvuZycXlcJ0iZ6#:v:h=4QNWkaIDfn54LKd240ADyg
AIAAIC1167,"A fake Facebook video ad used clips of a Canadian television anchor and Prime Minister Justin Trudeau to lure Canadians to invest in Petro-Canada.  The video, which was seen over 15,000 times, gave the appearance of Trudeau and Canadian Broadcasting Corporation (CBC) anchor Aarti Pole explaining that Petro-Canada had launched a new investment platform that was available to all residents of the country.  The energy company confirmed it had made no such offer and CBC said Pole had made no such statement.",Cause - no specific info,Cause,Deepfake Justin Trudeau endorses Petro-Canada scam,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-justin-trudeau-endorses-petro-canada-scam,Incident,,2023,2023,Canada,Energy; Politics,Facebook,,,"Deepfake - audio, video; Machine learning",Defraud,Fact check,Fraud; Mis/disinformation,Governance; Marketing,Manipulation; Financial loss,,,,,,,,10/24/2024 21:34,https://best-paper-award-ddck.dovetail.com/data/1goQQceJtvuZycXlcJ0iZ6#:v:h=4QNWkaIDfn54LKd240ADyg
AIAAIC0995,"A German magazine published a fake, AI-generated interview with former F1 racing driver Michael Schumacher, resulting in widespread outcry and ridicule. German tabloid magazine Die Aktuelle received a public dressing down for publishing a so-called 'exclusive interview' with the former F1 racing driver, who had been in an induced coma since a 2014 skiing accident. The article was produced using Character AI, an AI system that automatically generated 'quotes' by Schumacher about his health and family, and only revealed it had been artificially generated at the bottom of the 'interview'. The magazine ran it on its front cover, with the headline 'Michael Schumacher, the first interview'.",Cause - Human causes - Human abuse of AI tools,Cause,Magazine publishes Michael Schumacher fake AI-generated interview,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/michael-schumacher-ai-exclusive-interview,Incident,,2023,2023,Germany,Media/entertainment/sports/arts,Die Aktuelle,Character AI,Character AI,Chatbot; Machine learning,Communicate with personalities,Article publication,Mis/disinformation; Privacy; Ethics/values,Governance; Marketing,Privacy loss,,,,CEO/senior leadership termination,,Legal complaint,,10/11/2024 20:20,https://best-paper-award-ddck.dovetail.com/data/7iCFKHihyozzIm0jPOzPEA#:v:h=4SzdlIOipKlPMIsRHbuBPD
AIAAIC0995,"A German magazine published a fake, AI-generated interview with former F1 racing driver Michael Schumacher, resulting in widespread outcry and ridicule. German tabloid magazine Die Aktuelle received a public dressing down for publishing a so-called 'exclusive interview' with the former F1 racing driver, who had been in an induced coma since a 2014 skiing accident. The article was produced using Character AI, an AI system that automatically generated 'quotes' by Schumacher about his health and family, and only revealed it had been artificially generated at the bottom of the 'interview'. The magazine ran it on its front cover, with the headline 'Michael Schumacher, the first interview'.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Magazine publishes Michael Schumacher fake AI-generated interview,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/michael-schumacher-ai-exclusive-interview,Incident,,2023,2023,Germany,Media/entertainment/sports/arts,Die Aktuelle,Character AI,Character AI,Chatbot; Machine learning,Communicate with personalities,Article publication,Mis/disinformation; Privacy; Ethics/values,Governance; Marketing,Privacy loss,,,,CEO/senior leadership termination,,Legal complaint,,10/11/2024 20:20,https://best-paper-award-ddck.dovetail.com/data/7iCFKHihyozzIm0jPOzPEA#:v:h=4SzdlIOipKlPMIsRHbuBPD
AIAAIC0995,"A German magazine published a fake, AI-generated interview with former F1 racing driver Michael Schumacher, resulting in widespread outcry and ridicule. German tabloid magazine Die Aktuelle received a public dressing down for publishing a so-called 'exclusive interview' with the former F1 racing driver, who had been in an induced coma since a 2014 skiing accident. The article was produced using Character AI, an AI system that automatically generated 'quotes' by Schumacher about his health and family, and only revealed it had been artificially generated at the bottom of the 'interview'. The magazine ran it on its front cover, with the headline 'Michael Schumacher, the first interview'.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Magazine publishes Michael Schumacher fake AI-generated interview,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/michael-schumacher-ai-exclusive-interview,Incident,,2023,2023,Germany,Media/entertainment/sports/arts,Die Aktuelle,Character AI,Character AI,Chatbot; Machine learning,Communicate with personalities,Article publication,Mis/disinformation; Privacy; Ethics/values,Governance; Marketing,Privacy loss,,,,CEO/senior leadership termination,,Legal complaint,,10/11/2024 20:20,https://best-paper-award-ddck.dovetail.com/data/7iCFKHihyozzIm0jPOzPEA#:v:h=4SzdlIOipKlPMIsRHbuBPD
AIAAIC1235,The use of real personal data by Bavarian police to test a controversial AI-powered analytics system that enables police forces across different German jurisdictions to share and analyse data has been flagged as potentially illegal.,Cause - organization causes - legal non-compliance,Cause,Bavaria tests police AI analytics software using real data,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bavaria-police-test-palantir-using-real-data,Issue,,2023,2023,Germany,Govt - police,Bayerisches Landeskriminalamt,Bayerisches Landeskriminalamt; Palantir,VeRA; Gotham,Data analytics; Machine learning,Identify criminal suspects,Media investigation,Legal; Privacy,Governance; Marketing,Privacy loss,,,,,,,,10/6/2024 23:49,https://best-paper-award-ddck.dovetail.com/data/7yCOzFlowkWHBdgBc4NW1h#:v:h=4SHvL3OaJk0mC6iF9CsYaW
AIAAIC1235,The use of real personal data by Bavarian police to test a controversial AI-powered analytics system that enables police forces across different German jurisdictions to share and analyse data has been flagged as potentially illegal.,Entity - government authorities that adopt AI,Responsible Entities,Bavaria tests police AI analytics software using real data,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bavaria-police-test-palantir-using-real-data,Issue,,2023,2023,Germany,Govt - police,Bayerisches Landeskriminalamt,Bayerisches Landeskriminalamt; Palantir,VeRA; Gotham,Data analytics; Machine learning,Identify criminal suspects,Media investigation,Legal; Privacy,Governance; Marketing,Privacy loss,,,,,,,,10/6/2024 23:49,https://best-paper-award-ddck.dovetail.com/data/7yCOzFlowkWHBdgBc4NW1h#:v:h=4SHvL3OaJk0mC6iF9CsYaW
AIAAIC1235,The use of real personal data by Bavarian police to test a controversial AI-powered analytics system that enables police forces across different German jurisdictions to share and analyse data has been flagged as potentially illegal.,Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Bavaria tests police AI analytics software using real data,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bavaria-police-test-palantir-using-real-data,Issue,,2023,2023,Germany,Govt - police,Bayerisches Landeskriminalamt,Bayerisches Landeskriminalamt; Palantir,VeRA; Gotham,Data analytics; Machine learning,Identify criminal suspects,Media investigation,Legal; Privacy,Governance; Marketing,Privacy loss,,,,,,,,10/6/2024 23:49,https://best-paper-award-ddck.dovetail.com/data/7yCOzFlowkWHBdgBc4NW1h#:v:h=4SHvL3OaJk0mC6iF9CsYaW
AIAAIC1305,"A 'digital peeping Tom' used PimEyes to identify the real names of anonymous porn stars whose films he had watched. According to an extract published in WIRED of journalist Kashmir Hill's book Your Face Belongs to Us, 'David' 'was able to upload screenshots of women whose pornography he had watched and get photos of them from elsewhere on the web, a trail that sometimes led him to their legal names.'",Entity - malicious human,Responsible Entities,Film fan uses PimEyes to identify anonymous porn stars,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-used-to-identify-anonymous-porn-stars,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Media investigation,Governance; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 20:37,https://best-paper-award-ddck.dovetail.com/data/3Op3fWrJoLvAWUiBCnquJa#:v:h=4TixIQ1zjJn2IUTpNSAvYI
AIAAIC1305,"A 'digital peeping Tom' used PimEyes to identify the real names of anonymous porn stars whose films he had watched. According to an extract published in WIRED of journalist Kashmir Hill's book Your Face Belongs to Us, 'David' 'was able to upload screenshots of women whose pornography he had watched and get photos of them from elsewhere on the web, a trail that sometimes led him to their legal names.'",Cause - Human causes - Human abuse of AI tools,Cause,Film fan uses PimEyes to identify anonymous porn stars,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-used-to-identify-anonymous-porn-stars,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Media investigation,Governance; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 20:37,https://best-paper-award-ddck.dovetail.com/data/3Op3fWrJoLvAWUiBCnquJa#:v:h=4TixIQ1zjJn2IUTpNSAvYI
AIAAIC1305,"A 'digital peeping Tom' used PimEyes to identify the real names of anonymous porn stars whose films he had watched. According to an extract published in WIRED of journalist Kashmir Hill's book Your Face Belongs to Us, 'David' 'was able to upload screenshots of women whose pornography he had watched and get photos of them from elsewhere on the web, a trail that sometimes led him to their legal names.'",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,Film fan uses PimEyes to identify anonymous porn stars,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-used-to-identify-anonymous-porn-stars,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Media investigation,Governance; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 20:37,https://best-paper-award-ddck.dovetail.com/data/3Op3fWrJoLvAWUiBCnquJa#:v:h=4TixIQ1zjJn2IUTpNSAvYI
AIAAIC1012,"Canadian Tire came under fire from British Colombia's privacy commissioner for illegally operating facial recognition technology in four of its stores in the province.  The company used AxxonSoft and FaceFirst systems to collect facial images and videos of people entering Canadian Tire stores, created biometric templates, and compared them to a database of previously collected photos and biometric templates representing people of interest who had allegedly been involved in incidents at Canadian Tire stores in the same region.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Canadian Tire covertly uses facial recognition to collect user data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/canadian-tire-facial-recognition,Issue,,2023,2023,Canada,Retail,Canadian Tire,AxxonSoft; FaceFirst,"Face PSIM, FaceFrist",Facial recognition,"Strengthen security, safety",Regulatory inquiry/investigation,Privacy; Accuracy/reliability,Governance; Privacy; Marketing,Privacy loss,,,,System removal,,,,10/11/2024 20:08,https://best-paper-award-ddck.dovetail.com/data/4bfJw8kJsXqvccMMbVyEwL#:v:h=4VKkfWaje1fohsSNO8jAvi
AIAAIC1012,"Canadian Tire came under fire from British Colombia's privacy commissioner for illegally operating facial recognition technology in four of its stores in the province.  The company used AxxonSoft and FaceFirst systems to collect facial images and videos of people entering Canadian Tire stores, created biometric templates, and compared them to a database of previously collected photos and biometric templates representing people of interest who had allegedly been involved in incidents at Canadian Tire stores in the same region.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Canadian Tire covertly uses facial recognition to collect user data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/canadian-tire-facial-recognition,Issue,,2023,2023,Canada,Retail,Canadian Tire,AxxonSoft; FaceFirst,"Face PSIM, FaceFrist",Facial recognition,"Strengthen security, safety",Regulatory inquiry/investigation,Privacy; Accuracy/reliability,Governance; Privacy; Marketing,Privacy loss,,,,System removal,,,,10/11/2024 20:08,https://best-paper-award-ddck.dovetail.com/data/4bfJw8kJsXqvccMMbVyEwL#:v:h=4VKkfWaje1fohsSNO8jAvi
AIAAIC1012,"Canadian Tire came under fire from British Colombia's privacy commissioner for illegally operating facial recognition technology in four of its stores in the province.  The company used AxxonSoft and FaceFirst systems to collect facial images and videos of people entering Canadian Tire stores, created biometric templates, and compared them to a database of previously collected photos and biometric templates representing people of interest who had allegedly been involved in incidents at Canadian Tire stores in the same region.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Canadian Tire covertly uses facial recognition to collect user data,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/canadian-tire-facial-recognition,Issue,,2023,2023,Canada,Retail,Canadian Tire,AxxonSoft; FaceFirst,"Face PSIM, FaceFrist",Facial recognition,"Strengthen security, safety",Regulatory inquiry/investigation,Privacy; Accuracy/reliability,Governance; Privacy; Marketing,Privacy loss,,,,System removal,,,,10/11/2024 20:08,https://best-paper-award-ddck.dovetail.com/data/4bfJw8kJsXqvccMMbVyEwL#:v:h=4VKkfWaje1fohsSNO8jAvi
AIAAIC1414,"whilst Leonardo's terms of service state that users cannot 'generate content that includes impersonations of any real person or falsely portrays an individual in a misleading or defamatory way', Leonardo's guardrails can easily be bypassed by slightly misspelling celebrity names, and using sexually suggestive terms for image description. The ease with which users can instantly generate images on the site using its models highlights the platform’s versatility and the ease with which it can be misused.",Incident - human-driven - bypassing AI safeguards,Incident Type,Leonardo AI generates celebrity non-consensual porn images,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/leonardo-ai-generates-celebrity-non-consensual-porn-images,Incident,,2024,2024,Global,Media/entertainment/sports/arts,Leonardo AI,Leonardo AI,Leonardo AI,Text-to-image; Machine learning,Generate art,Media investigation,Identity theft/impersonation; Privacy; Safety,Governance,Identity theft/impersonation,,,,,,,,10/2/2024 15:19,https://best-paper-award-ddck.dovetail.com/data/755O5DoMqqfQiSeVyjdqUE#:v:h=4W9tDePXD8HndX96X9cUG7
AIAAIC1380,"Russian security forces are likely to have used facial recognition to arrest protestors at the funeral of Russian opposition leader Alexei Navalny, according to a local human rights group. OVID-Info reported that several people were detained at Navalny's funeral, including a woman captured on video saying 'Glory to the heroes,' the traditional response to the salute 'Glory to Ukraine.' She was charged with 'displaying a banned symbol' and handed a small fine, but was allowed to return home the next day. Other people were detained for unclear reasons. OVD-Info spokesman Dmitry Anisimov told Russian independent news outlet Agenstvo that the Russian government had installed new surveillance cameras around the church and cemetary, and that Russian police were able to identify and trace individuals from the funeral 'right up to their door.'",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Moscow arrests Navalny funeral attendees using facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/moscow-arrests-navalny-funeral-attendees-using-facial-recognition,Incident,,2024,2024,Russia,Govt - police; Govt - security,Moscow City Police,,,Facial recognition,Identify protestors,Media investigation,Human/civil rights; Privacy,Governance,,Loss of rights/freedoms; Privacy loss,,,,,,,10/2/2024 19:47,https://best-paper-award-ddck.dovetail.com/data/6272J8taqqi757P1Rd9w1p#:v:h=4WYDSsXYu2hgmIxiaKmzRg
AIAAIC1380,"Russian security forces are likely to have used facial recognition to arrest protestors at the funeral of Russian opposition leader Alexei Navalny, according to a local human rights group. OVID-Info reported that several people were detained at Navalny's funeral, including a woman captured on video saying 'Glory to the heroes,' the traditional response to the salute 'Glory to Ukraine.' She was charged with 'displaying a banned symbol' and handed a small fine, but was allowed to return home the next day. Other people were detained for unclear reasons. OVD-Info spokesman Dmitry Anisimov told Russian independent news outlet Agenstvo that the Russian government had installed new surveillance cameras around the church and cemetary, and that Russian police were able to identify and trace individuals from the funeral 'right up to their door.'",Cause - no specific info,Cause,Moscow arrests Navalny funeral attendees using facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/moscow-arrests-navalny-funeral-attendees-using-facial-recognition,Incident,,2024,2024,Russia,Govt - police; Govt - security,Moscow City Police,,,Facial recognition,Identify protestors,Media investigation,Human/civil rights; Privacy,Governance,,Loss of rights/freedoms; Privacy loss,,,,,,,10/2/2024 19:47,https://best-paper-award-ddck.dovetail.com/data/6272J8taqqi757P1Rd9w1p#:v:h=4WYDSsXYu2hgmIxiaKmzRg
AIAAIC1380,"Russian security forces are likely to have used facial recognition to arrest protestors at the funeral of Russian opposition leader Alexei Navalny, according to a local human rights group. OVID-Info reported that several people were detained at Navalny's funeral, including a woman captured on video saying 'Glory to the heroes,' the traditional response to the salute 'Glory to Ukraine.' She was charged with 'displaying a banned symbol' and handed a small fine, but was allowed to return home the next day. Other people were detained for unclear reasons. OVD-Info spokesman Dmitry Anisimov told Russian independent news outlet Agenstvo that the Russian government had installed new surveillance cameras around the church and cemetary, and that Russian police were able to identify and trace individuals from the funeral 'right up to their door.'",Entity - government authorities that adopt AI,Responsible Entities,Moscow arrests Navalny funeral attendees using facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/moscow-arrests-navalny-funeral-attendees-using-facial-recognition,Incident,,2024,2024,Russia,Govt - police; Govt - security,Moscow City Police,,,Facial recognition,Identify protestors,Media investigation,Human/civil rights; Privacy,Governance,,Loss of rights/freedoms; Privacy loss,,,,,,,10/2/2024 19:47,https://best-paper-award-ddck.dovetail.com/data/6272J8taqqi757P1Rd9w1p#:v:h=4WYDSsXYu2hgmIxiaKmzRg
AIAAIC1617,"In reality, the video was created by combining audio from a parody circulating on TikTok with footage of a speech Harris gave on reproductive rights at Howard University in April 2023. The original footage and official White House transcript do not contain such remarks.  A watermark added to the text on the podium indicated the video was created by a pro-Donald Trump meme account whose  tweet drew over 1.2 million views, according to AFP.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake Kamala Harris slurs her lines,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-kamala-harris-slurs-her-lines,Incident,,2024,2024,USA,Politics,,,,Deepfake - audio; Machine learning,Damage reputation,,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:19,https://best-paper-award-ddck.dovetail.com/data/4Mv9w4hi7cKln5S1y8Tfcf#:v:h=51srRz6fwogWhlEtxezhGn
AIAAIC1617,"In reality, the video was created by combining audio from a parody circulating on TikTok with footage of a speech Harris gave on reproductive rights at Howard University in April 2023. The original footage and official White House transcript do not contain such remarks.  A watermark added to the text on the podium indicated the video was created by a pro-Donald Trump meme account whose  tweet drew over 1.2 million views, according to AFP.",Entity - malicious human,Responsible Entities,Deepfake Kamala Harris slurs her lines,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-kamala-harris-slurs-her-lines,Incident,,2024,2024,USA,Politics,,,,Deepfake - audio; Machine learning,Damage reputation,,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:19,https://best-paper-award-ddck.dovetail.com/data/4Mv9w4hi7cKln5S1y8Tfcf#:v:h=51srRz6fwogWhlEtxezhGn
AIAAIC1407,Hong Kong's privacy regulator announced an investigation into Worldcoin's local operations due to 'serious risks to personal data privacy'.,Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Hong Kong privacy watchdog probes Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hong-kong-privacy-watchdog-probes-worldcoin,Incident,2023,2024,2024,Hong Kong,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance; Marketing,,,,,,,Regulatory investigation,,10/2/2024 16:25,https://best-paper-award-ddck.dovetail.com/data/5mopt5e5T1TOjzmI6drydr#:v:h=51SGvbnDnonoaJNzjaNGq7
AIAAIC1407,Hong Kong's privacy regulator announced an investigation into Worldcoin's local operations due to 'serious risks to personal data privacy'.,Entity - large dataset organization,Responsible Entities,Hong Kong privacy watchdog probes Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hong-kong-privacy-watchdog-probes-worldcoin,Incident,2023,2024,2024,Hong Kong,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance; Marketing,,,,,,,Regulatory investigation,,10/2/2024 16:25,https://best-paper-award-ddck.dovetail.com/data/5mopt5e5T1TOjzmI6drydr#:v:h=51SGvbnDnonoaJNzjaNGq7
AIAAIC1507,"Apparently created by Malaysian Instagram user @shahv4012, the image was shared more than 47 million times online, including by celebrities Dua Lipa, Lewis Hamilton, and Gigi and Bella Hadid. However, the image received criticism for “sanitising” the reality of the situation in Gaza. Critics, including actress Rachel Zegler, argue that the AI-generated image does not reflect the actual horrors faced by the Palestinian people.",Cause - Human causes - Human abuse of AI tools,Cause,All eyes on Rafah' deepfake criticised for 'sanitising' Gaza invasion,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/all-eyes-on-rafah-deepfake-criticised-for-sanitising-gaza-invasion,Issue,,2024,2024,Israel; Palestine,Govt - police; Govt - security; Govt - defence; Politics,@shahv4012,,,Deepfake - image; Machine learning,,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:00,https://best-paper-award-ddck.dovetail.com/data/3pMQJiGVIlqWlwBZ77v23m#:v:h=52w0gdGurBAm5ZXTTYRRmv
AIAAIC0917,"In response, Morris said the experiment was exempt because participants opted in, their identities were anonymised, and an intermediary evaluated the responses before they were shared with people who sought help.",Cause - organization causes - poor business ethics,Cause,Koko AI mental health counselling 'experiment' fails to obtain user consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/koko-ai-mental-health-counselling-experiment,Incident,,2023,2023,USA,Multiple; Health,Koko; Discord,Koko,GPT-3,Large language model; Machine learning,Provide mental health support,CEO statement,Ethics/values; Privacy,Governance,,,,,,,,,10/13/2024 22:40,https://best-paper-award-ddck.dovetail.com/data/4m68Cxn6n7RdYeBNYZskV0#:v:h=54wUJkktc1PAL3LsKv7GQx
AIAAIC1147,"Voice actors working in the video gaming industry were attacked using AI-generated versions of their own voices, and doxxed by having their home addresses read out using their synthesised voice and then posted online. According to a report by Vice, some of the audio clips may have been generated using ElevenLabs' Prime Voice AI (since renamed 'ElevenLabs Text-to-Speech') text-to-voice generator. However, this claim was rejected by ElevenLabs on the basis that every request using its system is tracked. A few weeks earlier, 4chan members were discovered to be using ElevenLabs' voice generator to make celebrity voices read highly offensive messages.  In a similar vein, GamesRadar reported in July 2023 that deepfake versions of video game voice actors including April Stewart and Ryan Laughton were being used to create non-consensual pornography for mods for games. Many video game companies and mod communities such as Nexus Mods have decided to allow AI-generated mod content.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Video game voice actors attacked using their own AI voices,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/video-game-voice-actors-attacked-using-their-own-ai-voices,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,ElevenLabs,ElevenLabs TTS; Prime Voice AI,Text-to-speech; Deep learning; Machine learning,Attack voice actors,User comments/complaints,Employment; Privacy; Safety,Governance; Marketing,Harassment,,,,,,,,10/7/2024 0:37,https://best-paper-award-ddck.dovetail.com/data/2CdZ2kjjZx5DEZ2wPi0aCY#:v:h=54OYGBhDP8N36c7U7BCG7Z
AIAAIC1147,"Voice actors working in the video gaming industry were attacked using AI-generated versions of their own voices, and doxxed by having their home addresses read out using their synthesised voice and then posted online. According to a report by Vice, some of the audio clips may have been generated using ElevenLabs' Prime Voice AI (since renamed 'ElevenLabs Text-to-Speech') text-to-voice generator. However, this claim was rejected by ElevenLabs on the basis that every request using its system is tracked. A few weeks earlier, 4chan members were discovered to be using ElevenLabs' voice generator to make celebrity voices read highly offensive messages.  In a similar vein, GamesRadar reported in July 2023 that deepfake versions of video game voice actors including April Stewart and Ryan Laughton were being used to create non-consensual pornography for mods for games. Many video game companies and mod communities such as Nexus Mods have decided to allow AI-generated mod content.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Video game voice actors attacked using their own AI voices,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/video-game-voice-actors-attacked-using-their-own-ai-voices,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,ElevenLabs,ElevenLabs TTS; Prime Voice AI,Text-to-speech; Deep learning; Machine learning,Attack voice actors,User comments/complaints,Employment; Privacy; Safety,Governance; Marketing,Harassment,,,,,,,,10/7/2024 0:37,https://best-paper-award-ddck.dovetail.com/data/2CdZ2kjjZx5DEZ2wPi0aCY#:v:h=54OYGBhDP8N36c7U7BCG7Z
AIAAIC1147,"Voice actors working in the video gaming industry were attacked using AI-generated versions of their own voices, and doxxed by having their home addresses read out using their synthesised voice and then posted online. According to a report by Vice, some of the audio clips may have been generated using ElevenLabs' Prime Voice AI (since renamed 'ElevenLabs Text-to-Speech') text-to-voice generator. However, this claim was rejected by ElevenLabs on the basis that every request using its system is tracked. A few weeks earlier, 4chan members were discovered to be using ElevenLabs' voice generator to make celebrity voices read highly offensive messages.  In a similar vein, GamesRadar reported in July 2023 that deepfake versions of video game voice actors including April Stewart and Ryan Laughton were being used to create non-consensual pornography for mods for games. Many video game companies and mod communities such as Nexus Mods have decided to allow AI-generated mod content.",Entity - AI developer company,Responsible Entities,Video game voice actors attacked using their own AI voices,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/video-game-voice-actors-attacked-using-their-own-ai-voices,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,ElevenLabs,ElevenLabs TTS; Prime Voice AI,Text-to-speech; Deep learning; Machine learning,Attack voice actors,User comments/complaints,Employment; Privacy; Safety,Governance; Marketing,Harassment,,,,,,,,10/7/2024 0:37,https://best-paper-award-ddck.dovetail.com/data/2CdZ2kjjZx5DEZ2wPi0aCY#:v:h=54OYGBhDP8N36c7U7BCG7Z
AIAAIC1186,"A South Korean man was jailed for using artificial intelligence to generate explicit images of children.  The unnamed man in his 40s was found to have developed approximately 360 AI-generated, highly explicit images of children, which, it is understood, were not distributed online. Law enforcement subsequently confiscated the images.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,South Korean arrested for using AI to create sexual images of children,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korean-arrested-for-using-ai-to-create-sexual-images-of-children,Incident,,2023,2023,South Korea,Media/entertainment/sports/arts,,,," Deepfake - audio, video; Machine learning",Self-gratification,Lawsuit filing/litigation,Safety; Legal,Governance; Marketing,Dignity loss,,,,,,Litigation,,10/24/2024 22:01,https://best-paper-award-ddck.dovetail.com/data/6hGr1kIgiLAVmgNUM0Jb0J#:v:h=55yz7HxiqR90HtbU0mb5uX
AIAAIC1186,"A South Korean man was jailed for using artificial intelligence to generate explicit images of children.  The unnamed man in his 40s was found to have developed approximately 360 AI-generated, highly explicit images of children, which, it is understood, were not distributed online. Law enforcement subsequently confiscated the images.",Entity - malicious human,Responsible Entities,South Korean arrested for using AI to create sexual images of children,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korean-arrested-for-using-ai-to-create-sexual-images-of-children,Incident,,2023,2023,South Korea,Media/entertainment/sports/arts,,,," Deepfake - audio, video; Machine learning",Self-gratification,Lawsuit filing/litigation,Safety; Legal,Governance; Marketing,Dignity loss,,,,,,Litigation,,10/24/2024 22:01,https://best-paper-award-ddck.dovetail.com/data/6hGr1kIgiLAVmgNUM0Jb0J#:v:h=55yz7HxiqR90HtbU0mb5uX
AIAAIC1186,"A South Korean man was jailed for using artificial intelligence to generate explicit images of children.  The unnamed man in his 40s was found to have developed approximately 360 AI-generated, highly explicit images of children, which, it is understood, were not distributed online. Law enforcement subsequently confiscated the images.",Cause - Human causes - Human abuse of AI tools,Cause,South Korean arrested for using AI to create sexual images of children,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korean-arrested-for-using-ai-to-create-sexual-images-of-children,Incident,,2023,2023,South Korea,Media/entertainment/sports/arts,,,," Deepfake - audio, video; Machine learning",Self-gratification,Lawsuit filing/litigation,Safety; Legal,Governance; Marketing,Dignity loss,,,,,,Litigation,,10/24/2024 22:01,https://best-paper-award-ddck.dovetail.com/data/6hGr1kIgiLAVmgNUM0Jb0J#:v:h=55yz7HxiqR90HtbU0mb5uX
AIAAIC1190,"Online AI model marketplace CivitAI has introduced a rewards system that encourages users to create deepfakes of real people.  CivitAI's 'bounties' feature encourages its community to develop deepfakes of real people by allowing users to ask the Civitai community to create AI models that generate images of specific styles, compositions, or specific real people. The person developing the 'best' AI model is rewarded with a virtual currency called 'Buzz'. In addition to celebrities, 404 Media discovered bounties for private people with no significant online presence",Entity - AI developer company,Responsible Entities,CivitAI rewards deepfakes of real people,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-rewards-deepfakes-of-real-people,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,,Ethics/values; Incentivisation; Privacy,,Privacy loss; Loss of integrity,,,,,,,,10/7/2024 0:20,https://best-paper-award-ddck.dovetail.com/data/6e6cFafwvfrKNGbb2KTqBX#:v:h=55P9YJOuM349b1Pc3HfpzX
AIAAIC1190,"Online AI model marketplace CivitAI has introduced a rewards system that encourages users to create deepfakes of real people.  CivitAI's 'bounties' feature encourages its community to develop deepfakes of real people by allowing users to ask the Civitai community to create AI models that generate images of specific styles, compositions, or specific real people. The person developing the 'best' AI model is rewarded with a virtual currency called 'Buzz'. In addition to celebrities, 404 Media discovered bounties for private people with no significant online presence",Incident - organization-driven - problematic AI implementation,Incident Type,CivitAI rewards deepfakes of real people,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-rewards-deepfakes-of-real-people,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,,Ethics/values; Incentivisation; Privacy,,Privacy loss; Loss of integrity,,,,,,,,10/7/2024 0:20,https://best-paper-award-ddck.dovetail.com/data/6e6cFafwvfrKNGbb2KTqBX#:v:h=55P9YJOuM349b1Pc3HfpzX
AIAAIC1190,"Online AI model marketplace CivitAI has introduced a rewards system that encourages users to create deepfakes of real people.  CivitAI's 'bounties' feature encourages its community to develop deepfakes of real people by allowing users to ask the Civitai community to create AI models that generate images of specific styles, compositions, or specific real people. The person developing the 'best' AI model is rewarded with a virtual currency called 'Buzz'. In addition to celebrities, 404 Media discovered bounties for private people with no significant online presence",Cause - organization causes - poor business ethics,Cause,CivitAI rewards deepfakes of real people,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-rewards-deepfakes-of-real-people,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,,Ethics/values; Incentivisation; Privacy,,Privacy loss; Loss of integrity,,,,,,,,10/7/2024 0:20,https://best-paper-award-ddck.dovetail.com/data/6e6cFafwvfrKNGbb2KTqBX#:v:h=55P9YJOuM349b1Pc3HfpzX
AIAAIC1740,"Unlike users in Europe, who can opt out of having their data used for AI training due to stringent privacy laws (GDPR), Australians currently have no such option. Meta's globalprivacy director, Melinda Claybaugh, claimed that the absence of an opt-out mechanism in Australia is due to differing legal frameworks. The inquiry revealed that unless users actively set their posts to private, all public content shared since 2007 is subject to scraping by Meta",Cause - governance causes - legal loophole,Cause,Meta admits farming Australians' Facebook photos to train AI,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-admits-farming-australians-facebook-photos-to-train-ai,Incident,,2024,2024,Australia,Multiple,,Meta,Meta AI,Machine learning,Train AI models,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:07,https://best-paper-award-ddck.dovetail.com/data/5krw28CG9ViCQTR5BQ5fEp#:v:h=57epqAKl5fwVy9NEvBGDWj
AIAAIC1406,"Worldcoin raised concerns among regulators and privacy advocates around the world due to an alleged lack of transparency regarding the methods the organisation is using to collect people’s data. In April 2022, internal documents shared with Technology Review and Buzzfeed News revealed that people signing up for Worldcoin iris scans were complaining about unclear, misleading, and unethical marketing practices.  Specifically, it was alleged that the organisation was collecting more personal data than it acknowledged, failing to obtain meaningful informed consent, and had not been declaring that it was using user data to train its artificial intelligence models.",Entity - large dataset organization,Responsible Entities,Worldcoin field-testing methods draw controversy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/worldcoin-field-testing-methods-draw-controversy,Incident,2023,2023,2023,Global,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,User comments/complaints,Privacy,Governance; Marketing,,Financial loss; Privacy loss,,,,,,,10/2/2024 16:59,https://best-paper-award-ddck.dovetail.com/data/2tdWT6cs0ArH6ftUhndO2z#:v:h=58I5lMQEflCceluxpmuMyn
AIAAIC1406,"Worldcoin raised concerns among regulators and privacy advocates around the world due to an alleged lack of transparency regarding the methods the organisation is using to collect people’s data. In April 2022, internal documents shared with Technology Review and Buzzfeed News revealed that people signing up for Worldcoin iris scans were complaining about unclear, misleading, and unethical marketing practices.  Specifically, it was alleged that the organisation was collecting more personal data than it acknowledged, failing to obtain meaningful informed consent, and had not been declaring that it was using user data to train its artificial intelligence models.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Worldcoin field-testing methods draw controversy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/worldcoin-field-testing-methods-draw-controversy,Incident,2023,2023,2023,Global,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,User comments/complaints,Privacy,Governance; Marketing,,Financial loss; Privacy loss,,,,,,,10/2/2024 16:59,https://best-paper-award-ddck.dovetail.com/data/2tdWT6cs0ArH6ftUhndO2z#:v:h=58I5lMQEflCceluxpmuMyn
AIAAIC1406,"Worldcoin raised concerns among regulators and privacy advocates around the world due to an alleged lack of transparency regarding the methods the organisation is using to collect people’s data. In April 2022, internal documents shared with Technology Review and Buzzfeed News revealed that people signing up for Worldcoin iris scans were complaining about unclear, misleading, and unethical marketing practices.  Specifically, it was alleged that the organisation was collecting more personal data than it acknowledged, failing to obtain meaningful informed consent, and had not been declaring that it was using user data to train its artificial intelligence models.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Worldcoin field-testing methods draw controversy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/worldcoin-field-testing-methods-draw-controversy,Incident,2023,2023,2023,Global,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,User comments/complaints,Privacy,Governance; Marketing,,Financial loss; Privacy loss,,,,,,,10/2/2024 16:59,https://best-paper-award-ddck.dovetail.com/data/2tdWT6cs0ArH6ftUhndO2z#:v:h=58I5lMQEflCceluxpmuMyn
AIAAIC1321,"Scammers tricked a Hong Kong-based employee of a multinational company into paying out HKD 200 million (USD 26 million) with a fake group video call created using deepfake technology. According to Hong Kong police, the worker received a strange message purportedly from his company’s UK-based chief financial officer asking for a secret transaction to be carried out.  Attending a subsequent video call, the employee was reassured by several colleagues whom he thought he recognised; however, it transpired that all the 'people' on the call were in fact deepfake recreations of colleagues that had been manipulated using public video footage.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake CFO scams finance worker for USD 25 million,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-cfo-scams-finance-worker-for-usd-25-million,Incident,,2024,2024,Hong Kong,Banking/financial services,Bank employee,,,"Deepfake - audio, video; Machine learning",Defraud,Police statement,Fraud,Governance,,Financial loss,,,,,,,10/24/2024 22:54,https://best-paper-award-ddck.dovetail.com/data/4L3EjqVgJ64uEJlk6H9pgO#:v:h=59bYgmC5UGI0aemvgIWMcn
AIAAIC1321,"Scammers tricked a Hong Kong-based employee of a multinational company into paying out HKD 200 million (USD 26 million) with a fake group video call created using deepfake technology. According to Hong Kong police, the worker received a strange message purportedly from his company’s UK-based chief financial officer asking for a secret transaction to be carried out.  Attending a subsequent video call, the employee was reassured by several colleagues whom he thought he recognised; however, it transpired that all the 'people' on the call were in fact deepfake recreations of colleagues that had been manipulated using public video footage.",Entity - malicious human,Responsible Entities,Deepfake CFO scams finance worker for USD 25 million,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-cfo-scams-finance-worker-for-usd-25-million,Incident,,2024,2024,Hong Kong,Banking/financial services,Bank employee,,,"Deepfake - audio, video; Machine learning",Defraud,Police statement,Fraud,Governance,,Financial loss,,,,,,,10/24/2024 22:54,https://best-paper-award-ddck.dovetail.com/data/4L3EjqVgJ64uEJlk6H9pgO#:v:h=59bYgmC5UGI0aemvgIWMcn
AIAAIC1321,"Scammers tricked a Hong Kong-based employee of a multinational company into paying out HKD 200 million (USD 26 million) with a fake group video call created using deepfake technology. According to Hong Kong police, the worker received a strange message purportedly from his company’s UK-based chief financial officer asking for a secret transaction to be carried out.  Attending a subsequent video call, the employee was reassured by several colleagues whom he thought he recognised; however, it transpired that all the 'people' on the call were in fact deepfake recreations of colleagues that had been manipulated using public video footage.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake CFO scams finance worker for USD 25 million,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-cfo-scams-finance-worker-for-usd-25-million,Incident,,2024,2024,Hong Kong,Banking/financial services,Bank employee,,,"Deepfake - audio, video; Machine learning",Defraud,Police statement,Fraud,Governance,,Financial loss,,,,,,,10/24/2024 22:54,https://best-paper-award-ddck.dovetail.com/data/4L3EjqVgJ64uEJlk6H9pgO#:v:h=59bYgmC5UGI0aemvgIWMcn
AIAAIC1367,"Deepfake images appearing to show US Presidential candidate Donald Trump with Black supporters prompted accusations of electoral manipulation. One image shared on Facebook by conservative radio show host Mark Kaye showed Trump with his arms around a group of Black women. In another, a user identified as 'Shaggy' placed Trump in front of a house with a group of young Black men.",Cause - Human causes - Human abuse of AI tools,Cause,Trump supporters target black voters with fake AI images,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/trump-supporters-target-black-voters-with-fake-ai-images,Incident,,2024,2024,USA,Politics,Mark Kaye,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,Media investigation,Ethics/values; Mis/disinformation,Marketing,Manipulation,,,,,,,,10/24/2024 22:57,https://best-paper-award-ddck.dovetail.com/data/7DVVd2q2dO1i2ahRJyxOfn#:v:h=59Dn47qgcjHfMNpXJU5MBR
AIAAIC1367,"Deepfake images appearing to show US Presidential candidate Donald Trump with Black supporters prompted accusations of electoral manipulation. One image shared on Facebook by conservative radio show host Mark Kaye showed Trump with his arms around a group of Black women. In another, a user identified as 'Shaggy' placed Trump in front of a house with a group of young Black men.",Incident - organization-driven - problematic AI implementation,Incident Type,Trump supporters target black voters with fake AI images,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/trump-supporters-target-black-voters-with-fake-ai-images,Incident,,2024,2024,USA,Politics,Mark Kaye,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,Media investigation,Ethics/values; Mis/disinformation,Marketing,Manipulation,,,,,,,,10/24/2024 22:57,https://best-paper-award-ddck.dovetail.com/data/7DVVd2q2dO1i2ahRJyxOfn#:v:h=59Dn47qgcjHfMNpXJU5MBR
AIAAIC1367,"Deepfake images appearing to show US Presidential candidate Donald Trump with Black supporters prompted accusations of electoral manipulation. One image shared on Facebook by conservative radio show host Mark Kaye showed Trump with his arms around a group of Black women. In another, a user identified as 'Shaggy' placed Trump in front of a house with a group of young Black men.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Trump supporters target black voters with fake AI images,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/trump-supporters-target-black-voters-with-fake-ai-images,Incident,,2024,2024,USA,Politics,Mark Kaye,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,Media investigation,Ethics/values; Mis/disinformation,Marketing,Manipulation,,,,,,,,10/24/2024 22:57,https://best-paper-award-ddck.dovetail.com/data/7DVVd2q2dO1i2ahRJyxOfn#:v:h=59Dn47qgcjHfMNpXJU5MBR
"AIAAIC1768
","which ChatGPT mishandled by downplaying risks associated with the child's living situation with parents charged with sexual offenses. The investigation found multiple signs of ChatGPT's involvement in the report, including inappropriate language and sentence structures inconsistent with child protection protocols. Notably, the report described a child's doll, allegedly used for inappropriate purposes by the father, as an ""age-appropriate toy,"" which raised alarms about the potential misrepresentation of risks to the child.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Inaccuracies reveal child protection worker used ChatGPT to draft court report,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/inaccuracies-reveal-child-protection-worker-used-chatgpt-to-draft-report,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 10:57,https://best-paper-award-ddck.dovetail.com/data/548I1sYhv6Ia6AIEDOi9qI#:v:h=59UsZUinkMRvfAJ0AZRZpU
AIAAIC1190,"alarming privacy advocates, mental health campaigners and others concerned about the potential use of CivitAI to create non-consensual AI-generated sexual images of real people.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,CivitAI rewards deepfakes of real people,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/civitai-rewards-deepfakes-of-real-people,Incident,2023,2023,2023,USA,Media/entertainment/sports/arts,,CivitAI,CivitAI,Text-to-image; Generative adversarial network (GAN); Neural network; Deep learning; Machine learning,Generate images,,Ethics/values; Incentivisation; Privacy,,Privacy loss; Loss of integrity,,,,,,,,10/7/2024 0:23,https://best-paper-award-ddck.dovetail.com/data/6e6cFafwvfrKNGbb2KTqBX#:v:h=5czaA1X7WA1IT0ClyzV1TF
AIAAIC1257,"The lawsuit argued that OpenAI integrated its systems with third-party platforms like Snapchat, Spotify, Stripe, Slack, and Microsoft Teams, enabling OpenAI to secretly gather users’ images, locations, music tastes, financial details, and private communications.",Entity - AI developer company,Responsible Entities,OpenAI 'unprecedented web scraping' trains AI models,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-unprecedented-web-scraping-trains-ai-models,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,,OpenAI,ChatGPT; DALL-E,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text; Generate images,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 21:23,https://best-paper-award-ddck.dovetail.com/data/7xeqrtiiKXcFbniKLZDcBj#:v:h=5e1BQG4fhQmM0ZEd7SGzEu
AIAAIC1257,"The lawsuit argued that OpenAI integrated its systems with third-party platforms like Snapchat, Spotify, Stripe, Slack, and Microsoft Teams, enabling OpenAI to secretly gather users’ images, locations, music tastes, financial details, and private communications.",Entity - AI developer company's affiliated parterns,Responsible Entities,OpenAI 'unprecedented web scraping' trains AI models,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-unprecedented-web-scraping-trains-ai-models,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,,OpenAI,ChatGPT; DALL-E,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text; Generate images,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 21:23,https://best-paper-award-ddck.dovetail.com/data/7xeqrtiiKXcFbniKLZDcBj#:v:h=5e1BQG4fhQmM0ZEd7SGzEu
AIAAIC1026,"Amazon was fined USD 31 million by the US Federal Trade Commission (FTC) for storing the voice and location data of childen using its Alexa personal assistant in order to help tune its voice recognition algorithm.  The ruling orders Amazon to overhaul its data deletion practices and impose stricter, more transparent privacy measures.  It also obliges the company to delete certain sensitive private data collected by Alexa and to stop it using deleted geolocation and voice information to create or improve its data products, and to create a privacy programme to govern its use of geolocation data. Amazon has been the target of a number of lawsuits alleging it has illegally recorded the voices of children using Alexa products without the consent of them or their parents.",Cause - organization causes - legal non-compliance,Cause,Amazon uses Alexa child data to tune voice algorithm,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-uses-alexa-child-data-to-tune-voice-algorithm,Incident,2014,2023,2023,USA,Consumer goods,,Amazon,Amazon Alexa; Amazon Ring,NLP/text analysis; Natural language understanding (NLU); Speech recognition,"Provide information, services",Regulatory inquiry/investigation,Privacy,Governance; Privacy,Privacy loss,,,,,USD 30m fine,Regulatory investigation,,10/11/2024 18:31,https://best-paper-award-ddck.dovetail.com/data/6NFCmLU0R470nECFdDGuSr#:v:h=5gupgE4XZHaClwQICtNfhy
AIAAIC1026,"Amazon was fined USD 31 million by the US Federal Trade Commission (FTC) for storing the voice and location data of childen using its Alexa personal assistant in order to help tune its voice recognition algorithm.  The ruling orders Amazon to overhaul its data deletion practices and impose stricter, more transparent privacy measures.  It also obliges the company to delete certain sensitive private data collected by Alexa and to stop it using deleted geolocation and voice information to create or improve its data products, and to create a privacy programme to govern its use of geolocation data. Amazon has been the target of a number of lawsuits alleging it has illegally recorded the voices of children using Alexa products without the consent of them or their parents.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Amazon uses Alexa child data to tune voice algorithm,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-uses-alexa-child-data-to-tune-voice-algorithm,Incident,2014,2023,2023,USA,Consumer goods,,Amazon,Amazon Alexa; Amazon Ring,NLP/text analysis; Natural language understanding (NLU); Speech recognition,"Provide information, services",Regulatory inquiry/investigation,Privacy,Governance; Privacy,Privacy loss,,,,,USD 30m fine,Regulatory investigation,,10/11/2024 18:31,https://best-paper-award-ddck.dovetail.com/data/6NFCmLU0R470nECFdDGuSr#:v:h=5gupgE4XZHaClwQICtNfhy
AIAAIC1026,"Amazon was fined USD 31 million by the US Federal Trade Commission (FTC) for storing the voice and location data of childen using its Alexa personal assistant in order to help tune its voice recognition algorithm.  The ruling orders Amazon to overhaul its data deletion practices and impose stricter, more transparent privacy measures.  It also obliges the company to delete certain sensitive private data collected by Alexa and to stop it using deleted geolocation and voice information to create or improve its data products, and to create a privacy programme to govern its use of geolocation data. Amazon has been the target of a number of lawsuits alleging it has illegally recorded the voices of children using Alexa products without the consent of them or their parents.",Entity - AI developer company,Responsible Entities,Amazon uses Alexa child data to tune voice algorithm,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-uses-alexa-child-data-to-tune-voice-algorithm,Incident,2014,2023,2023,USA,Consumer goods,,Amazon,Amazon Alexa; Amazon Ring,NLP/text analysis; Natural language understanding (NLU); Speech recognition,"Provide information, services",Regulatory inquiry/investigation,Privacy,Governance; Privacy,Privacy loss,,,,,USD 30m fine,Regulatory investigation,,10/11/2024 18:31,https://best-paper-award-ddck.dovetail.com/data/6NFCmLU0R470nECFdDGuSr#:v:h=5gupgE4XZHaClwQICtNfhy
AIAAIC0948,"The German Federal Constitutional Court ruled the use of Palantir surveillance software by police in Hesse and Hamburg as unconstitutional, in a case bought by German civil rights NGO Gesellschaft für Freiheitsrechte (GFF). The GFF had argued (in German) that Hesse and Hamburg had not made clear which sources the police could use for obtaining data or how much and on what grounds data mining could be conducted by law enforcement.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Hesse state Palantir predictive policing ruled 'unconstitutional',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/hesse-palantir-predictive-policing,Incident,,2023,2023,Germany,Govt - police,Hesse State Police,Palantir,Hessendata; Gotham,Prediction algorithm,Predict crime,Lawsuit filing/litigation,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance; Black box,,Unconstitutional,,,Product ban,,Litigation,,10/13/2024 22:33,https://best-paper-award-ddck.dovetail.com/data/7u0NT2v9zlyvmGEXg8vJKl#:v:h=5hzUc3yMwWRA4SIhrHPHEv
AIAAIC1405,"ISIS Khorasan officially claimed responsibility for the attack; the deepfake appeared part of a larger effort to defect blame on Ukraine, with which Russia is at war. Putin later appeared to accuse Ukraine of orchestrating the attack in a TV statement.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Russian state TV deepfake blames Ukraine for Crocus City Hall attack,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/russian-state-tv-deepfake-blames-ukraine-for-crocus-city-hall-attack,Incident,,2024,2024,Russia; Ukraine,Govt - defence,NTV,,,"Deepfake - video, audio; Machine learning",Deflect blame,,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 23:13,https://best-paper-award-ddck.dovetail.com/data/4PW3gWDksIUlUtA5mjzSY2#:v:h=5hDYJu1Ne3zTxWgSj96EJl
AIAAIC1728,over 30 billion images scraped from the internet without userconsent.,Cause - organization/human cause - lack of informed consent & transparency,Cause,Dutch regulator fines Clearview AI for privacy violations,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dutch-regulator-fines-clearview-ai,Incident,,2024,2024,Netherlands,Multiple,Clearview AI,Clearview AI,Clearview AI,Facial recognition; Machine learning,Identify individuals,Regulatory action,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 19:38,https://best-paper-award-ddck.dovetail.com/data/1C4UyEheRNvTZLRRZsqSJP#:v:h=5itohUN1uym2eupuMXVCdh
AIAAIC1569,"Personal images of Australian children have been used to train major AI models, violating their privacy and potentially resulting in the use of their images to create pornographic deepfakes. According to Human Rights Watch, the photos of 190 Australian children were scraped from personal blogs, video and photo-sharing sites, school websites, photographers’ collections of family portraits and other services without the consent of the children or their parents to create the LAION-5B dataset. The photos were then used to create popular generative AI tools such as Stable Diffusion and Midjourney and, HRW argues, were later used to create synthetic images that could be categorised as child pornography.  HRW said it found children whose images were in the dataset were easily identifiable, with some names included in the accompanying caption or the URL where the image was stored.  The finding raised ethical concerns about data privacy and the need for consent when AI training datasets. ➖ December 2023. Stanford Internet Observatory researchers discovered thousands of child sex abuse pictures on LAION-5B and LAION-400M. ",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Images of Australian children are used to train AI,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/images-of-australian-children-are-used-to-train-ai,Incident,,2024,2024,Australia,Multiple,,LAION,LAION-5B,Database/dataset,Pair text and images,Research study/report,Privacy; Safety,Governance,Privacy loss,,,,,,,,9/26/2024 23:57,https://best-paper-award-ddck.dovetail.com/data/6Yggtxspsf8NVlCpST5mXs#:v:h=5lky7ubrbQ3aMxOHEece3C
AIAAIC1569,"Personal images of Australian children have been used to train major AI models, violating their privacy and potentially resulting in the use of their images to create pornographic deepfakes. According to Human Rights Watch, the photos of 190 Australian children were scraped from personal blogs, video and photo-sharing sites, school websites, photographers’ collections of family portraits and other services without the consent of the children or their parents to create the LAION-5B dataset. The photos were then used to create popular generative AI tools such as Stable Diffusion and Midjourney and, HRW argues, were later used to create synthetic images that could be categorised as child pornography.  HRW said it found children whose images were in the dataset were easily identifiable, with some names included in the accompanying caption or the URL where the image was stored.  The finding raised ethical concerns about data privacy and the need for consent when AI training datasets. ➖ December 2023. Stanford Internet Observatory researchers discovered thousands of child sex abuse pictures on LAION-5B and LAION-400M. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Images of Australian children are used to train AI,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/images-of-australian-children-are-used-to-train-ai,Incident,,2024,2024,Australia,Multiple,,LAION,LAION-5B,Database/dataset,Pair text and images,Research study/report,Privacy; Safety,Governance,Privacy loss,,,,,,,,9/26/2024 23:57,https://best-paper-award-ddck.dovetail.com/data/6Yggtxspsf8NVlCpST5mXs#:v:h=5lky7ubrbQ3aMxOHEece3C
AIAAIC1569,"Personal images of Australian children have been used to train major AI models, violating their privacy and potentially resulting in the use of their images to create pornographic deepfakes. According to Human Rights Watch, the photos of 190 Australian children were scraped from personal blogs, video and photo-sharing sites, school websites, photographers’ collections of family portraits and other services without the consent of the children or their parents to create the LAION-5B dataset. The photos were then used to create popular generative AI tools such as Stable Diffusion and Midjourney and, HRW argues, were later used to create synthetic images that could be categorised as child pornography.  HRW said it found children whose images were in the dataset were easily identifiable, with some names included in the accompanying caption or the URL where the image was stored.  The finding raised ethical concerns about data privacy and the need for consent when AI training datasets. ➖ December 2023. Stanford Internet Observatory researchers discovered thousands of child sex abuse pictures on LAION-5B and LAION-400M. ",Entity - AI developer company,Responsible Entities,Images of Australian children are used to train AI,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/images-of-australian-children-are-used-to-train-ai,Incident,,2024,2024,Australia,Multiple,,LAION,LAION-5B,Database/dataset,Pair text and images,Research study/report,Privacy; Safety,Governance,Privacy loss,,,,,,,,9/26/2024 23:57,https://best-paper-award-ddck.dovetail.com/data/6Yggtxspsf8NVlCpST5mXs#:v:h=5lky7ubrbQ3aMxOHEece3C
AIAAIC1739,"Published by the ""Temple Mount Activists"", the video shows the Dome of the Rock and its surroundings engulfed in flames, with a caption reading ""absolute victory"" and ""Coming soon in these days"".",Entity - malicious human,Responsible Entities,Deepfake AI video shows Al-Aqsa mosque burning,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-ai-video-shows-al-aqsa-burning,Issue,,2024,2024,Israel; Palestine,Politics,Temple Mount Activists,Temple Mount Activists,,Deepfake - video,Intimidate/threaten Palestinians,User comments/complaints,Mis/disinformation,Governance,,,,,,,,,10/13/2024 22:54,https://best-paper-award-ddck.dovetail.com/data/2jn7HNByGbmvslm31JqDHk#:v:h=5mfjYohj7OnALchY3S7JmD
AIAAIC1178,"AI chatbot Replika was banned from processing user data in Italy due to the risks it could pose to minors and emotionally vulnerable people. In February 2023, Italy's privacy regulator ordered Replika to stop processing Italians' data on the basis that it lacked a proper legal basis for processing children’s data under the EU’s GDPR, and that it posed risks to minors. ",Cause - organization causes - legal non-compliance,Cause,Replika hit with data ban in Italy over child safety,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/replika-hit-with-data-ban-in-italy-over-child-safety,Incident,2017,2023,2023,Italy,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Regulatory ban,Safety; Privacy,Governance,Privacy loss,,,,,,Regulatory ban,,10/7/2024 0:27,https://best-paper-award-ddck.dovetail.com/data/6YwwYgh9liy2qG7Fp8E16x#:v:h=5nIYNtrzl5SIyhCdkwkT3k
AIAAIC1178,"AI chatbot Replika was banned from processing user data in Italy due to the risks it could pose to minors and emotionally vulnerable people. In February 2023, Italy's privacy regulator ordered Replika to stop processing Italians' data on the basis that it lacked a proper legal basis for processing children’s data under the EU’s GDPR, and that it posed risks to minors. ",Incident - organization-driven - problematic AI implementation,Incident Type,Replika hit with data ban in Italy over child safety,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/replika-hit-with-data-ban-in-italy-over-child-safety,Incident,2017,2023,2023,Italy,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Regulatory ban,Safety; Privacy,Governance,Privacy loss,,,,,,Regulatory ban,,10/7/2024 0:27,https://best-paper-award-ddck.dovetail.com/data/6YwwYgh9liy2qG7Fp8E16x#:v:h=5nIYNtrzl5SIyhCdkwkT3k
AIAAIC1074,"n response, the company updated its terms to say 'Notwithstanding the above, Zoom will not use audio, video or chat Customer Content to train our artificial intelligence models without your consent.'  However, privacy experts said the new update contradicted the earlier statement, and suggested the company could continue to collect and use customer data.",Cause - organziation causes - vague policy information,Cause,Zoom uses customer data to train AI models,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/zoom-customer-data-ai-model-training,Issue,,2023,2023,USA,Business/professional services,Zoom Video Communications,Zoom Video Communications,Zoom IQ,NLP/text analysis; Neural network; Deep learning; Machine learning,Summarise meetings,Company statement,Confidentiality; Privacy; Ethics/values,Governance; Legal; Marketing,,,,Loss of trust,Policy update,,,,10/7/2024 1:11,https://best-paper-award-ddck.dovetail.com/data/7LVeq546ZjC7gewId5V1fX#:v:h=5nN1tDlfd2rIDjUqwt3nUU
AIAAIC1074,"n response, the company updated its terms to say 'Notwithstanding the above, Zoom will not use audio, video or chat Customer Content to train our artificial intelligence models without your consent.'  However, privacy experts said the new update contradicted the earlier statement, and suggested the company could continue to collect and use customer data.",Incident - organization-driven - unclear info on user agreements and policy statements,Incident Type,Zoom uses customer data to train AI models,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/zoom-customer-data-ai-model-training,Issue,,2023,2023,USA,Business/professional services,Zoom Video Communications,Zoom Video Communications,Zoom IQ,NLP/text analysis; Neural network; Deep learning; Machine learning,Summarise meetings,Company statement,Confidentiality; Privacy; Ethics/values,Governance; Legal; Marketing,,,,Loss of trust,Policy update,,,,10/7/2024 1:11,https://best-paper-award-ddck.dovetail.com/data/7LVeq546ZjC7gewId5V1fX#:v:h=5nN1tDlfd2rIDjUqwt3nUU
AIAAIC1616,"However, Musk's post to X, which he owns and included the caption ""This is amazing,"" failed to clarify that it was satire, leading to widespread confusion among viewers. Musk's post contravened X's own policies.",Incident - human-driven - Public entity amplified of misleading content,Incident Type,Elon Musk shares Kamala Harris voice close video ad,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/elon-musk-shares-kamala-harris-voice-clone-video-ad,Issue,,2024,2024,USA,Politics,,,,Deepfake - video; Machine learning,Satirise/parody,,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:14,https://best-paper-award-ddck.dovetail.com/data/7DBPDK65ZBX1OiFoY6lnPh#:v:h=5nYLEUkCKIuQpGYNqjlpMg
AIAAIC1723,"Top ""AI companion apps"" systemically collect vast amounts of user data without consent and then share it for targeted advertising",Entity - AI developer company,Responsible Entities,"Report: AI companion apps ""relentlessly"" pry user data",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-ai-companion-apps-relentlessly-pry-user-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,Luka Inc,Anima; Chai; Crushon.AI; EVA AI; Genesia AI; iGirl; Mimico; Replika; Romantic AI; Talkie Soulful AI,Chatbot; Machine learning,Provide companionship,Research study/report,Privacy; Safety; Security,Governance; Privacy,Privacy loss,,,,,,,,9/26/2024 19:48,https://best-paper-award-ddck.dovetail.com/data/5RV9Y6z2RH28SONVePRBet#:v:h=5o2Q9hOS2JmdK3TLVUeEoq
AIAAIC1723,"Top ""AI companion apps"" systemically collect vast amounts of user data without consent and then share it for targeted advertising",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,"Report: AI companion apps ""relentlessly"" pry user data",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-ai-companion-apps-relentlessly-pry-user-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,Luka Inc,Anima; Chai; Crushon.AI; EVA AI; Genesia AI; iGirl; Mimico; Replika; Romantic AI; Talkie Soulful AI,Chatbot; Machine learning,Provide companionship,Research study/report,Privacy; Safety; Security,Governance; Privacy,Privacy loss,,,,,,,,9/26/2024 19:48,https://best-paper-award-ddck.dovetail.com/data/5RV9Y6z2RH28SONVePRBet#:v:h=5o2Q9hOS2JmdK3TLVUeEoq
AIAAIC1723,"Top ""AI companion apps"" systemically collect vast amounts of user data without consent and then share it for targeted advertising",Incident - organization-drive - unauthorized data use for targeted adversiting,Incident Type,"Report: AI companion apps ""relentlessly"" pry user data",9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/report-ai-companion-apps-relentlessly-pry-user-data,Issue,,2024,2024,Global,Media/entertainment/sports/arts,,Luka Inc,Anima; Chai; Crushon.AI; EVA AI; Genesia AI; iGirl; Mimico; Replika; Romantic AI; Talkie Soulful AI,Chatbot; Machine learning,Provide companionship,Research study/report,Privacy; Safety; Security,Governance; Privacy,Privacy loss,,,,,,,,9/26/2024 19:48,https://best-paper-award-ddck.dovetail.com/data/5RV9Y6z2RH28SONVePRBet#:v:h=5o2Q9hOS2JmdK3TLVUeEoq
AIAAIC1335,"British voice actor Greg Marston discovered that AI-generated clones of his voice were being used by third-parties without his permission.  Having discovered an 'eerily' similar voice to his own associated with a character named 'Connor' on the Wimbledon website, Marston realised that licensed voice recordings he had recorded for IBM in 2003 and to whom he had granted permission for its use, had been sold to third-party websites that were now using it to create synthetic voices able to say anything, anywhere, at any time",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,IBM sells Greg Marston voice for commercial cloning,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ibm-sells-greg-marston-voice-for-commercial-cloning,Incident,2021,2023,2023,UK,Media/entertainment/sports/arts,All England Lawn Tennis and Croquet Club,Revoicer,Revoicer,Text-to-speech; Emotion recognition; Deepfake - audio; Machine learning,Clone voice actor's voice,User comments/complaints,Employment; Ethics/values,Governance,Financial loss,,,,,,,,10/24/2024 22:56,https://best-paper-award-ddck.dovetail.com/data/5Je0NDIYnNTli89KS6ROPB#:v:h=5piQqka7WoeEgubgFg8Jd2
AIAAIC1335,"British voice actor Greg Marston discovered that AI-generated clones of his voice were being used by third-parties without his permission.  Having discovered an 'eerily' similar voice to his own associated with a character named 'Connor' on the Wimbledon website, Marston realised that licensed voice recordings he had recorded for IBM in 2003 and to whom he had granted permission for its use, had been sold to third-party websites that were now using it to create synthetic voices able to say anything, anywhere, at any time","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,IBM sells Greg Marston voice for commercial cloning,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ibm-sells-greg-marston-voice-for-commercial-cloning,Incident,2021,2023,2023,UK,Media/entertainment/sports/arts,All England Lawn Tennis and Croquet Club,Revoicer,Revoicer,Text-to-speech; Emotion recognition; Deepfake - audio; Machine learning,Clone voice actor's voice,User comments/complaints,Employment; Ethics/values,Governance,Financial loss,,,,,,,,10/24/2024 22:56,https://best-paper-award-ddck.dovetail.com/data/5Je0NDIYnNTli89KS6ROPB#:v:h=5piQqka7WoeEgubgFg8Jd2
AIAAIC1335,"British voice actor Greg Marston discovered that AI-generated clones of his voice were being used by third-parties without his permission.  Having discovered an 'eerily' similar voice to his own associated with a character named 'Connor' on the Wimbledon website, Marston realised that licensed voice recordings he had recorded for IBM in 2003 and to whom he had granted permission for its use, had been sold to third-party websites that were now using it to create synthetic voices able to say anything, anywhere, at any time",Cause - organization/human cause - lack of informed consent & transparency,Cause,IBM sells Greg Marston voice for commercial cloning,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ibm-sells-greg-marston-voice-for-commercial-cloning,Incident,2021,2023,2023,UK,Media/entertainment/sports/arts,All England Lawn Tennis and Croquet Club,Revoicer,Revoicer,Text-to-speech; Emotion recognition; Deepfake - audio; Machine learning,Clone voice actor's voice,User comments/complaints,Employment; Ethics/values,Governance,Financial loss,,,,,,,,10/24/2024 22:56,https://best-paper-award-ddck.dovetail.com/data/5Je0NDIYnNTli89KS6ROPB#:v:h=5piQqka7WoeEgubgFg8Jd2
AIAAIC1173,"Students at Carmel High School, USA, concocted deepfake videos of a nearby school principal and law enforcement officer shouting racist slurs and threatening to kill Black students. In one video, John Piscitella, the principal of nearby George Fisher Middle School, rants 'I f*cking hate Black kids. Like these stupid f*cking n***er monkey parents need to stop sending them here. Get them the f**k out, all of them.'","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Carmel school students attack Principal with racist deepfake video,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/carmel-school-students-attack-principal-with-racist-deepfake-video,Incident,,2023,2023,USA,Education,,,,"Deepfake - audio, video; Machine learning",Damage reputation,School statement,Legal; Mis/disinformation; Safety,Marketing,,,,,,,,,10/24/2024 21:36,https://best-paper-award-ddck.dovetail.com/data/5GUvQkfEmyMiWNoYmGqvBo#:v:h=5qlNidvC0oTfkRHXF2kfZl
AIAAIC1164,"Developed using Chinese American AI video creation company HeyGen, the video shows Swift flaunting her Mandarin in what looks like a talk show. But the clip appeared largely designed to promote itself than say anything about Taylor Swift, who does not speak Mandarin.",Entity - AI developer company,Responsible Entities,Taylor Swift speaks in Mandarin deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/taylor-swift-speaks-in-mandarin-deepfake,Incident,,2023,2023,China; USA,Media/entertainment/sports/arts,,HeyGen,Video Translate,"Deepfake - audio, video; Machine learning",Promote developer,User comments/complaints,Mis/disinformation; Privacy,,Manipulation,,,,,,,,10/28/2024 16:33,https://best-paper-award-ddck.dovetail.com/data/7oLXMZ0AGOivl1qXp4MMxA#:v:h=5r7PDGoB0I5BV3WojyxWDp
AIAAIC1164,"Developed using Chinese American AI video creation company HeyGen, the video shows Swift flaunting her Mandarin in what looks like a talk show. But the clip appeared largely designed to promote itself than say anything about Taylor Swift, who does not speak Mandarin.",Cause - organization causes - poor business ethics,Cause,Taylor Swift speaks in Mandarin deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/taylor-swift-speaks-in-mandarin-deepfake,Incident,,2023,2023,China; USA,Media/entertainment/sports/arts,,HeyGen,Video Translate,"Deepfake - audio, video; Machine learning",Promote developer,User comments/complaints,Mis/disinformation; Privacy,,Manipulation,,,,,,,,10/28/2024 16:33,https://best-paper-award-ddck.dovetail.com/data/7oLXMZ0AGOivl1qXp4MMxA#:v:h=5r7PDGoB0I5BV3WojyxWDp
AIAAIC1486,"An audio/video clip of Philippines President Ferdinand Marcos Jr apparently ordering a military attack against China caused alarm and resulted in the Philippines government cracking down on deepfakes. The deepfake clip, which was taken down, appeared to order the “armed forces and special task groups” to act however they deem appropriate should China “attack” the Philippines. Photographs of Chinese activities in the West Philippine Sea – including publicly released images from the Philippine Coast Guard – flashed in the video as a slideshow as the audio played.",Entity - no specific info,Responsible Entities,Deepfake Philippines President urges military action against China,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-philippines-president-urges-military-action-against-china,Incident,,2024,2024,Philippines,Politics; Govt - defence,,,,Deepfake - audio; Machine learning,Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/11/2024 20:43,https://best-paper-award-ddck.dovetail.com/data/6SoHDlejrxzh6OpFG4PxhL#:v:h=5uCLLeVdxRdL6qAaiINhOZ
AIAAIC1486,"An audio/video clip of Philippines President Ferdinand Marcos Jr apparently ordering a military attack against China caused alarm and resulted in the Philippines government cracking down on deepfakes. The deepfake clip, which was taken down, appeared to order the “armed forces and special task groups” to act however they deem appropriate should China “attack” the Philippines. Photographs of Chinese activities in the West Philippine Sea – including publicly released images from the Philippine Coast Guard – flashed in the video as a slideshow as the audio played.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake Philippines President urges military action against China,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-philippines-president-urges-military-action-against-china,Incident,,2024,2024,Philippines,Politics; Govt - defence,,,,Deepfake - audio; Machine learning,Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/11/2024 20:43,https://best-paper-award-ddck.dovetail.com/data/6SoHDlejrxzh6OpFG4PxhL#:v:h=5uCLLeVdxRdL6qAaiINhOZ
AIAAIC1486,"An audio/video clip of Philippines President Ferdinand Marcos Jr apparently ordering a military attack against China caused alarm and resulted in the Philippines government cracking down on deepfakes. The deepfake clip, which was taken down, appeared to order the “armed forces and special task groups” to act however they deem appropriate should China “attack” the Philippines. Photographs of Chinese activities in the West Philippine Sea – including publicly released images from the Philippine Coast Guard – flashed in the video as a slideshow as the audio played.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake Philippines President urges military action against China,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-philippines-president-urges-military-action-against-china,Incident,,2024,2024,Philippines,Politics; Govt - defence,,,,Deepfake - audio; Machine learning,Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/11/2024 20:43,https://best-paper-award-ddck.dovetail.com/data/6SoHDlejrxzh6OpFG4PxhL#:v:h=5uCLLeVdxRdL6qAaiINhOZ
AIAAIC1486,"An audio/video clip of Philippines President Ferdinand Marcos Jr apparently ordering a military attack against China caused alarm and resulted in the Philippines government cracking down on deepfakes. The deepfake clip, which was taken down, appeared to order the “armed forces and special task groups” to act however they deem appropriate should China “attack” the Philippines. Photographs of Chinese activities in the West Philippine Sea – including publicly released images from the Philippine Coast Guard – flashed in the video as a slideshow as the audio played.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Deepfake Philippines President urges military action against China,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-philippines-president-urges-military-action-against-china,Incident,,2024,2024,Philippines,Politics; Govt - defence,,,,Deepfake - audio; Machine learning,Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/11/2024 20:43,https://best-paper-award-ddck.dovetail.com/data/6SoHDlejrxzh6OpFG4PxhL#:v:h=5uCLLeVdxRdL6qAaiINhOZ
AIAAIC1239,"Amazon hit back by disputing claims that Q had released confidential data, and said it continued to fine-tune the system 'as it transitions from being a product in preview to being generally available.'",Cause - organization causes - poor business ethics,Cause,"Amazon Q hallucinates, leaks data",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-q-hallucinates-leaks-data,Issue,2023,2023,2023,USA,Business/professional services,Casey Newton; Zoe Schiffler,Amazon,Amazon Q,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Media investigation,Accuracy/reliability; Confidentiality; Privacy,Governance,,Confidentiality loss,,,,,,,10/11/2024 13:25,https://best-paper-award-ddck.dovetail.com/data/6qdPVS8qLWNLyJwXajPT1d#:v:h=5wdn8wUAkSqafjIbpeDRGD
AIAAIC1671,"OpenAI's new GPT-4o model imitates users' voices without their permission, sparking concerns about privacy, security and its potential for misuse. During testing, the model's ""Advanced Voice Mode"" feature occasionally and unintentionally imitated users' voices without their permission, according to OpenAI's release of the""system card"" for the GPT-4o model, which details the model's limitations and safety testing procedures.The card details a recording showing an interaction where the AI suddenly spoke in a voice similar to the user's after saying ""No!""",Entity - AI algorithm,Responsible Entities,ChatGPT imitates users' voices without permission,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-imitates-users-voices-without-permission,Issue,2024,2024,2024,Global,Multiple,OpenAI,OpenAI,ChatGPT; GPT-4o Advanced Voice Mode,Chatbot; Machine learning,Create voices,Company statement,Dual/multi-use; Privacy; Security,Governance,,,,,,,,,9/26/2024 23:13,https://best-paper-award-ddck.dovetail.com/data/lFHrqj1tcwdDQQgJpkJLc#:v:h=5yHlZd7sjhltOyhVRwb3jZ
AIAAIC1671,"OpenAI's new GPT-4o model imitates users' voices without their permission, sparking concerns about privacy, security and its potential for misuse. During testing, the model's ""Advanced Voice Mode"" feature occasionally and unintentionally imitated users' voices without their permission, according to OpenAI's release of the""system card"" for the GPT-4o model, which details the model's limitations and safety testing procedures.The card details a recording showing an interaction where the AI suddenly spoke in a voice similar to the user's after saying ""No!""",Cause - organization/human cause - lack of informed consent & transparency,Cause,ChatGPT imitates users' voices without permission,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-imitates-users-voices-without-permission,Issue,2024,2024,2024,Global,Multiple,OpenAI,OpenAI,ChatGPT; GPT-4o Advanced Voice Mode,Chatbot; Machine learning,Create voices,Company statement,Dual/multi-use; Privacy; Security,Governance,,,,,,,,,9/26/2024 23:13,https://best-paper-award-ddck.dovetail.com/data/lFHrqj1tcwdDQQgJpkJLc#:v:h=5yHlZd7sjhltOyhVRwb3jZ
AIAAIC1671,"OpenAI's new GPT-4o model imitates users' voices without their permission, sparking concerns about privacy, security and its potential for misuse. During testing, the model's ""Advanced Voice Mode"" feature occasionally and unintentionally imitated users' voices without their permission, according to OpenAI's release of the""system card"" for the GPT-4o model, which details the model's limitations and safety testing procedures.The card details a recording showing an interaction where the AI suddenly spoke in a voice similar to the user's after saying ""No!""",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,ChatGPT imitates users' voices without permission,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-imitates-users-voices-without-permission,Issue,2024,2024,2024,Global,Multiple,OpenAI,OpenAI,ChatGPT; GPT-4o Advanced Voice Mode,Chatbot; Machine learning,Create voices,Company statement,Dual/multi-use; Privacy; Security,Governance,,,,,,,,,9/26/2024 23:13,https://best-paper-award-ddck.dovetail.com/data/lFHrqj1tcwdDQQgJpkJLc#:v:h=5yHlZd7sjhltOyhVRwb3jZ
AIAAIC1671,"OpenAI's new GPT-4o model imitates users' voices without their permission, sparking concerns about privacy, security and its potential for misuse. During testing, the model's ""Advanced Voice Mode"" feature occasionally and unintentionally imitated users' voices without their permission, according to OpenAI's release of the""system card"" for the GPT-4o model, which details the model's limitations and safety testing procedures.The card details a recording showing an interaction where the AI suddenly spoke in a voice similar to the user's after saying ""No!""",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,ChatGPT imitates users' voices without permission,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-imitates-users-voices-without-permission,Issue,2024,2024,2024,Global,Multiple,OpenAI,OpenAI,ChatGPT; GPT-4o Advanced Voice Mode,Chatbot; Machine learning,Create voices,Company statement,Dual/multi-use; Privacy; Security,Governance,,,,,,,,,9/26/2024 23:13,https://best-paper-award-ddck.dovetail.com/data/lFHrqj1tcwdDQQgJpkJLc#:v:h=5yHlZd7sjhltOyhVRwb3jZ
AIAAIC1377,"Five students at Beverly Vista Middle School, Los Angeles, created and shared AI-generated images of fellow students, resulting in a police investigation and their expulsion. School principal Dr. Kelly Skon said in a statement to parents that staff had been alerted about the photos in which the faces of students were added to nude bodies using AI technology. The five 'egregiously involved eighth-grade students' were later expelled.",Cause - Human causes - Human abuse of AI tools,Cause,Beverly Hills students created and shared AI nude images of fellow students ,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/beverly-hills-students-created-shared-ai-nude-images-of-fellow-students,Incident,,2024,2024,USA,Education,Beverly Vista Middle School students,,,Deepfake - image; Machine learning,Nudify women,School statement,Ethics/values; Privacy; Safety,Governance; Marketing,Anxiety/distress/depression; Privacy loss,,,,,,Police investigation,,10/24/2024 23:04,https://best-paper-award-ddck.dovetail.com/data/5DoLNUi9YNXVhFJuEmjANl#:v:h=5ArdiL9xW0lfqpauSha3bk
AIAAIC1377,"Five students at Beverly Vista Middle School, Los Angeles, created and shared AI-generated images of fellow students, resulting in a police investigation and their expulsion. School principal Dr. Kelly Skon said in a statement to parents that staff had been alerted about the photos in which the faces of students were added to nude bodies using AI technology. The five 'egregiously involved eighth-grade students' were later expelled.",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,Beverly Hills students created and shared AI nude images of fellow students ,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/beverly-hills-students-created-shared-ai-nude-images-of-fellow-students,Incident,,2024,2024,USA,Education,Beverly Vista Middle School students,,,Deepfake - image; Machine learning,Nudify women,School statement,Ethics/values; Privacy; Safety,Governance; Marketing,Anxiety/distress/depression; Privacy loss,,,,,,Police investigation,,10/24/2024 23:04,https://best-paper-award-ddck.dovetail.com/data/5DoLNUi9YNXVhFJuEmjANl#:v:h=5ArdiL9xW0lfqpauSha3bk
AIAAIC1377,"Five students at Beverly Vista Middle School, Los Angeles, created and shared AI-generated images of fellow students, resulting in a police investigation and their expulsion. School principal Dr. Kelly Skon said in a statement to parents that staff had been alerted about the photos in which the faces of students were added to nude bodies using AI technology. The five 'egregiously involved eighth-grade students' were later expelled.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Beverly Hills students created and shared AI nude images of fellow students ,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/beverly-hills-students-created-shared-ai-nude-images-of-fellow-students,Incident,,2024,2024,USA,Education,Beverly Vista Middle School students,,,Deepfake - image; Machine learning,Nudify women,School statement,Ethics/values; Privacy; Safety,Governance; Marketing,Anxiety/distress/depression; Privacy loss,,,,,,Police investigation,,10/24/2024 23:04,https://best-paper-award-ddck.dovetail.com/data/5DoLNUi9YNXVhFJuEmjANl#:v:h=5ArdiL9xW0lfqpauSha3bk
AIAAIC1377,"Five students at Beverly Vista Middle School, Los Angeles, created and shared AI-generated images of fellow students, resulting in a police investigation and their expulsion. School principal Dr. Kelly Skon said in a statement to parents that staff had been alerted about the photos in which the faces of students were added to nude bodies using AI technology. The five 'egregiously involved eighth-grade students' were later expelled.",Entity - malicious human,Responsible Entities,Beverly Hills students created and shared AI nude images of fellow students ,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/beverly-hills-students-created-shared-ai-nude-images-of-fellow-students,Incident,,2024,2024,USA,Education,Beverly Vista Middle School students,,,Deepfake - image; Machine learning,Nudify women,School statement,Ethics/values; Privacy; Safety,Governance; Marketing,Anxiety/distress/depression; Privacy loss,,,,,,Police investigation,,10/24/2024 23:04,https://best-paper-award-ddck.dovetail.com/data/5DoLNUi9YNXVhFJuEmjANl#:v:h=5ArdiL9xW0lfqpauSha3bk
AIAAIC1159,"A video of Palestinian model Bella Hadid declaring support for Israel has been exposed as a deepfake, sparking ethical concerns about consent, privacy, and political disinformation.  The video, which was posted on X (formerly Twitter) by CEO of Israeli NGO Shrink the Conflict Danel Ben Namer, shows Hadid appearing to apologise for past remarks and saying she stands with Israel following the October 7, 2023, attack by Hamas militants. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Bella Hadid 'stands with Israel' deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bella-hadid-stands-with-israel-deepfake,Incident,2022,2023,2023,Israel; Palestine,Media/entertainment/sports/arts; Politics,,,,"Deepfake - audio, video; Machine learning",Manipulate public opinion,Media/NGO fact-check,Mis/disinformation; Privacy,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:05,https://best-paper-award-ddck.dovetail.com/data/3PLQ4SGCwfoyYPR0R2DlHH#:v:h=5FFEz3JAcvIhNU3AoRrD3T
AIAAIC1209,"The OPC later said that several states were joining the investigation, and that it would investigate whether OpenAI obtained the necessary consent for data use, whether it was adequately transparent about that use, and whether its use of any personal data was limited to purposes that were reasonable and appropriate.",Entity - AI developer company,Responsible Entities,Canada investigates ChatGPT privacy concerns,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/canada-investigates-chatgpt-privacy-concerns,Incident,2022,2023,2023,Canada,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy; Security,,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:01,https://best-paper-award-ddck.dovetail.com/data/4YKqP0hhpfYjI2fDqnkuso#:v:h=5FJZzHlgtjnGYaJbuaooHE
AIAAIC1096,Meta confirmed to Gizmodo the accounts were part of China's deepfake 'Spamouflage' disinformation operation.,Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,China uses AI to accuse US of starting Maui wildfires,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-flood-warning-system-false-alerts,Incident,,2023,2023,USA,Politics,Government of China,Government of China,,"Deepfake - image, video, audio; Machine learning",Scare/confuse/destabilise,Research study/report,Mis/disinformation,Governance; Marketing,Manipulation,,,,,,,,10/30/2024 16:41,https://best-paper-award-ddck.dovetail.com/data/70vg9Jv4ZaReF0BmWvugR1#:v:h=5I98uujsGfdYsNUTurVcJU
AIAAIC1392,"Hackers led by the Islamic Revolutionary Guard Corps interfered in streaming platforms in the UAE, UK and Canada with news broadcasts generated by AI.  In each case, a synthetic news anchor showed unverified photos that claimed to show Palestinians injured and killed by Israeli attacks on Gaza, accompanied by a ticker displaying the number of Palestinians killed and wounded in the war.",Cause - Human causes - Human abuse of AI tools,Cause,Iranian hackers interrupt TV streaming services with deepfake Gaza news,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/iranian-hackers-interrupt-tv-streaming-services-with-deepfake-gaza-news,Incident,,2024,2024,Canada; UAE; UK,Media/entertainment/sports/arts; Politics,Islamic Revolutionary Guards/Cotton Sandstorm,,,"Deepfake - video, audio; Machine learning",Influence public opinion,Commercial investigation,Mis/disinformation,Governance: Marketing,,,,,,,,,10/24/2024 23:10,https://best-paper-award-ddck.dovetail.com/data/6hDy31IxkOlSHMoF5MBAAb#:v:h=5JGtLM8y4wCI1v74FP50E9
AIAAIC1392,"Hackers led by the Islamic Revolutionary Guard Corps interfered in streaming platforms in the UAE, UK and Canada with news broadcasts generated by AI.  In each case, a synthetic news anchor showed unverified photos that claimed to show Palestinians injured and killed by Israeli attacks on Gaza, accompanied by a ticker displaying the number of Palestinians killed and wounded in the war.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Iranian hackers interrupt TV streaming services with deepfake Gaza news,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/iranian-hackers-interrupt-tv-streaming-services-with-deepfake-gaza-news,Incident,,2024,2024,Canada; UAE; UK,Media/entertainment/sports/arts; Politics,Islamic Revolutionary Guards/Cotton Sandstorm,,,"Deepfake - video, audio; Machine learning",Influence public opinion,Commercial investigation,Mis/disinformation,Governance: Marketing,,,,,,,,,10/24/2024 23:10,https://best-paper-award-ddck.dovetail.com/data/6hDy31IxkOlSHMoF5MBAAb#:v:h=5JGtLM8y4wCI1v74FP50E9
AIAAIC1392,"Hackers led by the Islamic Revolutionary Guard Corps interfered in streaming platforms in the UAE, UK and Canada with news broadcasts generated by AI.  In each case, a synthetic news anchor showed unverified photos that claimed to show Palestinians injured and killed by Israeli attacks on Gaza, accompanied by a ticker displaying the number of Palestinians killed and wounded in the war.",Entity - malicious human,Responsible Entities,Iranian hackers interrupt TV streaming services with deepfake Gaza news,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/iranian-hackers-interrupt-tv-streaming-services-with-deepfake-gaza-news,Incident,,2024,2024,Canada; UAE; UK,Media/entertainment/sports/arts; Politics,Islamic Revolutionary Guards/Cotton Sandstorm,,,"Deepfake - video, audio; Machine learning",Influence public opinion,Commercial investigation,Mis/disinformation,Governance: Marketing,,,,,,,,,10/24/2024 23:10,https://best-paper-award-ddck.dovetail.com/data/6hDy31IxkOlSHMoF5MBAAb#:v:h=5JGtLM8y4wCI1v74FP50E9
AIAAIC1539,"Users figured out how to trick Dream Machine into generating explicit videos and nudity, violating the terms of service of its creator and raising questions about its safety.  Users found ways to ""jailbreak"" or bypass the content filters of AI video generator Dream Machine to generate videos containing nudity and sexually explicit material, even if the quality is crude compared to AI-generated images, according to 404 Media. The discovery raised questions about Luma Labs' governance and Dream Machine's safety, and about the safety of AI video generators in general.",Cause - Human causes - Human abuse of AI tools,Cause,Dream Machine AI video generator makes porn,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dream-machine-ai-video-generator-makes-porn,Issue,2024,2024,2024,USA,Media/entertainment/sports/arts,,Luma Labs,Dream Machine,Text-to-video,Generate video,User comments/complaints,Privacy; Safety,Governance,,,,,,,,,9/27/2024 0:11,https://best-paper-award-ddck.dovetail.com/data/7rSWblhAb3tSxgB8cHRUUQ#:v:h=5K00dOy9lZXgPK05jtS4tx
AIAAIC1539,"Users figured out how to trick Dream Machine into generating explicit videos and nudity, violating the terms of service of its creator and raising questions about its safety.  Users found ways to ""jailbreak"" or bypass the content filters of AI video generator Dream Machine to generate videos containing nudity and sexually explicit material, even if the quality is crude compared to AI-generated images, according to 404 Media. The discovery raised questions about Luma Labs' governance and Dream Machine's safety, and about the safety of AI video generators in general.",Incident - human-driven - bypassing AI safeguards,Incident Type,Dream Machine AI video generator makes porn,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dream-machine-ai-video-generator-makes-porn,Issue,2024,2024,2024,USA,Media/entertainment/sports/arts,,Luma Labs,Dream Machine,Text-to-video,Generate video,User comments/complaints,Privacy; Safety,Governance,,,,,,,,,9/27/2024 0:11,https://best-paper-award-ddck.dovetail.com/data/7rSWblhAb3tSxgB8cHRUUQ#:v:h=5K00dOy9lZXgPK05jtS4tx
AIAAIC1539,"Users figured out how to trick Dream Machine into generating explicit videos and nudity, violating the terms of service of its creator and raising questions about its safety.  Users found ways to ""jailbreak"" or bypass the content filters of AI video generator Dream Machine to generate videos containing nudity and sexually explicit material, even if the quality is crude compared to AI-generated images, according to 404 Media. The discovery raised questions about Luma Labs' governance and Dream Machine's safety, and about the safety of AI video generators in general.",Entity - AI algorithm,Responsible Entities,Dream Machine AI video generator makes porn,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dream-machine-ai-video-generator-makes-porn,Issue,2024,2024,2024,USA,Media/entertainment/sports/arts,,Luma Labs,Dream Machine,Text-to-video,Generate video,User comments/complaints,Privacy; Safety,Governance,,,,,,,,,9/27/2024 0:11,https://best-paper-award-ddck.dovetail.com/data/7rSWblhAb3tSxgB8cHRUUQ#:v:h=5K00dOy9lZXgPK05jtS4tx
AIAAIC1539,"Users figured out how to trick Dream Machine into generating explicit videos and nudity, violating the terms of service of its creator and raising questions about its safety.  Users found ways to ""jailbreak"" or bypass the content filters of AI video generator Dream Machine to generate videos containing nudity and sexually explicit material, even if the quality is crude compared to AI-generated images, according to 404 Media. The discovery raised questions about Luma Labs' governance and Dream Machine's safety, and about the safety of AI video generators in general.",Entity - AI developer company,Responsible Entities,Dream Machine AI video generator makes porn,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dream-machine-ai-video-generator-makes-porn,Issue,2024,2024,2024,USA,Media/entertainment/sports/arts,,Luma Labs,Dream Machine,Text-to-video,Generate video,User comments/complaints,Privacy; Safety,Governance,,,,,,,,,9/27/2024 0:11,https://best-paper-award-ddck.dovetail.com/data/7rSWblhAb3tSxgB8cHRUUQ#:v:h=5K00dOy9lZXgPK05jtS4tx
AIAAIC1539,"Users figured out how to trick Dream Machine into generating explicit videos and nudity, violating the terms of service of its creator and raising questions about its safety.  Users found ways to ""jailbreak"" or bypass the content filters of AI video generator Dream Machine to generate videos containing nudity and sexually explicit material, even if the quality is crude compared to AI-generated images, according to 404 Media. The discovery raised questions about Luma Labs' governance and Dream Machine's safety, and about the safety of AI video generators in general.",Entity - malicious human,Responsible Entities,Dream Machine AI video generator makes porn,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/dream-machine-ai-video-generator-makes-porn,Issue,2024,2024,2024,USA,Media/entertainment/sports/arts,,Luma Labs,Dream Machine,Text-to-video,Generate video,User comments/complaints,Privacy; Safety,Governance,,,,,,,,,9/27/2024 0:11,https://best-paper-award-ddck.dovetail.com/data/7rSWblhAb3tSxgB8cHRUUQ#:v:h=5K00dOy9lZXgPK05jtS4tx
AIAAIC1692,usually without their knowledge or consent,Cause - organization/human cause - lack of informed consent & transparency,Cause,San Francisco City Attorney sues 16 denudification apps,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/san-francisco-city-attorney-sues-16-denudification-apps,Incident,,2024,2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",,Deepfake - image; Machine learning,Undress people,Lawsuit filing/litigation,Ethics/values; Privacy; Safety,Governance,Anxiety/distress; Financial loss; Harassment/bullying; Privacy loss,,,,,,,,10/18/2024 14:24,https://best-paper-award-ddck.dovetail.com/data/96DTYpYxcFqkuVOJeWfX0#:v:h=5Ky77gjRP88N0ZgjmqUAPq
AIAAIC1056,"A deepfake advert impersonating UK MoneySavingExpert founder Martin Lewis attempted to extort people of money by encouraging them to invest in an Elon Musk-backed project. The 'ad' shows a deepfake of Mr Lewis sitting in his office talking about an investment in 'Quantum AI', which is labelled as Elon Musk’s new project. A picture of Musk accompanies the video. ",Incident - organization-driven - problematic AI implementation,Incident Type,Martin Lewis impersonated in deepfake scam ad,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/martin-lewis-deepfake-scam-ad,Incident,,2023,2023,UK,Media/entertainment/sports/arts,Facebook; XCorp/xAI/Twitter,,,"Deepfake - audio, video; Machine learning",Defraud,User comments/complaints,Identity theft/impersonation; Mis/disinformation; Safety,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:21,https://best-paper-award-ddck.dovetail.com/data/28XyNXeY3JJ7xXcjbSuirN#:v:h=5KJMv1bHLVnNm8bKrVNT0j
AIAAIC1056,"A deepfake advert impersonating UK MoneySavingExpert founder Martin Lewis attempted to extort people of money by encouraging them to invest in an Elon Musk-backed project. The 'ad' shows a deepfake of Mr Lewis sitting in his office talking about an investment in 'Quantum AI', which is labelled as Elon Musk’s new project. A picture of Musk accompanies the video. ",Entity - no specific info,Responsible Entities,Martin Lewis impersonated in deepfake scam ad,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/martin-lewis-deepfake-scam-ad,Incident,,2023,2023,UK,Media/entertainment/sports/arts,Facebook; XCorp/xAI/Twitter,,,"Deepfake - audio, video; Machine learning",Defraud,User comments/complaints,Identity theft/impersonation; Mis/disinformation; Safety,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:21,https://best-paper-award-ddck.dovetail.com/data/28XyNXeY3JJ7xXcjbSuirN#:v:h=5KJMv1bHLVnNm8bKrVNT0j
AIAAIC1056,"A deepfake advert impersonating UK MoneySavingExpert founder Martin Lewis attempted to extort people of money by encouraging them to invest in an Elon Musk-backed project. The 'ad' shows a deepfake of Mr Lewis sitting in his office talking about an investment in 'Quantum AI', which is labelled as Elon Musk’s new project. A picture of Musk accompanies the video. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Martin Lewis impersonated in deepfake scam ad,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/martin-lewis-deepfake-scam-ad,Incident,,2023,2023,UK,Media/entertainment/sports/arts,Facebook; XCorp/xAI/Twitter,,,"Deepfake - audio, video; Machine learning",Defraud,User comments/complaints,Identity theft/impersonation; Mis/disinformation; Safety,Governance; Marketing,Financial loss,,,,,,,,10/30/2024 17:21,https://best-paper-award-ddck.dovetail.com/data/28XyNXeY3JJ7xXcjbSuirN#:v:h=5KJMv1bHLVnNm8bKrVNT0j
AIAAIC1314,"Sexually explicit AI-generated images of Taylor Swift published on Twitter and which went viral remained on the platform for up to 17 hours before they were removed. The images, which showed Swift in a series of sexual acts while dressed in Kansas City Chief memorabilia, were uploaded to deepfake porn website Celeb Jihad and quickly went viral on X/Twitter, Facebook, Instagram, Reddit, and other platforms. The images appeared also to have been shared on a Telegram group dedicated to abusive images of women, and created using Microsoft Designer, according to 404 Media.",Entity - malicious human,Responsible Entities,X/Twitter fails to remove graphic AI images of Taylor Swift,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/xtwitter-fails-to-remove-graphic-ai-images-of-taylor-swift,Incident,,2024,2024,USA,Media/entertainment/sports/arts,XCorp/xAI/Twitter,XCorp/xAI/Twitter,X/Twitter,Content moderation system; NLP/text analysis,Moderate content,User comments/complaints,Business model; Robustness; Safety; Privacy,,Harassment/abuse; Privacy loss,,,,,,Litigation,,10/2/2024 20:16,https://best-paper-award-ddck.dovetail.com/data/61hlP660WyAyWh28geTodC#:v:h=5MlyblNvxDLYMJd6RQiGow
AIAAIC1314,"Sexually explicit AI-generated images of Taylor Swift published on Twitter and which went viral remained on the platform for up to 17 hours before they were removed. The images, which showed Swift in a series of sexual acts while dressed in Kansas City Chief memorabilia, were uploaded to deepfake porn website Celeb Jihad and quickly went viral on X/Twitter, Facebook, Instagram, Reddit, and other platforms. The images appeared also to have been shared on a Telegram group dedicated to abusive images of women, and created using Microsoft Designer, according to 404 Media.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,X/Twitter fails to remove graphic AI images of Taylor Swift,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/xtwitter-fails-to-remove-graphic-ai-images-of-taylor-swift,Incident,,2024,2024,USA,Media/entertainment/sports/arts,XCorp/xAI/Twitter,XCorp/xAI/Twitter,X/Twitter,Content moderation system; NLP/text analysis,Moderate content,User comments/complaints,Business model; Robustness; Safety; Privacy,,Harassment/abuse; Privacy loss,,,,,,Litigation,,10/2/2024 20:16,https://best-paper-award-ddck.dovetail.com/data/61hlP660WyAyWh28geTodC#:v:h=5MlyblNvxDLYMJd6RQiGow
AIAAIC1397,"The UK national Health Service (NHS) faced criticism over its plan to introduce artificial intelligence (AI) for automatically generating patient notes during medical appointments. According to UK Health Secretary Victoria Atkins, the scheme will see AI automatically generate notes in the background during appointments and will improve productivity by cutting the time medics spend doing paperwork. Privacy experts argued the 'creepy' plan could reduce privacy, make patients hesitant to share sensitive or embarrassing medical information during consultations, and negatively impact doctor-patient trust. It would also raise difficult ethical questions about confidentiality and patient consent, critics said. A demonstration of the system showed the system mistakingly interpreting Ms Atkins saying England chief media officer 'Chris Whitty' as 'Christmas', fueling concerns about its accuracy and reliability - which are considered essential in a medical setting.",Entity - government authorities that adopt AI,Responsible Entities,NHS plan to AI generate patient notes draws criticism,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/nhs-plan-to-ai-generate-patient-notes-draws-criticism,Issue,,2024,2024,UK,Health,,National Health Service (NHS),,Machine learning,Transcribe medical notes,Product demonstration/release/launch,Accuracy/reliability; Confidentiality; Privacy,,Privacy loss,,,,,,,,10/2/2024 19:12,https://best-paper-award-ddck.dovetail.com/data/6gjEM8N3pHS1AiKhlSKqt9#:v:h=5NCQP6aGV4GPQfPYujgxGx
AIAAIC1397,"The UK national Health Service (NHS) faced criticism over its plan to introduce artificial intelligence (AI) for automatically generating patient notes during medical appointments. According to UK Health Secretary Victoria Atkins, the scheme will see AI automatically generate notes in the background during appointments and will improve productivity by cutting the time medics spend doing paperwork. Privacy experts argued the 'creepy' plan could reduce privacy, make patients hesitant to share sensitive or embarrassing medical information during consultations, and negatively impact doctor-patient trust. It would also raise difficult ethical questions about confidentiality and patient consent, critics said. A demonstration of the system showed the system mistakingly interpreting Ms Atkins saying England chief media officer 'Chris Whitty' as 'Christmas', fueling concerns about its accuracy and reliability - which are considered essential in a medical setting.",Incident - organization-driven - problematic AI implementation,Incident Type,NHS plan to AI generate patient notes draws criticism,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/nhs-plan-to-ai-generate-patient-notes-draws-criticism,Issue,,2024,2024,UK,Health,,National Health Service (NHS),,Machine learning,Transcribe medical notes,Product demonstration/release/launch,Accuracy/reliability; Confidentiality; Privacy,,Privacy loss,,,,,,,,10/2/2024 19:12,https://best-paper-award-ddck.dovetail.com/data/6gjEM8N3pHS1AiKhlSKqt9#:v:h=5NCQP6aGV4GPQfPYujgxGx
AIAAIC1242,"Prisma Labs, the company behind Lensa AI, was sued by a group of Illinois residents for violating their privacy by illegally collecting their facial geometry data through Lensa. Chicago-based law firm Loevy & Loevy filed the class action suit against Prisma alleging that the Cyprus-based company 'unlawfully' collected Illinois residents’ biometric data without their permission, contravening the Illinois Biometric Information Privacy Act. The suit further alleged that the biometric data was illegally stored and used to train Lensa’s 'Magic Avatars' service.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Prisma Labs sued for collecting facial biometrics without consent,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/prisma-labs-sued-for-collecting-facial-biometrics-without-consent,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,Jack Flora,Prisma Labs,Magic Avatars 2.0,Neural network; Deep learning; Machine learning,Create avatars,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:40,https://best-paper-award-ddck.dovetail.com/data/6YwAeGsryomYMz9PUSsNH6#:v:h=5NSQ9JWh9wKMnugencyovy
AIAAIC1242,"Prisma Labs, the company behind Lensa AI, was sued by a group of Illinois residents for violating their privacy by illegally collecting their facial geometry data through Lensa. Chicago-based law firm Loevy & Loevy filed the class action suit against Prisma alleging that the Cyprus-based company 'unlawfully' collected Illinois residents’ biometric data without their permission, contravening the Illinois Biometric Information Privacy Act. The suit further alleged that the biometric data was illegally stored and used to train Lensa’s 'Magic Avatars' service.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Prisma Labs sued for collecting facial biometrics without consent,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/prisma-labs-sued-for-collecting-facial-biometrics-without-consent,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,Jack Flora,Prisma Labs,Magic Avatars 2.0,Neural network; Deep learning; Machine learning,Create avatars,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:40,https://best-paper-award-ddck.dovetail.com/data/6YwAeGsryomYMz9PUSsNH6#:v:h=5NSQ9JWh9wKMnugencyovy
AIAAIC1242,"Prisma Labs, the company behind Lensa AI, was sued by a group of Illinois residents for violating their privacy by illegally collecting their facial geometry data through Lensa. Chicago-based law firm Loevy & Loevy filed the class action suit against Prisma alleging that the Cyprus-based company 'unlawfully' collected Illinois residents’ biometric data without their permission, contravening the Illinois Biometric Information Privacy Act. The suit further alleged that the biometric data was illegally stored and used to train Lensa’s 'Magic Avatars' service.",Entity - AI developer company,Responsible Entities,Prisma Labs sued for collecting facial biometrics without consent,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/prisma-labs-sued-for-collecting-facial-biometrics-without-consent,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,Jack Flora,Prisma Labs,Magic Avatars 2.0,Neural network; Deep learning; Machine learning,Create avatars,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:40,https://best-paper-award-ddck.dovetail.com/data/6YwAeGsryomYMz9PUSsNH6#:v:h=5NSQ9JWh9wKMnugencyovy
AIAAIC1242,"Prisma Labs, the company behind Lensa AI, was sued by a group of Illinois residents for violating their privacy by illegally collecting their facial geometry data through Lensa. Chicago-based law firm Loevy & Loevy filed the class action suit against Prisma alleging that the Cyprus-based company 'unlawfully' collected Illinois residents’ biometric data without their permission, contravening the Illinois Biometric Information Privacy Act. The suit further alleged that the biometric data was illegally stored and used to train Lensa’s 'Magic Avatars' service.",Cause - organization causes - legal non-compliance,Cause,Prisma Labs sued for collecting facial biometrics without consent,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/prisma-labs-sued-for-collecting-facial-biometrics-without-consent,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,Jack Flora,Prisma Labs,Magic Avatars 2.0,Neural network; Deep learning; Machine learning,Create avatars,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/6/2024 23:40,https://best-paper-award-ddck.dovetail.com/data/6YwAeGsryomYMz9PUSsNH6#:v:h=5NSQ9JWh9wKMnugencyovy
AIAAIC1624,Designed to exploit the trust many people have in health experts,Cause - Lack of AI control,Cause,Deepfakes of UK health expert used to promote health scams,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfakes-of-uk-tv-health-experts-used-to-promote-health-scams,Incident,2023,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - video; Machine learning,Generate video,Industry investigation,Ethics/values; Fraud; Personality rights; Mis/disinformation,Governance; Marketing,Personality rights loss,,,,,,,,10/12/2024 1:24,https://best-paper-award-ddck.dovetail.com/data/pFSly53pGLC6OGZhCpmoX#:v:h=5QqgcePuWDcpK4BAo9nhbx
AIAAIC1415,"The Garante said it was concerned about 'the possible implications for the processing of personal data of users located in the European Union and in particular in Italy', and has asked OpenAI for 'clarifications' within twenty days.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Italian privacy watchdog opens investigation into Sora,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/italian-privacy-watchdog-opens-investigation-into-sora,Issue,,2024,2024,Italy,Media/entertainment/sports/arts,OpenAI,OpenAI,Sora,Text-to-video,Generate video,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 15:08,https://best-paper-award-ddck.dovetail.com/data/4PmxyCy3JxbQ7JYazWWW70#:v:h=5Sab2CyNCqiGQvRU7NgZ69
AIAAIC1415,"The Garante said it was concerned about 'the possible implications for the processing of personal data of users located in the European Union and in particular in Italy', and has asked OpenAI for 'clarifications' within twenty days.",Cause - Human causes - Undertrusting AI,Cause,Italian privacy watchdog opens investigation into Sora,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/italian-privacy-watchdog-opens-investigation-into-sora,Issue,,2024,2024,Italy,Media/entertainment/sports/arts,OpenAI,OpenAI,Sora,Text-to-video,Generate video,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 15:08,https://best-paper-award-ddck.dovetail.com/data/4PmxyCy3JxbQ7JYazWWW70#:v:h=5Sab2CyNCqiGQvRU7NgZ69
AIAAIC1375,"Videos of clones of a Ukrainian YouTube mental health influencer in the guise of a Russian woman extolling the Russia-China relationship circulated on Chinese social media. 20-year-old Olga Loiek spotted videos of herself on Bilibili, Douyin and other Chinese social media platforms speaking Mandarin, promoting national ties between Russia and China, selling Russian goods and saying she wants to marry a Chinese man. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Cloned Ukrainian YouTuber promotes Russia-China relations,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ukrainian-youtuber-cloned-to-promote-russia-china-relations,Incident,2020,2024,2024,China; Ukraine,Media/entertainment/sports/arts; Politics,,HeyGen,HeyGen,Deepfake - video; Machine learning,Promote Russia-China relations,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,Anxiety/distress/depression,,,,,,,,10/24/2024 23:01,https://best-paper-award-ddck.dovetail.com/data/1gam1nQCnCihSWkBQwgEHE#:v:h=5Tp8Xg7AJsJdVjaSpoqV6n
AIAAIC1503,"Microsoft’s AI feature, Recall, over potential privacy concerns.  This feature, part of Microsoft’s AI Copilot+ system in Windows 11, takes screenshots of a user’s screen every few seconds. The screenshots are stored locally on the user’s computer in an encrypted format.",Cause - developer causes - programmed AI with problematic functions,Cause,UK watchdog investigates Microsoft Recall AI feature ,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-watchdog-investigates-microsoft-recall-ai-feature,Issue,2024,2024,2024,UK,Technology,,Microsoft,Recall,Machine learning,Identify viewed content,Regulatory inquiry/investigation,Privacy; Security,,Privacy loss,,,,,,,,10/2/2024 12:15,https://best-paper-award-ddck.dovetail.com/data/1XbeDXcEcI6Qj3y0Q8qpLB#:v:h=5TIDfbaV5GXYnw66b8slCY
AIAAIC1503,"Microsoft’s AI feature, Recall, over potential privacy concerns.  This feature, part of Microsoft’s AI Copilot+ system in Windows 11, takes screenshots of a user’s screen every few seconds. The screenshots are stored locally on the user’s computer in an encrypted format.",Incident - organization-driven - problematic AI implementation,Incident Type,UK watchdog investigates Microsoft Recall AI feature ,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-watchdog-investigates-microsoft-recall-ai-feature,Issue,2024,2024,2024,UK,Technology,,Microsoft,Recall,Machine learning,Identify viewed content,Regulatory inquiry/investigation,Privacy; Security,,Privacy loss,,,,,,,,10/2/2024 12:15,https://best-paper-award-ddck.dovetail.com/data/1XbeDXcEcI6Qj3y0Q8qpLB#:v:h=5TIDfbaV5GXYnw66b8slCY
AIAAIC1503,"Microsoft’s AI feature, Recall, over potential privacy concerns.  This feature, part of Microsoft’s AI Copilot+ system in Windows 11, takes screenshots of a user’s screen every few seconds. The screenshots are stored locally on the user’s computer in an encrypted format.",Entity - AI developer company,Responsible Entities,UK watchdog investigates Microsoft Recall AI feature ,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-watchdog-investigates-microsoft-recall-ai-feature,Issue,2024,2024,2024,UK,Technology,,Microsoft,Recall,Machine learning,Identify viewed content,Regulatory inquiry/investigation,Privacy; Security,,Privacy loss,,,,,,,,10/2/2024 12:15,https://best-paper-award-ddck.dovetail.com/data/1XbeDXcEcI6Qj3y0Q8qpLB#:v:h=5TIDfbaV5GXYnw66b8slCY
AIAAIC1620,"Elon Musk's social media platform X (formerly Twitter) came under fire for automatically harvesting user data to train its AI chatbot, Grok, without notifying users or obtaining their consent.",Cause - organization/human cause - lack of informed consent & transparency,Cause,X automatically harvests user data to train AI chatbot,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/x-automatically-harvests-user-data-to-train-ai-chatbot,Issue,2023,2024,2024,Global,Multiple,,X Corp,Grok,Chatbot; Machine learning,Train AI model,User comments/complaints,Copyright; Ethics/values; Privacy,Governance,Copyright loss; Privacy loss,,,,,,,,9/26/2024 23:29,https://best-paper-award-ddck.dovetail.com/data/7eE844CztMR7oh9smZeAg5#:v:h=5TKEl47x2YiEULVgXID1Jn
AIAAIC1408,"It also noted that Worldcoin and ‘affiliates’ are reportedly collecting facial and iris data in 10 locations across South Korea, and that it would take action 'if vilations are found.'",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,South Korea privacy watchdog investigates Worldcoin,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/south-korea-privacy-watchdog-investigates-worldcoin,Incident,2023,2024,2024,South Korea,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security,Governance,Privacy loss,,,,,,Regulatory investigation,,10/2/2024 16:00,https://best-paper-award-ddck.dovetail.com/data/55eJ2S2Wo63yynNtTqwMwz#:v:h=5Wih2KRur22JhcEPxOAfuO
AIAAIC1159,was posted on X (formerly Twitter) by CEO of Israeli NGO Shrink the Conflict Danel Ben Namer,Incident - human-driven - Public entity amplified of misleading content,Incident Type,Bella Hadid 'stands with Israel' deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bella-hadid-stands-with-israel-deepfake,Incident,2022,2023,2023,Israel; Palestine,Media/entertainment/sports/arts; Politics,,,,"Deepfake - audio, video; Machine learning",Manipulate public opinion,Media/NGO fact-check,Mis/disinformation; Privacy,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:05,https://best-paper-award-ddck.dovetail.com/data/3PLQ4SGCwfoyYPR0R2DlHH#:v:h=5Xw4JgcrYglRNMDRLQ4fnv
AIAAIC1159,was posted on X (formerly Twitter) by CEO of Israeli NGO Shrink the Conflict Danel Ben Namer,Cause - Human causes - Human abuse of AI tools,Cause,Bella Hadid 'stands with Israel' deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bella-hadid-stands-with-israel-deepfake,Incident,2022,2023,2023,Israel; Palestine,Media/entertainment/sports/arts; Politics,,,,"Deepfake - audio, video; Machine learning",Manipulate public opinion,Media/NGO fact-check,Mis/disinformation; Privacy,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:05,https://best-paper-award-ddck.dovetail.com/data/3PLQ4SGCwfoyYPR0R2DlHH#:v:h=5Xw4JgcrYglRNMDRLQ4fnv
AIAAIC1159,was posted on X (formerly Twitter) by CEO of Israeli NGO Shrink the Conflict Danel Ben Namer,Entity - malicious human,Responsible Entities,Bella Hadid 'stands with Israel' deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bella-hadid-stands-with-israel-deepfake,Incident,2022,2023,2023,Israel; Palestine,Media/entertainment/sports/arts; Politics,,,,"Deepfake - audio, video; Machine learning",Manipulate public opinion,Media/NGO fact-check,Mis/disinformation; Privacy,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:05,https://best-paper-award-ddck.dovetail.com/data/3PLQ4SGCwfoyYPR0R2DlHH#:v:h=5Xw4JgcrYglRNMDRLQ4fnv
AIAAIC1446,The Greek Data Protection Authority (DPA) found that there was deficient cooperation on the part of the ministry as the Controller. It further considered that the required Data Protection Impact Assessments carried out by the ministry were incomplete,Cause - organization causes - lack of data protection,Cause,Greece fined for AI-powered asylum centre monitoring system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greece-fined-for-ai-powered-asylum-centre-monitoring-system,Incident,,2024,2024,Greece,Govt - immigration,Ministry of Immigration and Asylum,Ministry of Immigration and Asylum,Centaur; Hyperion,Computer vision; Drone; Machine learning; Motion analysis,Monitor asylum centres,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,"EUR 175,000 fine",,,10/2/2024 14:11,https://best-paper-award-ddck.dovetail.com/data/3DmI2hEdtkisj5sDsJPgAG#:v:h=60IrhMcIqzaTHQu8HzBl5j
AIAAIC1296,The incident prompted suggestions that Chattr is likely one of many AI companies to have overlooked security and data privacy in the rush to get their products to market.,Cause - organization causes - lack of data protection,Cause,AI hiring chatbot hack violates applicants' privacy,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-hiring-chatbot-hack-violates-applicants-privacy,Incident,,2024,2024,USA,Business/professional services; Food/food services,"Applebees, Arbys, Chick-fil-A, DunkinDonuts, IHOP, KFC, Shoneys, Subway, Tacobell, Target, Wendys",Chattr,Chattr,Chatbot; Machine learning; Neural network; Deep learning; Machine learning; Reinforcement learning,Recruit employees,White-hat hack,Confidentiality; Privacy; Security,Governance,Privacy loss,,,,,,,,10/2/2024 21:13,https://best-paper-award-ddck.dovetail.com/data/5XiFZ25AMksPdlUlJ2Qrrz#:v:h=62pnVhXphom8L9FubQmkMI
AIAAIC1744,"LinkedIn appears to have scraped its users' data  without informing or gaining their consent  to train its own AI models and those of its ""affiliates"".",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,LinkedIn trains AI models without user consent,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/linkedin-trains-ai-models-without-user-consent,Issue,,2024,2024,Global,Multiple,LinkedIn,LinkedIn,,Machine learning,Train AI models,User comments/complaints,Confidentality; Ethics/values; Privacy,Governance,Confidentiality loss; Privacy loss,,,,,,,,9/26/2024 18:30,https://best-paper-award-ddck.dovetail.com/data/5k4RicGAHvOEDcmUaFZPyG#:v:h=64Qsog8NSsAG1k0zA1sXOu
AIAAIC1413,"Developed by Israeli company Corsight, the system catalogues the faces of unaware Palestinians without their consent and has resulted in the misidentification, abduction and beatings of innocent Palestinians, including the poet Mosab Abu Toha.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Israel facial recognition system misidentifies innocent Gazans,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/israel-facial-recognition-system-misidentifies-innocent-gazans,Incident,,2024,2024,Israel; Palestine,Govt - defence,Israel Defense Forces (IDF),Corsight,,Facial recognition,Identify terrorists,Media investigation,Human/civil rights; Privacy,Governance; Marketing,Privacy loss; Loss of rights/freedoms,Chilling effect,,,,,,,10/2/2024 15:27,https://best-paper-award-ddck.dovetail.com/data/513IxSsMP1gESrQePS8buy#:v:h=64YClk6ga49xbuRd97Tp31
AIAAIC1413,"Developed by Israeli company Corsight, the system catalogues the faces of unaware Palestinians without their consent and has resulted in the misidentification, abduction and beatings of innocent Palestinians, including the poet Mosab Abu Toha.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Israel facial recognition system misidentifies innocent Gazans,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/israel-facial-recognition-system-misidentifies-innocent-gazans,Incident,,2024,2024,Israel; Palestine,Govt - defence,Israel Defense Forces (IDF),Corsight,,Facial recognition,Identify terrorists,Media investigation,Human/civil rights; Privacy,Governance; Marketing,Privacy loss; Loss of rights/freedoms,Chilling effect,,,,,,,10/2/2024 15:27,https://best-paper-award-ddck.dovetail.com/data/513IxSsMP1gESrQePS8buy#:v:h=64YClk6ga49xbuRd97Tp31
AIAAIC1469,"The group also claimed that OpenAI refused to correct or delete wrong answers, and would not disclose information about the data processed, its sources, or recipients.",Cause - organization causes - poor business ethics,Cause,ChatGPT accused of violating GDPR by not correcting inaccurate personal information,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-said-to-violate-gdpr-by-not-correcting-inaccurate-personal-info,Incident,2022,2024,2024,Austria,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot,Generate text,Legal complaint,Accuracy/reliability; Mis/disinformation; Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 13:16,https://best-paper-award-ddck.dovetail.com/data/6AJcNsz8AZfklQimhDzbDm#:v:h=658lFSlbDdaG9KXWMSxz5B
AIAAIC1003,"An AI-generated US Republican National Congress ('RNC') advert showing a dystopian future in which the USA is overrun by immigrants, gangs and drugs was criticised for alienating US citizens and reducing trust in politics and politicians. The ad was labeled as AI-generated, but the labelling is small and inconspicuous, leading some commentators to complain that the Republican Party was engaging in opaque and unethical behaviour. It was released the day before President Biden confirmed his second run at the US Presidency.",Cause - no specific info,Cause,RNC smears President Biden with AI ad,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rnc-smears-president-biden-with-fake-ai-advert,Incident,,2023,2023,USA,Politics,Republican National Committee (GOP),,,Deepfake - image; Machine learning,Scare/confuse/destabilise,Product demonstration/release/launch,Mis/disinformation; Ethics/values,Marketing,,,,,,,,,10/30/2024 19:05,https://best-paper-award-ddck.dovetail.com/data/PTMB35CugSyw0jAOt00Np#:v:h=66lyvRDv28kkUwBD8sidSj
AIAAIC1003,"An AI-generated US Republican National Congress ('RNC') advert showing a dystopian future in which the USA is overrun by immigrants, gangs and drugs was criticised for alienating US citizens and reducing trust in politics and politicians. The ad was labeled as AI-generated, but the labelling is small and inconspicuous, leading some commentators to complain that the Republican Party was engaging in opaque and unethical behaviour. It was released the day before President Biden confirmed his second run at the US Presidency.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,RNC smears President Biden with AI ad,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rnc-smears-president-biden-with-fake-ai-advert,Incident,,2023,2023,USA,Politics,Republican National Committee (GOP),,,Deepfake - image; Machine learning,Scare/confuse/destabilise,Product demonstration/release/launch,Mis/disinformation; Ethics/values,Marketing,,,,,,,,,10/30/2024 19:05,https://best-paper-award-ddck.dovetail.com/data/PTMB35CugSyw0jAOt00Np#:v:h=66lyvRDv28kkUwBD8sidSj
AIAAIC1003,"An AI-generated US Republican National Congress ('RNC') advert showing a dystopian future in which the USA is overrun by immigrants, gangs and drugs was criticised for alienating US citizens and reducing trust in politics and politicians. The ad was labeled as AI-generated, but the labelling is small and inconspicuous, leading some commentators to complain that the Republican Party was engaging in opaque and unethical behaviour. It was released the day before President Biden confirmed his second run at the US Presidency.",Incident - organization-driven - problematic AI implementation,Incident Type,RNC smears President Biden with AI ad,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rnc-smears-president-biden-with-fake-ai-advert,Incident,,2023,2023,USA,Politics,Republican National Committee (GOP),,,Deepfake - image; Machine learning,Scare/confuse/destabilise,Product demonstration/release/launch,Mis/disinformation; Ethics/values,Marketing,,,,,,,,,10/30/2024 19:05,https://best-paper-award-ddck.dovetail.com/data/PTMB35CugSyw0jAOt00Np#:v:h=66lyvRDv28kkUwBD8sidSj
AIAAIC1497,"A group of voiceover actors sued AI start-up, Lovo, for the unauthorised use of their voices A group of voiceover actors, including Paul Skye Lehrman, filed a class-action lawsuit for USD 5M in damages against AI startup Lovo, accusing the company of misappropriating their voices without consent. The lawsuit alleges that Lovo used the actors’ voices to create AI-generated content, leading to voice theft and potential loss of income. The actors allege that Lovo’s unauthorised use of their voices has deprived them of control over their work and proper compensation. The lawsuit seeks to represent other voiceover artists who believe their voices were misappropriated by Lovo.",Entity - AI developer company,Responsible Entities,Voice Actors sue AI start-up for “voice theft”,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/voice-actors-sue-ai-startup-for-voice-theft,Incident,,2024,2024,USA,Media/entertainment/sports/arts,LOVO,LOVO,Lovo Voice Generator,Deepfake - audio; Machine learning,Generate voice,Legal filing,Personality rights,Governance,Personality rights loss; Financial loss,,,Reputational damage,,$5M in damages,Litigation,,10/12/2024 0:55,https://best-paper-award-ddck.dovetail.com/data/6pHtWShnb04KpoDyxzXLX3#:v:h=66RbLgcPXpYD8xzmF1pW5G
AIAAIC1497,"A group of voiceover actors sued AI start-up, Lovo, for the unauthorised use of their voices A group of voiceover actors, including Paul Skye Lehrman, filed a class-action lawsuit for USD 5M in damages against AI startup Lovo, accusing the company of misappropriating their voices without consent. The lawsuit alleges that Lovo used the actors’ voices to create AI-generated content, leading to voice theft and potential loss of income. The actors allege that Lovo’s unauthorised use of their voices has deprived them of control over their work and proper compensation. The lawsuit seeks to represent other voiceover artists who believe their voices were misappropriated by Lovo.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Voice Actors sue AI start-up for “voice theft”,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/voice-actors-sue-ai-startup-for-voice-theft,Incident,,2024,2024,USA,Media/entertainment/sports/arts,LOVO,LOVO,Lovo Voice Generator,Deepfake - audio; Machine learning,Generate voice,Legal filing,Personality rights,Governance,Personality rights loss; Financial loss,,,Reputational damage,,$5M in damages,Litigation,,10/12/2024 0:55,https://best-paper-award-ddck.dovetail.com/data/6pHtWShnb04KpoDyxzXLX3#:v:h=66RbLgcPXpYD8xzmF1pW5G
AIAAIC1162,"The clip was allegedly created by German comedy outlet Snicklick and was labelled as satire. But some users appeared to believe it was real, while others chose to use it as an opportunity to attack Thunberg for her pro-Palestinian views and her environmental beliefs, and to spread disinformation.",Cause - human causes - Overtrusting AI,Cause,Greta Thunberg promotes use of 'vegan grenades',10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greta-thunberg-promotes-use-of-vegan-grenades,Incident,,2023,2023,Sweden,Politics,,Snicklick,,"Deepfake - audio, video; Machine learning",Satarise/parody,Fact check,Mis/disinformation,,Reputational damage,,,,,,,,10/24/2024 21:10,https://best-paper-award-ddck.dovetail.com/data/78Or8CTKr49gQc0kfGND1h#:v:h=68OFb8YQCc5sZznRozKGs9
AIAAIC1162,"The clip was allegedly created by German comedy outlet Snicklick and was labelled as satire. But some users appeared to believe it was real, while others chose to use it as an opportunity to attack Thunberg for her pro-Palestinian views and her environmental beliefs, and to spread disinformation.",Entity - user misinterpretation,Responsible Entities,Greta Thunberg promotes use of 'vegan grenades',10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greta-thunberg-promotes-use-of-vegan-grenades,Incident,,2023,2023,Sweden,Politics,,Snicklick,,"Deepfake - audio, video; Machine learning",Satarise/parody,Fact check,Mis/disinformation,,Reputational damage,,,,,,,,10/24/2024 21:10,https://best-paper-award-ddck.dovetail.com/data/78Or8CTKr49gQc0kfGND1h#:v:h=68OFb8YQCc5sZznRozKGs9
AIAAIC1270,"A 'completely bogus' deepfake video of Singapore Prime Minister Lee Hsien Loong promoting an investment product raised concerns about the use of AI to disrupt politics and create disinformation. In the altered video, Mr Lee is allegedly interviewed by a presenter from Chinese news network CGTN about a 'revolutionary investment platform designed by Elon Musk' that was purportedly approved by the Singapore government.  The video ends with the presenter urging viewers to click on a link to register for the platform, to earn 'passive income'.",Entity - malicious human,Responsible Entities,Singapore PM Lee Hsien Loong crypto promotion deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/singapore-pm-lee-hsien-loong-crypto-promotion-deepfake,Incident,2020,2023,2023,Singapore,Banking/financial services; Politics,,,ChatGPT,"Deepfake - audio, video; Machine learning",Defraud,,Mis/disinformation; Fraud,Governance; Marketing,Financial loss,,,,,,,,10/24/2024 22:21,https://best-paper-award-ddck.dovetail.com/data/47RXx3DqnSYiOuUzVXFPA7#:v:h=69uBNFRgKMOgU0foHGheqz
AIAAIC1270,"A 'completely bogus' deepfake video of Singapore Prime Minister Lee Hsien Loong promoting an investment product raised concerns about the use of AI to disrupt politics and create disinformation. In the altered video, Mr Lee is allegedly interviewed by a presenter from Chinese news network CGTN about a 'revolutionary investment platform designed by Elon Musk' that was purportedly approved by the Singapore government.  The video ends with the presenter urging viewers to click on a link to register for the platform, to earn 'passive income'.",Cause - Human causes - Human abuse of AI tools,Cause,Singapore PM Lee Hsien Loong crypto promotion deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/singapore-pm-lee-hsien-loong-crypto-promotion-deepfake,Incident,2020,2023,2023,Singapore,Banking/financial services; Politics,,,ChatGPT,"Deepfake - audio, video; Machine learning",Defraud,,Mis/disinformation; Fraud,Governance; Marketing,Financial loss,,,,,,,,10/24/2024 22:21,https://best-paper-award-ddck.dovetail.com/data/47RXx3DqnSYiOuUzVXFPA7#:v:h=69uBNFRgKMOgU0foHGheqz
AIAAIC1270,"A 'completely bogus' deepfake video of Singapore Prime Minister Lee Hsien Loong promoting an investment product raised concerns about the use of AI to disrupt politics and create disinformation. In the altered video, Mr Lee is allegedly interviewed by a presenter from Chinese news network CGTN about a 'revolutionary investment platform designed by Elon Musk' that was purportedly approved by the Singapore government.  The video ends with the presenter urging viewers to click on a link to register for the platform, to earn 'passive income'.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Singapore PM Lee Hsien Loong crypto promotion deepfake,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/singapore-pm-lee-hsien-loong-crypto-promotion-deepfake,Incident,2020,2023,2023,Singapore,Banking/financial services; Politics,,,ChatGPT,"Deepfake - audio, video; Machine learning",Defraud,,Mis/disinformation; Fraud,Governance; Marketing,Financial loss,,,,,,,,10/24/2024 22:21,https://best-paper-award-ddck.dovetail.com/data/47RXx3DqnSYiOuUzVXFPA7#:v:h=69uBNFRgKMOgU0foHGheqz
"AIAAIC1788
",The fraudsters used advanced AI technology ,Entity - malicious human,Responsible Entities,"Pensioner loses NZD 224,000 to deepfake scam",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pensioner-loses-nzd-224000-to-deepfake-scam,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:04,https://best-paper-award-ddck.dovetail.com/data/2ZOAjWwPQtEjv3sKuAiOJ#:v:h=69DMdubwQfTJoXT9dvy3zN
AIAAIC1760,Nguyen and Ardayfio,Entity - malicious human,Responsible Entities,Harvard students add facial recognition to Meta smart glasses to dox strangers,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/harvard-students-add-facial-recognition-to-meta-smart-glasses,Issue,2024,2024,2024,USA,Research/academia,,AnhPhu Nguyen; Caine Ardayfio; EssilorLuxottica; Meta; Pimeyes, I-XRAY; Ray-Ban Meta Smart Glasses; Pimeyes,Facial recognition; Smart glasses,Identify individuals,Research study/report,Dual/multi-use; Privacy,,Privacy loss,,,,,,,,11/4/2024 16:58,https://best-paper-award-ddck.dovetail.com/data/3QUOtg4w3Lo6DSlLwz1pZo#:v:h=69FvvewQ7wvB3E5ZRimEuM
AIAAIC1257,"A lawsuit filed against OpenAI in California, USA, alleged that two of its AI models, ChatGPT and DALL-E, were trained using hundreds of millions of people’s data without proper consent.  The160-page complaint, served on behalf of 16 plaintiffs, accused OpenAI of training its generative AI programmes ChatGPT and DALL-E on 'stolen private information' taken from hundreds of millions of internet users, including children, without proper permission.",Cause - organization/human cause - lack of informed consent & transparency,Cause,OpenAI 'unprecedented web scraping' trains AI models,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-unprecedented-web-scraping-trains-ai-models,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,,OpenAI,ChatGPT; DALL-E,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text; Generate images,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 21:22,https://best-paper-award-ddck.dovetail.com/data/7xeqrtiiKXcFbniKLZDcBj#:v:h=6bXJA2j7jFS367KEv5XbHR
AIAAIC1257,"A lawsuit filed against OpenAI in California, USA, alleged that two of its AI models, ChatGPT and DALL-E, were trained using hundreds of millions of people’s data without proper consent.  The160-page complaint, served on behalf of 16 plaintiffs, accused OpenAI of training its generative AI programmes ChatGPT and DALL-E on 'stolen private information' taken from hundreds of millions of internet users, including children, without proper permission.",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,OpenAI 'unprecedented web scraping' trains AI models,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/openai-unprecedented-web-scraping-trains-ai-models,Incident,2022,2023,2023,USA,Media/entertainment/sports/arts,,OpenAI,ChatGPT; DALL-E,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text; Generate images,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 21:22,https://best-paper-award-ddck.dovetail.com/data/7xeqrtiiKXcFbniKLZDcBj#:v:h=6bXJA2j7jFS367KEv5XbHR
AIAAIC1254,"A Tesla whistleblower leaked 100GB of sensitive company data, including thousands of complaints about the safety of the company's self-driving system, including sudden acceleration or phantom braking.",Cause - Human causes - employee internal threats,Cause,Whistleblower reveals Tesla phantom braking complaints,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/whistleblower-reveals-tesla-phantom-braking-complaints,Incident,2014,2023,2023,Netherlands; Germany,Automotive,Lukasz Krupski,Tesla,Autopilot,Driver assistance system,"Automate steering, acceleration, braking",Data leak; Whistleblower,Confidentiality; Privacy; Safety; Security,Governance,Privacy loss; Confidentiality loss,,,,,,Regulatory investigation,,10/4/2024 14:36,https://best-paper-award-ddck.dovetail.com/data/4DasqRusymkPLKKFZIW8MS#:v:h=6cOOizsjUBtvn8v6s3ZTkh
AIAAIC1254,"A Tesla whistleblower leaked 100GB of sensitive company data, including thousands of complaints about the safety of the company's self-driving system, including sudden acceleration or phantom braking.",Incident - organization-driven - problematic AI implementation,Incident Type,Whistleblower reveals Tesla phantom braking complaints,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/whistleblower-reveals-tesla-phantom-braking-complaints,Incident,2014,2023,2023,Netherlands; Germany,Automotive,Lukasz Krupski,Tesla,Autopilot,Driver assistance system,"Automate steering, acceleration, braking",Data leak; Whistleblower,Confidentiality; Privacy; Safety; Security,Governance,Privacy loss; Confidentiality loss,,,,,,Regulatory investigation,,10/4/2024 14:36,https://best-paper-award-ddck.dovetail.com/data/4DasqRusymkPLKKFZIW8MS#:v:h=6cOOizsjUBtvn8v6s3ZTkh
AIAAIC1617,"An AI-generated video apparently showing US Vice President Kamala Harris speaking incoherently and claiming she said things she never actually said prompted concerns about electoral disinformation and interference. The 22-second clip purported to show Harris saying, “Today is today. And yesterday was today yesterday. Tomorrow will be today tomorrow. So live today so that future today will past today, as it is tomorrow.” ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake Kamala Harris slurs her lines,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-kamala-harris-slurs-her-lines,Incident,,2024,2024,USA,Politics,,,,Deepfake - audio; Machine learning,Damage reputation,,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:19,https://best-paper-award-ddck.dovetail.com/data/4Mv9w4hi7cKln5S1y8Tfcf#:v:h=6eC8pkB38tYB55hOjBgFqm
"AIAAIC1784
","A company cloned the voice of YouTuber Marques Brownlee and used it promote one of their products his consent, triggering a public backlash. What happened Networking product company Dot used an AI-generated clone of Brownlee's voice to promote their Dot Metal product in an Instagram ad.  Brownlee publicly called out the unauthorised use of his voice on social media, describing the company's actions as ""scummy"" and ""shady"".",Incident - organization-driven - problematic AI implementation,Incident Type,Company uses Marques Brownlee AI voice clone to promote product without consent,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/company-uses-marques-brownlee-ai-voice-clone-to-promote-product,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:06,https://best-paper-award-ddck.dovetail.com/data/281o35XZfVDBoPqfqlkVwq#:v:h=6eVSShIpsTspvgditIgysr
"AIAAIC1784
","A company cloned the voice of YouTuber Marques Brownlee and used it promote one of their products his consent, triggering a public backlash. What happened Networking product company Dot used an AI-generated clone of Brownlee's voice to promote their Dot Metal product in an Instagram ad.  Brownlee publicly called out the unauthorised use of his voice on social media, describing the company's actions as ""scummy"" and ""shady"".",Cause - organization/human cause - lack of informed consent & transparency,Cause,Company uses Marques Brownlee AI voice clone to promote product without consent,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/company-uses-marques-brownlee-ai-voice-clone-to-promote-product,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:06,https://best-paper-award-ddck.dovetail.com/data/281o35XZfVDBoPqfqlkVwq#:v:h=6eVSShIpsTspvgditIgysr
"AIAAIC1784
","A company cloned the voice of YouTuber Marques Brownlee and used it promote one of their products his consent, triggering a public backlash. What happened Networking product company Dot used an AI-generated clone of Brownlee's voice to promote their Dot Metal product in an Instagram ad.  Brownlee publicly called out the unauthorised use of his voice on social media, describing the company's actions as ""scummy"" and ""shady"".",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Company uses Marques Brownlee AI voice clone to promote product without consent,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/company-uses-marques-brownlee-ai-voice-clone-to-promote-product,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:06,https://best-paper-award-ddck.dovetail.com/data/281o35XZfVDBoPqfqlkVwq#:v:h=6eVSShIpsTspvgditIgysr
AIAAIC1700,"The images sparked outrage among Swift's fans, many of whom are concerned about the spread of misinformation, particularly in the context of the upcoming 2024 election. Swift has not publicly endorsed any candidate for this election, although she supported Joe Biden and Kamala Harris in 2020 and has been critical of Trump.",Cause - Human causes - Human abuse of AI tools,Cause,Donald Trump uses AI to fake Taylor Swift endorsement,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/donald-trump-uses-ai-to-fake-taylor-swift-endorsement,Issue,,2024,2024,USA,Politics; Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Deceive voters,,Ethics/values; Mis/disinformation,Governance,,,,,,,,,10/13/2024 23:00,https://best-paper-award-ddck.dovetail.com/data/29x9mi44lzE1VL1iEqQWMz#:v:h=6hWlsMJ24wKXDgFvauI25E
AIAAIC1700,"The images sparked outrage among Swift's fans, many of whom are concerned about the spread of misinformation, particularly in the context of the upcoming 2024 election. Swift has not publicly endorsed any candidate for this election, although she supported Joe Biden and Kamala Harris in 2020 and has been critical of Trump.",Entity - malicious human,Responsible Entities,Donald Trump uses AI to fake Taylor Swift endorsement,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/donald-trump-uses-ai-to-fake-taylor-swift-endorsement,Issue,,2024,2024,USA,Politics; Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Deceive voters,,Ethics/values; Mis/disinformation,Governance,,,,,,,,,10/13/2024 23:00,https://best-paper-award-ddck.dovetail.com/data/29x9mi44lzE1VL1iEqQWMz#:v:h=6hWlsMJ24wKXDgFvauI25E
AIAAIC1736,"A man in Massachusetts was arrested for allegedly stalking, doxing, and harassing a femaleprofessor for seven years using an AI chatbot and other tools. James Florence Jr. was accused of using AI to generate fake nude images of the woman, and of creating a chatbotin her likeness that gave out her name, address, and personal details on a website for AI-powered sex bots. Florence allegedly posted 128 images, including nude fakes, of the woman 687 times on a forum for shamingwomen, along with her personal information, and programmed the woman's information into two public chatbotwebsites to impersonate her. The chatbots were programmed with the victim's date of birth, home address, employment, education, hobbies,typical dress, names of family/friends, and even her mother's death date. If asked where she lived, the chatbotwould reply with her real address followed by ""Why don't you come over?""","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Stalker doxxes and harrasses woman using AI chatbot,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/stalker-doxxes-and-harrasses-woman-using-ai-chatbot,Incident,,2024,2024,USA,Media/entertainment/sports/arts,James Florence Jr.,CRUSHON AI CORP,CrushonAI,Chatbot; Machine learning,Harrass/intimidate/shame,Lawsuit filing/litigation,Privacy; Safety,,Harassment; Privacy loss,,,,,,,,9/26/2024 19:15,https://best-paper-award-ddck.dovetail.com/data/5Eyp8PFURZXO9oG2EqeMqC#:v:h=6lpc5Ojqp88ZMs4kYQNeA6
AIAAIC1736,"A man in Massachusetts was arrested for allegedly stalking, doxing, and harassing a femaleprofessor for seven years using an AI chatbot and other tools. James Florence Jr. was accused of using AI to generate fake nude images of the woman, and of creating a chatbotin her likeness that gave out her name, address, and personal details on a website for AI-powered sex bots. Florence allegedly posted 128 images, including nude fakes, of the woman 687 times on a forum for shamingwomen, along with her personal information, and programmed the woman's information into two public chatbotwebsites to impersonate her. The chatbots were programmed with the victim's date of birth, home address, employment, education, hobbies,typical dress, names of family/friends, and even her mother's death date. If asked where she lived, the chatbotwould reply with her real address followed by ""Why don't you come over?""",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,Stalker doxxes and harrasses woman using AI chatbot,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/stalker-doxxes-and-harrasses-woman-using-ai-chatbot,Incident,,2024,2024,USA,Media/entertainment/sports/arts,James Florence Jr.,CRUSHON AI CORP,CrushonAI,Chatbot; Machine learning,Harrass/intimidate/shame,Lawsuit filing/litigation,Privacy; Safety,,Harassment; Privacy loss,,,,,,,,9/26/2024 19:15,https://best-paper-award-ddck.dovetail.com/data/5Eyp8PFURZXO9oG2EqeMqC#:v:h=6lpc5Ojqp88ZMs4kYQNeA6
AIAAIC1736,"A man in Massachusetts was arrested for allegedly stalking, doxing, and harassing a femaleprofessor for seven years using an AI chatbot and other tools. James Florence Jr. was accused of using AI to generate fake nude images of the woman, and of creating a chatbotin her likeness that gave out her name, address, and personal details on a website for AI-powered sex bots. Florence allegedly posted 128 images, including nude fakes, of the woman 687 times on a forum for shamingwomen, along with her personal information, and programmed the woman's information into two public chatbotwebsites to impersonate her. The chatbots were programmed with the victim's date of birth, home address, employment, education, hobbies,typical dress, names of family/friends, and even her mother's death date. If asked where she lived, the chatbotwould reply with her real address followed by ""Why don't you come over?""",Cause - Human causes - Human abuse of AI tools,Cause,Stalker doxxes and harrasses woman using AI chatbot,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/stalker-doxxes-and-harrasses-woman-using-ai-chatbot,Incident,,2024,2024,USA,Media/entertainment/sports/arts,James Florence Jr.,CRUSHON AI CORP,CrushonAI,Chatbot; Machine learning,Harrass/intimidate/shame,Lawsuit filing/litigation,Privacy; Safety,,Harassment; Privacy loss,,,,,,,,9/26/2024 19:15,https://best-paper-award-ddck.dovetail.com/data/5Eyp8PFURZXO9oG2EqeMqC#:v:h=6lpc5Ojqp88ZMs4kYQNeA6
AIAAIC1736,"A man in Massachusetts was arrested for allegedly stalking, doxing, and harassing a femaleprofessor for seven years using an AI chatbot and other tools. James Florence Jr. was accused of using AI to generate fake nude images of the woman, and of creating a chatbotin her likeness that gave out her name, address, and personal details on a website for AI-powered sex bots. Florence allegedly posted 128 images, including nude fakes, of the woman 687 times on a forum for shamingwomen, along with her personal information, and programmed the woman's information into two public chatbotwebsites to impersonate her. The chatbots were programmed with the victim's date of birth, home address, employment, education, hobbies,typical dress, names of family/friends, and even her mother's death date. If asked where she lived, the chatbotwould reply with her real address followed by ""Why don't you come over?""",Entity - malicious human,Responsible Entities,Stalker doxxes and harrasses woman using AI chatbot,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/stalker-doxxes-and-harrasses-woman-using-ai-chatbot,Incident,,2024,2024,USA,Media/entertainment/sports/arts,James Florence Jr.,CRUSHON AI CORP,CrushonAI,Chatbot; Machine learning,Harrass/intimidate/shame,Lawsuit filing/litigation,Privacy; Safety,,Harassment; Privacy loss,,,,,,,,9/26/2024 19:15,https://best-paper-award-ddck.dovetail.com/data/5Eyp8PFURZXO9oG2EqeMqC#:v:h=6lpc5Ojqp88ZMs4kYQNeA6
AIAAIC1483,"The CEO of the world largest marketing services group was targeted by an elaborate scam involving voice cloning in an attempt to solicit money and personal details from the company’s workforce. WPP CEO Mark Read’s image and voice were stolen by fraudsters, who created a WhatsApp account seemingly belonging to him and used it to set up a Microsoft Teams meeting that appeared to be with him and another senior WPP executive. During the meeting, the impostors deployed a deepfake video and voice clone of Read the executive as well as YouTube footage of them. The scammers also tried using the meeting’s chat function to impersonate Read and target a fellow WPP executive by asking them to set up a new business and hand over money and other personal details, according to the Guardian. ",Entity - malicious human,Responsible Entities,WPP CEO impersonated in deepfake scam,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/wpp-ceo-impersonated-in-deepfake-scam,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,"Deepfake - audio, video; Machine learning",Defraud,,Fraud,Governance; Marketing,,,,,,,,,10/24/2024 20:39,https://best-paper-award-ddck.dovetail.com/data/6RfixpodKkNk6g9JsscDeL#:v:h=6mx9GXEQVk3yv4y0EwGZqL
AIAAIC1483,"The CEO of the world largest marketing services group was targeted by an elaborate scam involving voice cloning in an attempt to solicit money and personal details from the company’s workforce. WPP CEO Mark Read’s image and voice were stolen by fraudsters, who created a WhatsApp account seemingly belonging to him and used it to set up a Microsoft Teams meeting that appeared to be with him and another senior WPP executive. During the meeting, the impostors deployed a deepfake video and voice clone of Read the executive as well as YouTube footage of them. The scammers also tried using the meeting’s chat function to impersonate Read and target a fellow WPP executive by asking them to set up a new business and hand over money and other personal details, according to the Guardian. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,WPP CEO impersonated in deepfake scam,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/wpp-ceo-impersonated-in-deepfake-scam,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,"Deepfake - audio, video; Machine learning",Defraud,,Fraud,Governance; Marketing,,,,,,,,,10/24/2024 20:39,https://best-paper-award-ddck.dovetail.com/data/6RfixpodKkNk6g9JsscDeL#:v:h=6mx9GXEQVk3yv4y0EwGZqL
AIAAIC1445,A video shared online by Canada's Alberta Party featuring a man endorsing the party faced a backlash after social media users pointed out that the man in the video was not a real person. The video showed a man in front of a superimposed image of Calgary. Alberta Party leader Barry Morishita later acknowleged it had been created using  video creation platform Synthesia. The clip was subsequently deleted.,Entity - government authorities that adopt AI,Responsible Entities,Alberta Party endorses itself using deepfake video,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/alberta-party-endorses-itself-using-deepfake-video,Incident,,2023,2023,Canada,Politics,Alberta Party,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Endorse political party,User comments/complaints,Ethics/values,Governance; Marketing,,,,,,,,,10/24/2024 21:01,https://best-paper-award-ddck.dovetail.com/data/3DuQPcVxgRW4f6IdVcY41x#:v:h=6mAL4oMhCKd1zSoz0TOqkj
AIAAIC1445,A video shared online by Canada's Alberta Party featuring a man endorsing the party faced a backlash after social media users pointed out that the man in the video was not a real person. The video showed a man in front of a superimposed image of Calgary. Alberta Party leader Barry Morishita later acknowleged it had been created using  video creation platform Synthesia. The clip was subsequently deleted.,"Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Alberta Party endorses itself using deepfake video,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/alberta-party-endorses-itself-using-deepfake-video,Incident,,2023,2023,Canada,Politics,Alberta Party,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Endorse political party,User comments/complaints,Ethics/values,Governance; Marketing,,,,,,,,,10/24/2024 21:01,https://best-paper-award-ddck.dovetail.com/data/3DuQPcVxgRW4f6IdVcY41x#:v:h=6mAL4oMhCKd1zSoz0TOqkj
AIAAIC1445,A video shared online by Canada's Alberta Party featuring a man endorsing the party faced a backlash after social media users pointed out that the man in the video was not a real person. The video showed a man in front of a superimposed image of Calgary. Alberta Party leader Barry Morishita later acknowleged it had been created using  video creation platform Synthesia. The clip was subsequently deleted.,Cause - no specific info,Cause,Alberta Party endorses itself using deepfake video,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/alberta-party-endorses-itself-using-deepfake-video,Incident,,2023,2023,Canada,Politics,Alberta Party,Synthesia,Synthesia,"Deepfake - audio, video; Machine learning",Endorse political party,User comments/complaints,Ethics/values,Governance; Marketing,,,,,,,,,10/24/2024 21:01,https://best-paper-award-ddck.dovetail.com/data/3DuQPcVxgRW4f6IdVcY41x#:v:h=6mAL4oMhCKd1zSoz0TOqkj
AIAAIC1532,"Fifty female students at Bacchus Marsh Grammar school in Melbourne, Australia, were targeted with AI-generated fake nude images. The images which were shared on social media, appeared to have been created using AI to graft photos of the girls' faces obtained from their private social media accounts onto others' bodies.  The mother of one of the targeted students shared that her 16-year-old daughter vomited after seeing the ""incredibly graphic"" and ""mutilated"" images online. The school said it was working with police to remove the images from social media and determine if the perpetrator is a student or someone else.",Cause - Lack of AI control,Cause,50 Melbourne school girls targeted using AI nude images,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/50-melbourne-school-girls-targeted-using-ai-nude-images,Incident,,2024,2024,Australia,Education,Bacchus Marsh Grammar students,,,Deepfake - image; Machine learning,,Police statement ,Ethics/values; Safety,Governance; Marketing,,,,,,,,,10/12/2024 1:02,https://best-paper-award-ddck.dovetail.com/data/5gQurSHekkdsAKDznegZ9V#:v:h=6o8U35uRNEuFGFVvJPcRgv
AIAAIC1532,"Fifty female students at Bacchus Marsh Grammar school in Melbourne, Australia, were targeted with AI-generated fake nude images. The images which were shared on social media, appeared to have been created using AI to graft photos of the girls' faces obtained from their private social media accounts onto others' bodies.  The mother of one of the targeted students shared that her 16-year-old daughter vomited after seeing the ""incredibly graphic"" and ""mutilated"" images online. The school said it was working with police to remove the images from social media and determine if the perpetrator is a student or someone else.",Cause - organization/human cause - lack of informed consent & transparency,Cause,50 Melbourne school girls targeted using AI nude images,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/50-melbourne-school-girls-targeted-using-ai-nude-images,Incident,,2024,2024,Australia,Education,Bacchus Marsh Grammar students,,,Deepfake - image; Machine learning,,Police statement ,Ethics/values; Safety,Governance; Marketing,,,,,,,,,10/12/2024 1:02,https://best-paper-award-ddck.dovetail.com/data/5gQurSHekkdsAKDznegZ9V#:v:h=6o8U35uRNEuFGFVvJPcRgv
AIAAIC1532,"Fifty female students at Bacchus Marsh Grammar school in Melbourne, Australia, were targeted with AI-generated fake nude images. The images which were shared on social media, appeared to have been created using AI to graft photos of the girls' faces obtained from their private social media accounts onto others' bodies.  The mother of one of the targeted students shared that her 16-year-old daughter vomited after seeing the ""incredibly graphic"" and ""mutilated"" images online. The school said it was working with police to remove the images from social media and determine if the perpetrator is a student or someone else.",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,50 Melbourne school girls targeted using AI nude images,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/50-melbourne-school-girls-targeted-using-ai-nude-images,Incident,,2024,2024,Australia,Education,Bacchus Marsh Grammar students,,,Deepfake - image; Machine learning,,Police statement ,Ethics/values; Safety,Governance; Marketing,,,,,,,,,10/12/2024 1:02,https://best-paper-award-ddck.dovetail.com/data/5gQurSHekkdsAKDznegZ9V#:v:h=6o8U35uRNEuFGFVvJPcRgv
AIAAIC1532,"Fifty female students at Bacchus Marsh Grammar school in Melbourne, Australia, were targeted with AI-generated fake nude images. The images which were shared on social media, appeared to have been created using AI to graft photos of the girls' faces obtained from their private social media accounts onto others' bodies.  The mother of one of the targeted students shared that her 16-year-old daughter vomited after seeing the ""incredibly graphic"" and ""mutilated"" images online. The school said it was working with police to remove the images from social media and determine if the perpetrator is a student or someone else.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,50 Melbourne school girls targeted using AI nude images,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/50-melbourne-school-girls-targeted-using-ai-nude-images,Incident,,2024,2024,Australia,Education,Bacchus Marsh Grammar students,,,Deepfake - image; Machine learning,,Police statement ,Ethics/values; Safety,Governance; Marketing,,,,,,,,,10/12/2024 1:02,https://best-paper-award-ddck.dovetail.com/data/5gQurSHekkdsAKDznegZ9V#:v:h=6o8U35uRNEuFGFVvJPcRgv
AIAAIC1209,"A complaint that ChatGPT had collected and disclosed personal information without consent led to an investigation by Canada's privacy watchdog. In April 2023, The Office of the Privacy Commissioner of Canada (OPC) announced it was investigating OpenAI in response to a complaint that ChatGPT had collected and disclosed personal information without consent. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Canada investigates ChatGPT privacy concerns,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/canada-investigates-chatgpt-privacy-concerns,Incident,2022,2023,2023,Canada,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy; Security,,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:00,https://best-paper-award-ddck.dovetail.com/data/4YKqP0hhpfYjI2fDqnkuso#:v:h=6uhU5XpzWAcrepsNm7XGY6
AIAAIC1209,"A complaint that ChatGPT had collected and disclosed personal information without consent led to an investigation by Canada's privacy watchdog. In April 2023, The Office of the Privacy Commissioner of Canada (OPC) announced it was investigating OpenAI in response to a complaint that ChatGPT had collected and disclosed personal information without consent. ",Incident - organization-driven - unauthorized data usage for AI model training,Incident Type,Canada investigates ChatGPT privacy concerns,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/canada-investigates-chatgpt-privacy-concerns,Incident,2022,2023,2023,Canada,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Privacy; Security,,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:00,https://best-paper-award-ddck.dovetail.com/data/4YKqP0hhpfYjI2fDqnkuso#:v:h=6uhU5XpzWAcrepsNm7XGY6
AIAAIC1067,"The image is thought to have been manipulated using Photoshop. In May 2023, Adobe announced it is incorporating generative AI into Photoshop with a new 'generative fill' tool that can be used to add or remove objects, change backgrounds and more. Labour",Cause - Human causes - Human abuse of AI tools,Cause,Rishi Sunak pulls pint deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/rishi-sunak-pulls-pint-deepfake,Incident,,2023,2023,UK,Politics,XCorp/xAI/Twitter,Adobe,Photoshop,Deepfake - image; Machine learning,Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,11/4/2024 15:56,https://best-paper-award-ddck.dovetail.com/data/76DqzQd426GplTUSmMoAlL#:v:h=6uIqUSXMb9Kx8D3IbdTHPk
AIAAIC1082,"However, Brazilian advertising regulator watchdog Conar announced it would investigate a possible breach of ethics after receiving complaints questioning whether it was right to use such methods 'to bring a deceased person back to life' on screen.",Cause - organization causes - poor business ethics,Cause,VW Brazil Elis Regina deepfake advert,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/vw-brazil-elis-regina-deepfake,Incident,,2023,2023,Brazil,Business/professional services,VW Brazil,AlmapBBDO,,"Deepfake - video, audio; Machine learning",Recreate singer,Product demonstration/release/launch,Legal; Ethics/values,Marketing,Manipulation,,,,,,Regulatory investigation,,10/30/2024 16:45,https://best-paper-award-ddck.dovetail.com/data/4xrumqLFjMvWJSTCIv8prm#:v:h=6v9Zx6HCXIgGeVES8UlANF
"AIAAIC1784
","In this instance, Dot appears to have attemped to exploit the availability of AI voice cloning technology to capitalise on Brownlee's influence and credibility.",Cause - organization causes - poor business ethics,Cause,Company uses Marques Brownlee AI voice clone to promote product without consent,,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/company-uses-marques-brownlee-ai-voice-clone-to-promote-product,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:08,https://best-paper-award-ddck.dovetail.com/data/281o35XZfVDBoPqfqlkVwq#:v:h=6xJH9fBEJe7C2tKgeewgju
AIAAIC1381,"The EAPD said it had received complaints against it's parent company Tools for Humanity for failing to provide people with sufficient information about the project, collecting data of minors, and the inability to people to withdraw their consent to process their data.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Spain suspends Worldcoin over privacy concerns,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/spain-suspends-worldcoin-over-privacy-concerns,Incident,2023,2024,2024,Spain,Banking/financial services,Tools for Humanity/Worldcoin,Tools for Humanity/Worldcoin,Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 19:44,https://best-paper-award-ddck.dovetail.com/data/2KvcGYwqmHB0goQ8GTNz3s#:v:h=6xSnPHHFj2Yb0lNYsqszgd
AIAAIC1065,The use of live facial recognition during Ireland-based budget airline Ryanair's external online booking process to verify the identities of its customers has been labelled 'invasive' and 'unjustified' in a legal complaint by privacy group NYOB.,Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Ryanair facial recognition customer verification,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ryanair-uses-facial-recognition-to-verify-customers,Incident,,2023,2023,Spain; EU,Aerospace/defence,Ryanair,,,Facial recognition; Computer vision; Machine learning,Verify customer identity,Legal complaint,Privacy,Privacy,Privacy loss,,,,,,Litigation,,10/7/2024 1:12,https://best-paper-award-ddck.dovetail.com/data/1KYigdpc4kgvDKm1ZMhHEK#:v:h=6zz3L4baT7AAdvhOlZVQC7
AIAAIC1065,The use of live facial recognition during Ireland-based budget airline Ryanair's external online booking process to verify the identities of its customers has been labelled 'invasive' and 'unjustified' in a legal complaint by privacy group NYOB.,Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Ryanair facial recognition customer verification,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ryanair-uses-facial-recognition-to-verify-customers,Incident,,2023,2023,Spain; EU,Aerospace/defence,Ryanair,,,Facial recognition; Computer vision; Machine learning,Verify customer identity,Legal complaint,Privacy,Privacy,Privacy loss,,,,,,Litigation,,10/7/2024 1:12,https://best-paper-award-ddck.dovetail.com/data/1KYigdpc4kgvDKm1ZMhHEK#:v:h=6zz3L4baT7AAdvhOlZVQC7
AIAAIC1196,"Poland's data protection authority the Urząd Ochrony Danych Osobowych (UODO) announced it was opening an investigation into OpenAI's ChatGPT for violating the privacy of Polish users. The announcement of the investigation comes after a complaint had accused OpenAI and ChatGPT of multiple breaches of the EU’s General Data Protection Regulation (GDPR), including processing 'data in an unlawful and unreliable manner' and in a non-transparent manner. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,Poland investigates ChatGPT for alleged privacy abuse,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/poland-investigates-chatgpt-alleged-privacy-abuse,Incident,2022,2023,2023,Poland,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance; Privacy,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:14,https://best-paper-award-ddck.dovetail.com/data/6MIgBLj98nrsZHmvhkHkHV#:v:h=6D7W5R2QcbliGXcdFTmpwI
AIAAIC1196,"Poland's data protection authority the Urząd Ochrony Danych Osobowych (UODO) announced it was opening an investigation into OpenAI's ChatGPT for violating the privacy of Polish users. The announcement of the investigation comes after a complaint had accused OpenAI and ChatGPT of multiple breaches of the EU’s General Data Protection Regulation (GDPR), including processing 'data in an unlawful and unreliable manner' and in a non-transparent manner. ",Cause - organization causes - legal non-compliance,Cause,Poland investigates ChatGPT for alleged privacy abuse,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/poland-investigates-chatgpt-alleged-privacy-abuse,Incident,2022,2023,2023,Poland,Multiple,OpenAI,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,Regulatory inquiry/investigation,Privacy,Governance; Privacy,Privacy loss,,,,,,Regulatory investigation,,10/7/2024 0:14,https://best-paper-award-ddck.dovetail.com/data/6MIgBLj98nrsZHmvhkHkHV#:v:h=6D7W5R2QcbliGXcdFTmpwI
AIAAIC1019,"The photograph and report, which have since been deleted, had quickly gone viral on Twitter and were retweeted by high-profile Twitter Russian news account @RT and @DeItaone.",Cause - Lack of AI control,Cause,Pentagon deepfake 'explosion' jitters US stock market,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pentagon-deepfake-explosion,Incident,,2023,2023,USA,Govt - defence,X Corp/Twitter,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,,Mis/disinformation,Governance; Marketing,,Stock market price fall,,,,,,,10/30/2024 17:36,https://best-paper-award-ddck.dovetail.com/data/35vWwsC8yBttpuxC7vKuxO#:v:h=6EDn4x2vnvb5MtnlvVxvHg
AIAAIC1019,"The photograph and report, which have since been deleted, had quickly gone viral on Twitter and were retweeted by high-profile Twitter Russian news account @RT and @DeItaone.",Incident - human-driven - Public entity amplified of misleading content,Incident Type,Pentagon deepfake 'explosion' jitters US stock market,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pentagon-deepfake-explosion,Incident,,2023,2023,USA,Govt - defence,X Corp/Twitter,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,,Mis/disinformation,Governance; Marketing,,Stock market price fall,,,,,,,10/30/2024 17:36,https://best-paper-award-ddck.dovetail.com/data/35vWwsC8yBttpuxC7vKuxO#:v:h=6EDn4x2vnvb5MtnlvVxvHg
AIAAIC1254,"A Tesla whistleblower leaked 100GB of sensitive company data, including thousands of complaints about the safety of the company's self-driving system, including sudden acceleration or phantom braking. Whistleblower Lukasz Krupski, an ex-employee at Telsa's Norwegian unit, leaked 100 GB of internal communications, employee personal data, customer complaints, and accident reports involving Tesla's braking and self-driving software, to German business newspaper Handelsblatt in May 2023.  Krupski later told the BBC that he felt the carmaker's Autopilot driver assistance system was not safe for public roads, with other drivers, passengers, and pedestrians at risk. He also said that his colleagues had discussed Tesla vehicles randomly braking in response to non-existent obstacles, a phenonomen known as 'phantom braking', with some incidents resulting in crashes with oncoming traffic.",Cause - organization causes - poor business ethics,Cause,Whistleblower reveals Tesla phantom braking complaints,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/whistleblower-reveals-tesla-phantom-braking-complaints,Incident,2014,2023,2023,Netherlands; Germany,Automotive,Lukasz Krupski,Tesla,Autopilot,Driver assistance system,"Automate steering, acceleration, braking",Data leak; Whistleblower,Confidentiality; Privacy; Safety; Security,Governance,Privacy loss; Confidentiality loss,,,,,,Regulatory investigation,,10/4/2024 11:29,https://best-paper-award-ddck.dovetail.com/data/4DasqRusymkPLKKFZIW8MS#:v:h=6FCge0DgZT2d5SGW1qVHiM
"AIAAIC1788
","A New Zealand pensioner lost NZD 224,000 (approximately USD 140,000) in a deepfake scam featuring Prime Minister Christopher Luxon. What happened The fraudsters used advanced AI technology to create a realistic-looking video advertisement of Luxon encouraging pesnioners to invest in Bitcoin, which led Jill Creasy, 72, to believe she was engaging in legitimate financial transactions. After responding to the ad, Creasy was contacted by a Greek national calling himself Adam Manolas who claimed to be a Terma Group investment adviser based in Manchester, UK.  Manolas explained how the investment worked then sent Creasy software called AnyDesk, which gave him remote access to her computer. Using her email, he set up accounts under her name at crypto exchange platforms Easy Crypto and Binance, before instructing her to log in to her TSB internet banking account. She then watched as he transferred several payments over the next 26 days to purchase Bitcoin from Easy Crypto. Most of the payments were for NZD 20,000 - her daily transfer limit with TSB.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"Pensioner loses NZD 224,000 to deepfake scam",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pensioner-loses-nzd-224000-to-deepfake-scam,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:01,https://best-paper-award-ddck.dovetail.com/data/2ZOAjWwPQtEjv3sKuAiOJ#:v:h=6HNONjzC8si7kawqUZ4xZg
"AIAAIC1788
","A New Zealand pensioner lost NZD 224,000 (approximately USD 140,000) in a deepfake scam featuring Prime Minister Christopher Luxon. What happened The fraudsters used advanced AI technology to create a realistic-looking video advertisement of Luxon encouraging pesnioners to invest in Bitcoin, which led Jill Creasy, 72, to believe she was engaging in legitimate financial transactions. After responding to the ad, Creasy was contacted by a Greek national calling himself Adam Manolas who claimed to be a Terma Group investment adviser based in Manchester, UK.  Manolas explained how the investment worked then sent Creasy software called AnyDesk, which gave him remote access to her computer. Using her email, he set up accounts under her name at crypto exchange platforms Easy Crypto and Binance, before instructing her to log in to her TSB internet banking account. She then watched as he transferred several payments over the next 26 days to purchase Bitcoin from Easy Crypto. Most of the payments were for NZD 20,000 - her daily transfer limit with TSB.",Cause - Human causes - Human abuse of AI tools,Cause,"Pensioner loses NZD 224,000 to deepfake scam",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pensioner-loses-nzd-224000-to-deepfake-scam,,,,,,,,,,,,,,,,,,,,,,,10/31/2024 11:01,https://best-paper-award-ddck.dovetail.com/data/2ZOAjWwPQtEjv3sKuAiOJ#:v:h=6HNONjzC8si7kawqUZ4xZg
AIAAIC0213,"Controversial podcaster Joe Rogan had his identity stolen and deepfaked in a video ad to push Alpha Grind, a male enhancement product that markets itself as 'For Men with the Highest Expectations'. The video clip, which shows Rogan discussing Alpha Grind with guest Professor Andrew D. Huberman on The Joe Rogan Experience podcast, sparked uproar on Twitter, with people noting that it is illegal to steal someone's identity to promote a product using AI.",Incident - organization-driven - problematic AI implementation,Incident Type,Joe Rogan libido booster Alpha Grind deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/joe-rogan-libido-booster-alpha-grind-ad-deepfake,Incident,,2023,2023,USA,Health,,,,Deepfake - video; Machine learning,Sell product,,Mis/disinformation,Governance,,,,,,,,,10/30/2024 19:38,https://best-paper-award-ddck.dovetail.com/data/2aXTMJed5UVJNZuDZnRNKs#:v:h=6Jysg6nBzQ8Y2cNitl09SD
AIAAIC0213,"Controversial podcaster Joe Rogan had his identity stolen and deepfaked in a video ad to push Alpha Grind, a male enhancement product that markets itself as 'For Men with the Highest Expectations'. The video clip, which shows Rogan discussing Alpha Grind with guest Professor Andrew D. Huberman on The Joe Rogan Experience podcast, sparked uproar on Twitter, with people noting that it is illegal to steal someone's identity to promote a product using AI.",Cause - organization causes - poor business ethics,Cause,Joe Rogan libido booster Alpha Grind deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/joe-rogan-libido-booster-alpha-grind-ad-deepfake,Incident,,2023,2023,USA,Health,,,,Deepfake - video; Machine learning,Sell product,,Mis/disinformation,Governance,,,,,,,,,10/30/2024 19:38,https://best-paper-award-ddck.dovetail.com/data/2aXTMJed5UVJNZuDZnRNKs#:v:h=6Jysg6nBzQ8Y2cNitl09SD
AIAAIC0213,"Controversial podcaster Joe Rogan had his identity stolen and deepfaked in a video ad to push Alpha Grind, a male enhancement product that markets itself as 'For Men with the Highest Expectations'. The video clip, which shows Rogan discussing Alpha Grind with guest Professor Andrew D. Huberman on The Joe Rogan Experience podcast, sparked uproar on Twitter, with people noting that it is illegal to steal someone's identity to promote a product using AI.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Joe Rogan libido booster Alpha Grind deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/joe-rogan-libido-booster-alpha-grind-ad-deepfake,Incident,,2023,2023,USA,Health,,,,Deepfake - video; Machine learning,Sell product,,Mis/disinformation,Governance,,,,,,,,,10/30/2024 19:38,https://best-paper-award-ddck.dovetail.com/data/2aXTMJed5UVJNZuDZnRNKs#:v:h=6Jysg6nBzQ8Y2cNitl09SD
AIAAIC0213,"Controversial podcaster Joe Rogan had his identity stolen and deepfaked in a video ad to push Alpha Grind, a male enhancement product that markets itself as 'For Men with the Highest Expectations'. The video clip, which shows Rogan discussing Alpha Grind with guest Professor Andrew D. Huberman on The Joe Rogan Experience podcast, sparked uproar on Twitter, with people noting that it is illegal to steal someone's identity to promote a product using AI.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Joe Rogan libido booster Alpha Grind deepfake,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/joe-rogan-libido-booster-alpha-grind-ad-deepfake,Incident,,2023,2023,USA,Health,,,,Deepfake - video; Machine learning,Sell product,,Mis/disinformation,Governance,,,,,,,,,10/30/2024 19:38,https://best-paper-award-ddck.dovetail.com/data/2aXTMJed5UVJNZuDZnRNKs#:v:h=6Jysg6nBzQ8Y2cNitl09SD
AIAAIC1452,"A Maori woman was misidentified by a facial recognition system at a supermarket in New Zealand, accused of being a shoplifter and thrown out.  Te Ani Solomon was misidentified as a trespassed 'thief' by the AI system at a Foodstuffs supermarket in Rotorua, New Zealand, and accosted by staff who accused her of being a shoplifter and insisted she leave, even after she had offered three forms of photo identification. ",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Maori woman misidentified by Foodstuffs facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maori-woman-misidentified-by-foodstuffs-facial-recognition,Incident,,2024,2024,New Zealand,Retail,Foodstuffs,,,Facial recognition,Strengthen security,User comments/complaints,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance,Anxiety/distress; Discrimination,Privacy loss,,,,,,,10/2/2024 13:42,https://best-paper-award-ddck.dovetail.com/data/5EmDnTMZeDZBnXvKlld52n#:v:h=6Les1bYVcLtxw5JRXgkAgK
AIAAIC1452,"A Maori woman was misidentified by a facial recognition system at a supermarket in New Zealand, accused of being a shoplifter and thrown out.  Te Ani Solomon was misidentified as a trespassed 'thief' by the AI system at a Foodstuffs supermarket in Rotorua, New Zealand, and accosted by staff who accused her of being a shoplifter and insisted she leave, even after she had offered three forms of photo identification. ",Entity - AI algorithm,Responsible Entities,Maori woman misidentified by Foodstuffs facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maori-woman-misidentified-by-foodstuffs-facial-recognition,Incident,,2024,2024,New Zealand,Retail,Foodstuffs,,,Facial recognition,Strengthen security,User comments/complaints,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance,Anxiety/distress; Discrimination,Privacy loss,,,,,,,10/2/2024 13:42,https://best-paper-award-ddck.dovetail.com/data/5EmDnTMZeDZBnXvKlld52n#:v:h=6Les1bYVcLtxw5JRXgkAgK
AIAAIC1452,"A Maori woman was misidentified by a facial recognition system at a supermarket in New Zealand, accused of being a shoplifter and thrown out.  Te Ani Solomon was misidentified as a trespassed 'thief' by the AI system at a Foodstuffs supermarket in Rotorua, New Zealand, and accosted by staff who accused her of being a shoplifter and insisted she leave, even after she had offered three forms of photo identification. ",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Maori woman misidentified by Foodstuffs facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maori-woman-misidentified-by-foodstuffs-facial-recognition,Incident,,2024,2024,New Zealand,Retail,Foodstuffs,,,Facial recognition,Strengthen security,User comments/complaints,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance,Anxiety/distress; Discrimination,Privacy loss,,,,,,,10/2/2024 13:42,https://best-paper-award-ddck.dovetail.com/data/5EmDnTMZeDZBnXvKlld52n#:v:h=6Les1bYVcLtxw5JRXgkAgK
AIAAIC1354,"Public service provider Serco Leisure, Serco Jersey and seven associated community leisure trusts were ordered to stop using facial recognition technology and fingerprint scanning to monitor employee attendance. An investigation by the UK's Information Commissioner's Office found that Serco Leisure and the trusts had been unlawfully processing the biometric data of more than 2,000 employees at 38 leisure facilities for the purpose of attendance checks and subsequent payment for their time.  The ICO said Serco and the trusts failed to show why it is necessary or proportionate to use facial recognition and fingerprint scanning for this purpose, when there are less intrusive means available such as ID cards or fobs. It also said that employees had not been proactively offered an alternative to having their faces and fingers scanned to clock in and out of their place of work, and that it had been presented as a requirement in order to get paid. 'Due to the imbalance of power between Serco Leisure and its employees, it is unlikely that they would feel able to say no to the collection and use of their biometric data for attendance checks,' the ICO argued.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Serco ordered to halt using facial recognition to monitor employees,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/serco-ordered-to-halt-using-facial-recognition-to-monitor-employees,Incident,,2024,2024,UK,Tourism/leisure,Serco Leisure,,,Facial recognition;  Fingerprint scanning,Monitor employees,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 19:54,https://best-paper-award-ddck.dovetail.com/data/2Zs6cxsxdrdd9ZHUvJXnSm#:v:h=6NpuTLlZb9DHQKWWkP8uFg
AIAAIC1354,"Public service provider Serco Leisure, Serco Jersey and seven associated community leisure trusts were ordered to stop using facial recognition technology and fingerprint scanning to monitor employee attendance. An investigation by the UK's Information Commissioner's Office found that Serco Leisure and the trusts had been unlawfully processing the biometric data of more than 2,000 employees at 38 leisure facilities for the purpose of attendance checks and subsequent payment for their time.  The ICO said Serco and the trusts failed to show why it is necessary or proportionate to use facial recognition and fingerprint scanning for this purpose, when there are less intrusive means available such as ID cards or fobs. It also said that employees had not been proactively offered an alternative to having their faces and fingers scanned to clock in and out of their place of work, and that it had been presented as a requirement in order to get paid. 'Due to the imbalance of power between Serco Leisure and its employees, it is unlikely that they would feel able to say no to the collection and use of their biometric data for attendance checks,' the ICO argued.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Serco ordered to halt using facial recognition to monitor employees,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/serco-ordered-to-halt-using-facial-recognition-to-monitor-employees,Incident,,2024,2024,UK,Tourism/leisure,Serco Leisure,,,Facial recognition;  Fingerprint scanning,Monitor employees,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 19:54,https://best-paper-award-ddck.dovetail.com/data/2Zs6cxsxdrdd9ZHUvJXnSm#:v:h=6NpuTLlZb9DHQKWWkP8uFg
AIAAIC1354,"Public service provider Serco Leisure, Serco Jersey and seven associated community leisure trusts were ordered to stop using facial recognition technology and fingerprint scanning to monitor employee attendance. An investigation by the UK's Information Commissioner's Office found that Serco Leisure and the trusts had been unlawfully processing the biometric data of more than 2,000 employees at 38 leisure facilities for the purpose of attendance checks and subsequent payment for their time.  The ICO said Serco and the trusts failed to show why it is necessary or proportionate to use facial recognition and fingerprint scanning for this purpose, when there are less intrusive means available such as ID cards or fobs. It also said that employees had not been proactively offered an alternative to having their faces and fingers scanned to clock in and out of their place of work, and that it had been presented as a requirement in order to get paid. 'Due to the imbalance of power between Serco Leisure and its employees, it is unlikely that they would feel able to say no to the collection and use of their biometric data for attendance checks,' the ICO argued.",Cause - organization causes - legal non-compliance,Cause,Serco ordered to halt using facial recognition to monitor employees,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/serco-ordered-to-halt-using-facial-recognition-to-monitor-employees,Incident,,2024,2024,UK,Tourism/leisure,Serco Leisure,,,Facial recognition;  Fingerprint scanning,Monitor employees,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 19:54,https://best-paper-award-ddck.dovetail.com/data/2Zs6cxsxdrdd9ZHUvJXnSm#:v:h=6NpuTLlZb9DHQKWWkP8uFg
AIAAIC1447,"US congress member Alexandria Ocasio-Cortez, also known as AOC, said she was the victim of a deepfake video that depicted her in sexually explicit acts.  Ocasio-Cortez, a survivor of physical sexual assault, opened up about the shock she felt upon seeing a video of herself online that others could perceive as real in an interview with Rolling Stone. She explained that the mental image of the deepfake version of herself performing sexual acts was deeply disturbing and resurfaced trauma","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Alexandria Ocasio-Cortez depicted as deepfake pornstar,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/alexandria-ocasio-cortez-depicted-as-deepfake-pornstar,Incident,,2024,2024,USA,Politics,,,,Deepfake - image; Machine learning,Damage reputation,Research study/report,Ethics/values; Mis/disinformation; Safety,Governance; Marketing,Anxiety/distress; Trauma,,,,,,,,10/24/2024 20:58,https://best-paper-award-ddck.dovetail.com/data/4U8Zts0o6OVXkHBAOpQVUN#:v:h=6NT844Az8VMMuBxuHLQLfY
AIAAIC1447,"US congress member Alexandria Ocasio-Cortez, also known as AOC, said she was the victim of a deepfake video that depicted her in sexually explicit acts.  Ocasio-Cortez, a survivor of physical sexual assault, opened up about the shock she felt upon seeing a video of herself online that others could perceive as real in an interview with Rolling Stone. She explained that the mental image of the deepfake version of herself performing sexual acts was deeply disturbing and resurfaced trauma",Entity - no specific info,Responsible Entities,Alexandria Ocasio-Cortez depicted as deepfake pornstar,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/alexandria-ocasio-cortez-depicted-as-deepfake-pornstar,Incident,,2024,2024,USA,Politics,,,,Deepfake - image; Machine learning,Damage reputation,Research study/report,Ethics/values; Mis/disinformation; Safety,Governance; Marketing,Anxiety/distress; Trauma,,,,,,,,10/24/2024 20:58,https://best-paper-award-ddck.dovetail.com/data/4U8Zts0o6OVXkHBAOpQVUN#:v:h=6NT844Az8VMMuBxuHLQLfY
AIAAIC1447,"US congress member Alexandria Ocasio-Cortez, also known as AOC, said she was the victim of a deepfake video that depicted her in sexually explicit acts.  Ocasio-Cortez, a survivor of physical sexual assault, opened up about the shock she felt upon seeing a video of herself online that others could perceive as real in an interview with Rolling Stone. She explained that the mental image of the deepfake version of herself performing sexual acts was deeply disturbing and resurfaced trauma",Cause - no specific info,Cause,Alexandria Ocasio-Cortez depicted as deepfake pornstar,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/alexandria-ocasio-cortez-depicted-as-deepfake-pornstar,Incident,,2024,2024,USA,Politics,,,,Deepfake - image; Machine learning,Damage reputation,Research study/report,Ethics/values; Mis/disinformation; Safety,Governance; Marketing,Anxiety/distress; Trauma,,,,,,,,10/24/2024 20:58,https://best-paper-award-ddck.dovetail.com/data/4U8Zts0o6OVXkHBAOpQVUN#:v:h=6NT844Az8VMMuBxuHLQLfY
AIAAIC1628,"Meta (formerly Facebook) agreed to pay a USD 1.4 billion fine to settle a lawsuit with the state of Texas over allegations of illegally collecting biometric data using facial recognition.  In a lawsuit filed by Texas Attorney General Ken Paxton in 2022, Meta was accused of collecting biometric data, specifically facial recognition data, from millions of users without obtaining their informed consent, which is required under Texas law.  Meta agreed to settle the lawsuit by paying USD 1.4 billion, marking the largest privacy settlement ever obtained by a US state attorney general. The lawsuit had claimed that Meta breached the Texas Capture or Use of Biometric Identifier Act, which prohibits private entities from capturing, disclosing, or profiting from biometric identifiers without informed consent.  Meta was also alleged to have violated the Deceptive Trade Practices and Consumer Protection Act by implementing facial-recognition-based photo and video tagging features without proper user consent.",Entity - AI developer company,Responsible Entities,Meta fined USD 1.4 billion for unlawful use of facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-fined-usd-1-4-billion-for-unlawful-use-of-facial-recognition,Incident,2011,2024,2024,USA,Multiple,Facebook,Facebook,Tag Suggestions,Facial recognition,Suggest friends to tag,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,USD 1.4 billion fine,,,9/26/2024 23:26,https://best-paper-award-ddck.dovetail.com/data/3AyRCN3DLU7NFXKNk0ruiR#:v:h=6QDmZTbmK8cSC2DPY03EfS
AIAAIC1628,"Meta (formerly Facebook) agreed to pay a USD 1.4 billion fine to settle a lawsuit with the state of Texas over allegations of illegally collecting biometric data using facial recognition.  In a lawsuit filed by Texas Attorney General Ken Paxton in 2022, Meta was accused of collecting biometric data, specifically facial recognition data, from millions of users without obtaining their informed consent, which is required under Texas law.  Meta agreed to settle the lawsuit by paying USD 1.4 billion, marking the largest privacy settlement ever obtained by a US state attorney general. The lawsuit had claimed that Meta breached the Texas Capture or Use of Biometric Identifier Act, which prohibits private entities from capturing, disclosing, or profiting from biometric identifiers without informed consent.  Meta was also alleged to have violated the Deceptive Trade Practices and Consumer Protection Act by implementing facial-recognition-based photo and video tagging features without proper user consent.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Meta fined USD 1.4 billion for unlawful use of facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-fined-usd-1-4-billion-for-unlawful-use-of-facial-recognition,Incident,2011,2024,2024,USA,Multiple,Facebook,Facebook,Tag Suggestions,Facial recognition,Suggest friends to tag,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,USD 1.4 billion fine,,,9/26/2024 23:26,https://best-paper-award-ddck.dovetail.com/data/3AyRCN3DLU7NFXKNk0ruiR#:v:h=6QDmZTbmK8cSC2DPY03EfS
AIAAIC1628,"Meta (formerly Facebook) agreed to pay a USD 1.4 billion fine to settle a lawsuit with the state of Texas over allegations of illegally collecting biometric data using facial recognition.  In a lawsuit filed by Texas Attorney General Ken Paxton in 2022, Meta was accused of collecting biometric data, specifically facial recognition data, from millions of users without obtaining their informed consent, which is required under Texas law.  Meta agreed to settle the lawsuit by paying USD 1.4 billion, marking the largest privacy settlement ever obtained by a US state attorney general. The lawsuit had claimed that Meta breached the Texas Capture or Use of Biometric Identifier Act, which prohibits private entities from capturing, disclosing, or profiting from biometric identifiers without informed consent.  Meta was also alleged to have violated the Deceptive Trade Practices and Consumer Protection Act by implementing facial-recognition-based photo and video tagging features without proper user consent.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Meta fined USD 1.4 billion for unlawful use of facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-fined-usd-1-4-billion-for-unlawful-use-of-facial-recognition,Incident,2011,2024,2024,USA,Multiple,Facebook,Facebook,Tag Suggestions,Facial recognition,Suggest friends to tag,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,USD 1.4 billion fine,,,9/26/2024 23:26,https://best-paper-award-ddck.dovetail.com/data/3AyRCN3DLU7NFXKNk0ruiR#:v:h=6QDmZTbmK8cSC2DPY03EfS
AIAAIC1628,"Meta (formerly Facebook) agreed to pay a USD 1.4 billion fine to settle a lawsuit with the state of Texas over allegations of illegally collecting biometric data using facial recognition.  In a lawsuit filed by Texas Attorney General Ken Paxton in 2022, Meta was accused of collecting biometric data, specifically facial recognition data, from millions of users without obtaining their informed consent, which is required under Texas law.  Meta agreed to settle the lawsuit by paying USD 1.4 billion, marking the largest privacy settlement ever obtained by a US state attorney general. The lawsuit had claimed that Meta breached the Texas Capture or Use of Biometric Identifier Act, which prohibits private entities from capturing, disclosing, or profiting from biometric identifiers without informed consent.  Meta was also alleged to have violated the Deceptive Trade Practices and Consumer Protection Act by implementing facial-recognition-based photo and video tagging features without proper user consent.",Cause - organization causes - legal non-compliance,Cause,Meta fined USD 1.4 billion for unlawful use of facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/meta-fined-usd-1-4-billion-for-unlawful-use-of-facial-recognition,Incident,2011,2024,2024,USA,Multiple,Facebook,Facebook,Tag Suggestions,Facial recognition,Suggest friends to tag,Lawsuit filing/litigation,Privacy,Governance,Privacy loss,,,,,USD 1.4 billion fine,,,9/26/2024 23:26,https://best-paper-award-ddck.dovetail.com/data/3AyRCN3DLU7NFXKNk0ruiR#:v:h=6QDmZTbmK8cSC2DPY03EfS
AIAAIC1684,"A plan by the US Department of Homeland Security (DHS) to use facial recognition technology to scan the faces of migrant children sparkedcontroversy. Part of a larger effort to use AI to improve border security, the plan involves collecting and analysing facial recognition data from migrant children as young as 14 years old totrain an AI system to identify and track individuals, including migrants, at the border. Critics argue that the plan raises serious concerns about privacy, civil liberties, and the potential for bias in the AI system, specifically:  The use of facial recognition technology on children, who may not fully understand the implications of the technology",Entity - government authorities that adopt AI,Responsible Entities,US plan to train AI system by scanning migrants' kids faces prompts controversy,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/us-plans-to-train-ai-system-by-scanning-migrants-kids-faces,Issue,,2024,2024,USA,Govt - immigration,Department of Homeland Security (DHS),,,Facial recognition,Train AI systems,,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 22:54,https://best-paper-award-ddck.dovetail.com/data/52nVgSbgvAMYokd9QLPhBw#:v:h=6SmntN8e4W43wtXjHohAgv
AIAAIC1178,"According to the watchdog said 'There is actually no age verification mechanism in place: no gating mechanism for children, no blocking of the app if a user declares that they are underage.'",Entity - AI developer company,Responsible Entities,Replika hit with data ban in Italy over child safety,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/replika-hit-with-data-ban-in-italy-over-child-safety,Incident,2017,2023,2023,Italy,Media/entertainment/sports/arts,,Luka Inc,Replika,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Provide companionship,Regulatory ban,Safety; Privacy,Governance,Privacy loss,,,,,,Regulatory ban,,10/7/2024 0:28,https://best-paper-award-ddck.dovetail.com/data/6YwwYgh9liy2qG7Fp8E16x#:v:h=6TKxibgrjdroEkZBB9ItQc
AIAAIC1193,"Doctors in Australia using ChatGPT to write medical notes, which were then uploaded to patient record systems, were ordered to stop by their CEO. An email shared with ABC showed that doctors at Perth's South Metropolitan Health Service (SMHS) had been using software such as ChatGPT to write medical notes which were then being uploaded to patient record systems, thereby potentially compromising patient confidentiality and privacy. The incident resulted in the hospital group's CEO ordering staff across the health service's five hospitals not to use AI chatbots. ""Crucially, at this stage, there is no assurance of patient confidentiality when using AI bot technology, such as ChatGPT, nor do we fully understand the security risks,' warned SMHS chief executive, Paul Forden",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Perth doctors warned for using ChatGPT to write patient medical records,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/perth-doctors-warned-for-using-chatgpt-to-write-patient-medical-records,Issue,2022,2023,2023,Australia,Health,South Metropolitan Health Service,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Write patient records,Company statement,Confidentiality; Privacy,Governance,Confidentiality loss,,,,,,,,10/7/2024 0:17,https://best-paper-award-ddck.dovetail.com/data/6v4ELfD3haz2FLoQkudyuE#:v:h=6WYAYOmRDM1BU8pKHVF4sl
AIAAIC1193,"Doctors in Australia using ChatGPT to write medical notes, which were then uploaded to patient record systems, were ordered to stop by their CEO. An email shared with ABC showed that doctors at Perth's South Metropolitan Health Service (SMHS) had been using software such as ChatGPT to write medical notes which were then being uploaded to patient record systems, thereby potentially compromising patient confidentiality and privacy. The incident resulted in the hospital group's CEO ordering staff across the health service's five hospitals not to use AI chatbots. ""Crucially, at this stage, there is no assurance of patient confidentiality when using AI bot technology, such as ChatGPT, nor do we fully understand the security risks,' warned SMHS chief executive, Paul Forden",Cause - Human causes - Undertrusting AI,Cause,Perth doctors warned for using ChatGPT to write patient medical records,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/perth-doctors-warned-for-using-chatgpt-to-write-patient-medical-records,Issue,2022,2023,2023,Australia,Health,South Metropolitan Health Service,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Write patient records,Company statement,Confidentiality; Privacy,Governance,Confidentiality loss,,,,,,,,10/7/2024 0:17,https://best-paper-award-ddck.dovetail.com/data/6v4ELfD3haz2FLoQkudyuE#:v:h=6WYAYOmRDM1BU8pKHVF4sl
AIAAIC1325,"The CNI also took issue with Amazon's transparency, or lack thereof. Before April 2020, temporary workers had not been informed before their data was collected, and employees were not properly told about video surveillance systems.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Amazon France fined for excessive automated monitoring of workers,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/amazon-france-fined-for-excessive-automated-monitoring-of-workers,Incident,,2020,2024,France,Transport/logistics,Amazon France Logistique,Amazon France,"Stow Machine Gun indicator; Idle Time indicator, Latency under ten minutes indicator",Handheld scanner,Monitor employee performance,Regulatory inquiry/investigation,Employment; Necessity/proportionality; Privacy,Governance; Marketing,Privacy loss,,,,,EUR 32 million fine,Regulatory investigation,,10/2/2024 20:15,https://best-paper-award-ddck.dovetail.com/data/5XKzZRCbZ9Dzw1Zm8U8bJ1#:v:h=6Y1rnYvB1bKSAkFTrhf2Ih
AIAAIC1475,"BBC presenter's image was used in an ad campaign without her consent after an AI deepfake of her voice was used by a scammer to negotiate the deal.  Insect repellant company Incognito was tricked into believing it was speaking to BBC science presenter, Liz Bonnin, through a series of voice messages and a Facebook profile allegedly purporting Bonnin's identity. The deal was in fact negotiated between a scammer and Incognito CEO Howard Carter via email and Whatsapp voice messages. Incognito paid the scammer £20,000, believing it to be Bonnin.",Cause - Human causes - Human abuse of AI tools,Cause,BBC presenter’s AI-generated voice used to trick company,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bbc-presenters-ai-generated-voice-used-to-trick-company,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - audio; Machine learning,Generate voice,Industry complaint,Personality rights; Fraud,Governance,"Personality rights loss; Financial loss, Reputational damage",,,,,,,,10/24/2024 20:50,https://best-paper-award-ddck.dovetail.com/data/4WS0rej2Iwr1auLWYV7U4C#:v:h=6ZPcUcQzxYTze8jHaSgKps
AIAAIC1475,"BBC presenter's image was used in an ad campaign without her consent after an AI deepfake of her voice was used by a scammer to negotiate the deal.  Insect repellant company Incognito was tricked into believing it was speaking to BBC science presenter, Liz Bonnin, through a series of voice messages and a Facebook profile allegedly purporting Bonnin's identity. The deal was in fact negotiated between a scammer and Incognito CEO Howard Carter via email and Whatsapp voice messages. Incognito paid the scammer £20,000, believing it to be Bonnin.",Cause - organization/human cause - lack of informed consent & transparency,Cause,BBC presenter’s AI-generated voice used to trick company,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bbc-presenters-ai-generated-voice-used-to-trick-company,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - audio; Machine learning,Generate voice,Industry complaint,Personality rights; Fraud,Governance,"Personality rights loss; Financial loss, Reputational damage",,,,,,,,10/24/2024 20:50,https://best-paper-award-ddck.dovetail.com/data/4WS0rej2Iwr1auLWYV7U4C#:v:h=6ZPcUcQzxYTze8jHaSgKps
AIAAIC1475,"BBC presenter's image was used in an ad campaign without her consent after an AI deepfake of her voice was used by a scammer to negotiate the deal.  Insect repellant company Incognito was tricked into believing it was speaking to BBC science presenter, Liz Bonnin, through a series of voice messages and a Facebook profile allegedly purporting Bonnin's identity. The deal was in fact negotiated between a scammer and Incognito CEO Howard Carter via email and Whatsapp voice messages. Incognito paid the scammer £20,000, believing it to be Bonnin.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,BBC presenter’s AI-generated voice used to trick company,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bbc-presenters-ai-generated-voice-used-to-trick-company,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - audio; Machine learning,Generate voice,Industry complaint,Personality rights; Fraud,Governance,"Personality rights loss; Financial loss, Reputational damage",,,,,,,,10/24/2024 20:50,https://best-paper-award-ddck.dovetail.com/data/4WS0rej2Iwr1auLWYV7U4C#:v:h=6ZPcUcQzxYTze8jHaSgKps
AIAAIC1475,"BBC presenter's image was used in an ad campaign without her consent after an AI deepfake of her voice was used by a scammer to negotiate the deal.  Insect repellant company Incognito was tricked into believing it was speaking to BBC science presenter, Liz Bonnin, through a series of voice messages and a Facebook profile allegedly purporting Bonnin's identity. The deal was in fact negotiated between a scammer and Incognito CEO Howard Carter via email and Whatsapp voice messages. Incognito paid the scammer £20,000, believing it to be Bonnin.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,BBC presenter’s AI-generated voice used to trick company,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/bbc-presenters-ai-generated-voice-used-to-trick-company,Incident,,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - audio; Machine learning,Generate voice,Industry complaint,Personality rights; Fraud,Governance,"Personality rights loss; Financial loss, Reputational damage",,,,,,,,10/24/2024 20:50,https://best-paper-award-ddck.dovetail.com/data/4WS0rej2Iwr1auLWYV7U4C#:v:h=6ZPcUcQzxYTze8jHaSgKps
AIAAIC1166,"Girls at Westfield High School in New Jersey, USA, were subjected to fake nude images of them being shared among other students, sparking uproar and prompting a police investigation. Male classmates reputedly used girls' photos found online to concoct and circulate AI-generated pornographic images of female students as young as 14 years old in group chats. One victim told the Wall Street Journal, 'We're aware that there are creepy guys out there but you'd never think one of your classmates would violate you like this.'  ",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,Westfield High School non-concensual nude deepfakes,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/westfield-high-school-non-concensual-nude-deepfakes,Incident,,2023,2023,USA,Education,Westfield High School students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,Police investigation,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/24/2024 21:30,https://best-paper-award-ddck.dovetail.com/data/7lCkwKfvJsjHwYaeuKWjwU#:v:h=711tY97brgngyQe0lmYHwq
AIAAIC1166,"Girls at Westfield High School in New Jersey, USA, were subjected to fake nude images of them being shared among other students, sparking uproar and prompting a police investigation. Male classmates reputedly used girls' photos found online to concoct and circulate AI-generated pornographic images of female students as young as 14 years old in group chats. One victim told the Wall Street Journal, 'We're aware that there are creepy guys out there but you'd never think one of your classmates would violate you like this.'  ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Westfield High School non-concensual nude deepfakes,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/westfield-high-school-non-concensual-nude-deepfakes,Incident,,2023,2023,USA,Education,Westfield High School students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,Police investigation,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/24/2024 21:30,https://best-paper-award-ddck.dovetail.com/data/7lCkwKfvJsjHwYaeuKWjwU#:v:h=711tY97brgngyQe0lmYHwq
AIAAIC1452,"Te Ani Solomon was misidentified as a trespassed 'thief' by the AI system at a Foodstuffs supermarket in Rotorua, New Zealand, and accosted by staff who accused her of being a shoplifter and insisted she leave, even after she had offered three forms of photo identification. ",Cause - human causes - Overtrusting AI,Cause,Maori woman misidentified by Foodstuffs facial recognition,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/maori-woman-misidentified-by-foodstuffs-facial-recognition,Incident,,2024,2024,New Zealand,Retail,Foodstuffs,,,Facial recognition,Strengthen security,User comments/complaints,"Accuracy/reliability; Bias/discrimination - race, ethnicity; Privacy",Governance,Anxiety/distress; Discrimination,Privacy loss,,,,,,,10/4/2024 13:40,https://best-paper-award-ddck.dovetail.com/data/5EmDnTMZeDZBnXvKlld52n#:v:h=712ayZ7DZ5IC0wQ1fb4yPK
AIAAIC1604,"A school was reprimanded by the UK data pricacy watchdog over its use of facial recognition to process cashless payments i  its canteen.  Chelmer Valley High School in Chelmsford, Essex, implemented the technology in March 2023 without first conducting a data protection impact assessment (DPIA) or obtaining explicit consent from students and parents, according to the Information Commissioner's Office.   A DPIA is required under the UK General Data Protection Regulation (UK GDPR). The school's DPIA was only completed in November 2023, months after the technology had been in use. The school has also sent a letter to parents in March 2023 allowing them to opt-out their children but did not seek explicit consent, assuming approval by default. This approach was deemed invalid by the ICO, as consent must be an affirmative action. The ICO highlighted that most students were old enough to provide their own consent, and the parental opt-out system limited their ability to exercise their rights and freedoms regarding their biometric data. The regulator recommended that the school improve its data protection practices, including conducting thorough DPIAs and obtaining explicit opt-in consent from students.  The ICO's reprimand serves as a reminder to UK-based educational institutions about the importance of adhering to data protection laws when implementing AI and other new technologies.",Cause - organization causes - legal non-compliance,Cause,Chelmer Valley High School illegally used facial recognition to take canteen payments,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chelmer-valley-high-school-illegally-used-facial-recognition,Incident,,2024,2024,UK,Education,Chelmer Valley High School,,,Facial recognition,Process canteen payments,Regulatory investigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:50,https://best-paper-award-ddck.dovetail.com/data/l9JpYkbBaK5RjdAjJfBgZ#:v:h=72i0hdEtn5C1YJu0lRtHs2
AIAAIC1604,"A school was reprimanded by the UK data pricacy watchdog over its use of facial recognition to process cashless payments i  its canteen.  Chelmer Valley High School in Chelmsford, Essex, implemented the technology in March 2023 without first conducting a data protection impact assessment (DPIA) or obtaining explicit consent from students and parents, according to the Information Commissioner's Office.   A DPIA is required under the UK General Data Protection Regulation (UK GDPR). The school's DPIA was only completed in November 2023, months after the technology had been in use. The school has also sent a letter to parents in March 2023 allowing them to opt-out their children but did not seek explicit consent, assuming approval by default. This approach was deemed invalid by the ICO, as consent must be an affirmative action. The ICO highlighted that most students were old enough to provide their own consent, and the parental opt-out system limited their ability to exercise their rights and freedoms regarding their biometric data. The regulator recommended that the school improve its data protection practices, including conducting thorough DPIAs and obtaining explicit opt-in consent from students.  The ICO's reprimand serves as a reminder to UK-based educational institutions about the importance of adhering to data protection laws when implementing AI and other new technologies.",Incident - organization-driven - unauthorized data collection and use to enable AI functions (not training),Incident Type,Chelmer Valley High School illegally used facial recognition to take canteen payments,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chelmer-valley-high-school-illegally-used-facial-recognition,Incident,,2024,2024,UK,Education,Chelmer Valley High School,,,Facial recognition,Process canteen payments,Regulatory investigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:50,https://best-paper-award-ddck.dovetail.com/data/l9JpYkbBaK5RjdAjJfBgZ#:v:h=72i0hdEtn5C1YJu0lRtHs2
AIAAIC1604,"A school was reprimanded by the UK data pricacy watchdog over its use of facial recognition to process cashless payments i  its canteen.  Chelmer Valley High School in Chelmsford, Essex, implemented the technology in March 2023 without first conducting a data protection impact assessment (DPIA) or obtaining explicit consent from students and parents, according to the Information Commissioner's Office.   A DPIA is required under the UK General Data Protection Regulation (UK GDPR). The school's DPIA was only completed in November 2023, months after the technology had been in use. The school has also sent a letter to parents in March 2023 allowing them to opt-out their children but did not seek explicit consent, assuming approval by default. This approach was deemed invalid by the ICO, as consent must be an affirmative action. The ICO highlighted that most students were old enough to provide their own consent, and the parental opt-out system limited their ability to exercise their rights and freedoms regarding their biometric data. The regulator recommended that the school improve its data protection practices, including conducting thorough DPIAs and obtaining explicit opt-in consent from students.  The ICO's reprimand serves as a reminder to UK-based educational institutions about the importance of adhering to data protection laws when implementing AI and other new technologies.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Chelmer Valley High School illegally used facial recognition to take canteen payments,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chelmer-valley-high-school-illegally-used-facial-recognition,Incident,,2024,2024,UK,Education,Chelmer Valley High School,,,Facial recognition,Process canteen payments,Regulatory investigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:50,https://best-paper-award-ddck.dovetail.com/data/l9JpYkbBaK5RjdAjJfBgZ#:v:h=72i0hdEtn5C1YJu0lRtHs2
AIAAIC1604,"A school was reprimanded by the UK data pricacy watchdog over its use of facial recognition to process cashless payments i  its canteen.  Chelmer Valley High School in Chelmsford, Essex, implemented the technology in March 2023 without first conducting a data protection impact assessment (DPIA) or obtaining explicit consent from students and parents, according to the Information Commissioner's Office.   A DPIA is required under the UK General Data Protection Regulation (UK GDPR). The school's DPIA was only completed in November 2023, months after the technology had been in use. The school has also sent a letter to parents in March 2023 allowing them to opt-out their children but did not seek explicit consent, assuming approval by default. This approach was deemed invalid by the ICO, as consent must be an affirmative action. The ICO highlighted that most students were old enough to provide their own consent, and the parental opt-out system limited their ability to exercise their rights and freedoms regarding their biometric data. The regulator recommended that the school improve its data protection practices, including conducting thorough DPIAs and obtaining explicit opt-in consent from students.  The ICO's reprimand serves as a reminder to UK-based educational institutions about the importance of adhering to data protection laws when implementing AI and other new technologies.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Chelmer Valley High School illegally used facial recognition to take canteen payments,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chelmer-valley-high-school-illegally-used-facial-recognition,Incident,,2024,2024,UK,Education,Chelmer Valley High School,,,Facial recognition,Process canteen payments,Regulatory investigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:50,https://best-paper-award-ddck.dovetail.com/data/l9JpYkbBaK5RjdAjJfBgZ#:v:h=72i0hdEtn5C1YJu0lRtHs2
AIAAIC1604,"A school was reprimanded by the UK data pricacy watchdog over its use of facial recognition to process cashless payments i  its canteen.  Chelmer Valley High School in Chelmsford, Essex, implemented the technology in March 2023 without first conducting a data protection impact assessment (DPIA) or obtaining explicit consent from students and parents, according to the Information Commissioner's Office.   A DPIA is required under the UK General Data Protection Regulation (UK GDPR). The school's DPIA was only completed in November 2023, months after the technology had been in use. The school has also sent a letter to parents in March 2023 allowing them to opt-out their children but did not seek explicit consent, assuming approval by default. This approach was deemed invalid by the ICO, as consent must be an affirmative action. The ICO highlighted that most students were old enough to provide their own consent, and the parental opt-out system limited their ability to exercise their rights and freedoms regarding their biometric data. The regulator recommended that the school improve its data protection practices, including conducting thorough DPIAs and obtaining explicit opt-in consent from students.  The ICO's reprimand serves as a reminder to UK-based educational institutions about the importance of adhering to data protection laws when implementing AI and other new technologies.",Cause - organization causes - lack of data protection,Cause,Chelmer Valley High School illegally used facial recognition to take canteen payments,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chelmer-valley-high-school-illegally-used-facial-recognition,Incident,,2024,2024,UK,Education,Chelmer Valley High School,,,Facial recognition,Process canteen payments,Regulatory investigation,Privacy,Governance,Privacy loss,,,,,,,,9/26/2024 23:50,https://best-paper-award-ddck.dovetail.com/data/l9JpYkbBaK5RjdAjJfBgZ#:v:h=72i0hdEtn5C1YJu0lRtHs2
AIAAIC1120,"ChatGPT allowed some users to see other users' conversations and personal information, suggesting OpenAI had access to user conversations, and calling into question the company's privacy duty of care. Users had shared images of chat histories that they said were not theirs on social media sites Reddit and Twitter, prompting a flood of complaints.  Initially, the incident appeared confined to user conversations, which OpenAI states in its ChatGPT FAQs are reviewed - most likely to improve its systems on an ongoing basis.  However, the company later confirmed that some users' first and last names, email addresses, payment addresses, parts of credit card numbers and credit card expiration dates had also been exposed. OpenAI disabled the chatbot to fix the error, and said that users had not been able to access full conversations. CEO Sam Altman later said the company felf 'awful' about the glitch, and that it had been fixed. ",Entity - AI algorithm,Responsible Entities,"ChatGPT leaks user conversations, personal information",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-leaks-user-conversations,Incident,2022,2023,2023,USA,Technology,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,,Privacy,Governance,Privacy loss,,,,System update,,,,10/7/2024 0:52,https://best-paper-award-ddck.dovetail.com/data/7Innvupi1JGm8bssWwNSJA#:v:h=75utrDSvUzKezvmPUYN2AW
AIAAIC1120,"ChatGPT allowed some users to see other users' conversations and personal information, suggesting OpenAI had access to user conversations, and calling into question the company's privacy duty of care. Users had shared images of chat histories that they said were not theirs on social media sites Reddit and Twitter, prompting a flood of complaints.  Initially, the incident appeared confined to user conversations, which OpenAI states in its ChatGPT FAQs are reviewed - most likely to improve its systems on an ongoing basis.  However, the company later confirmed that some users' first and last names, email addresses, payment addresses, parts of credit card numbers and credit card expiration dates had also been exposed. OpenAI disabled the chatbot to fix the error, and said that users had not been able to access full conversations. CEO Sam Altman later said the company felf 'awful' about the glitch, and that it had been fixed. ",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,"ChatGPT leaks user conversations, personal information",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-leaks-user-conversations,Incident,2022,2023,2023,USA,Technology,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,,Privacy,Governance,Privacy loss,,,,System update,,,,10/7/2024 0:52,https://best-paper-award-ddck.dovetail.com/data/7Innvupi1JGm8bssWwNSJA#:v:h=75utrDSvUzKezvmPUYN2AW
AIAAIC1120,"ChatGPT allowed some users to see other users' conversations and personal information, suggesting OpenAI had access to user conversations, and calling into question the company's privacy duty of care. Users had shared images of chat histories that they said were not theirs on social media sites Reddit and Twitter, prompting a flood of complaints.  Initially, the incident appeared confined to user conversations, which OpenAI states in its ChatGPT FAQs are reviewed - most likely to improve its systems on an ongoing basis.  However, the company later confirmed that some users' first and last names, email addresses, payment addresses, parts of credit card numbers and credit card expiration dates had also been exposed. OpenAI disabled the chatbot to fix the error, and said that users had not been able to access full conversations. CEO Sam Altman later said the company felf 'awful' about the glitch, and that it had been fixed. ",Cause - organization causes - lack of data protection,Cause,"ChatGPT leaks user conversations, personal information",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-leaks-user-conversations,Incident,2022,2023,2023,USA,Technology,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,,Privacy,Governance,Privacy loss,,,,System update,,,,10/7/2024 0:52,https://best-paper-award-ddck.dovetail.com/data/7Innvupi1JGm8bssWwNSJA#:v:h=75utrDSvUzKezvmPUYN2AW
AIAAIC1120,"ChatGPT allowed some users to see other users' conversations and personal information, suggesting OpenAI had access to user conversations, and calling into question the company's privacy duty of care. Users had shared images of chat histories that they said were not theirs on social media sites Reddit and Twitter, prompting a flood of complaints.  Initially, the incident appeared confined to user conversations, which OpenAI states in its ChatGPT FAQs are reviewed - most likely to improve its systems on an ongoing basis.  However, the company later confirmed that some users' first and last names, email addresses, payment addresses, parts of credit card numbers and credit card expiration dates had also been exposed. OpenAI disabled the chatbot to fix the error, and said that users had not been able to access full conversations. CEO Sam Altman later said the company felf 'awful' about the glitch, and that it had been fixed. ",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,"ChatGPT leaks user conversations, personal information",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-leaks-user-conversations,Incident,2022,2023,2023,USA,Technology,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning,Generate text,,Privacy,Governance,Privacy loss,,,,System update,,,,10/7/2024 0:52,https://best-paper-award-ddck.dovetail.com/data/7Innvupi1JGm8bssWwNSJA#:v:h=75utrDSvUzKezvmPUYN2AW
AIAAIC1473,"UK police officers recently accessed controversial facial recognition service PimEyes over 2,000 times, contrary to their own stated policies and procedures. An iNews/Liberty investigation revealed that London's Metropolitan Police Service (MPF) computers accessed PimEyes 2,337 times in a recent three-month period.  The Metropolitan Police Service (MPF) responded by saying that the recorded instances of use may have been related to officers conducting research on the software. The MPF said it had strengthened safeguards and blocked access to the site on Met devices.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,"UK police use PimEyes, raising privacy concerns",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-police-found-to-use-pimeyes-raising-privacy-concerns,Issue,2017,2024,2024,UK,Govt - police,Metropolitan Police Service (MPS),PimEyes,PimEyes,Facial recognition,Identify criminal suspects,Media investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 12:23,https://best-paper-award-ddck.dovetail.com/data/1ZnRdlaYvCiqDDIMNyDrI3#:v:h=77RviCgEg5daef4VAVyQSZ
AIAAIC1473,"UK police officers recently accessed controversial facial recognition service PimEyes over 2,000 times, contrary to their own stated policies and procedures. An iNews/Liberty investigation revealed that London's Metropolitan Police Service (MPF) computers accessed PimEyes 2,337 times in a recent three-month period.  The Metropolitan Police Service (MPF) responded by saying that the recorded instances of use may have been related to officers conducting research on the software. The MPF said it had strengthened safeguards and blocked access to the site on Met devices.",Entity - government authorities that adopt AI,Responsible Entities,"UK police use PimEyes, raising privacy concerns",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/uk-police-found-to-use-pimeyes-raising-privacy-concerns,Issue,2017,2024,2024,UK,Govt - police,Metropolitan Police Service (MPS),PimEyes,PimEyes,Facial recognition,Identify criminal suspects,Media investigation,Privacy,Governance,Privacy loss,,,,,,,,10/2/2024 12:23,https://best-paper-award-ddck.dovetail.com/data/1ZnRdlaYvCiqDDIMNyDrI3#:v:h=77RviCgEg5daef4VAVyQSZ
"AIAAIC1773
","Drew Crecente discovered that an AI-powered chatbot had been created using the likeness and name of his dead daughter without consent, triggering anger and pain for his family.  What happened Drew Clemente discovered that a chatbot on Character AI had been set up in his daughter Jennifer Ann's name and using her likeness, without the consent of her family. The bot portrayed Jennifer Ann as a friendly and knowledgeable character, claiming expertise in journalism, which referenced her uncle, a prominent journalist. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"Character AI used to create ""disturbing"" Jennifer Ann Clemente persona",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/character-ai-fails-to-police-non-consensual-ai-personas,Incident,,2024,2024,"USA
","Media/entertainment/sports/arts
",,,,,,,,,,,,,,,,,10/31/2024 10:42,https://best-paper-award-ddck.dovetail.com/data/2RnvcQTcMjOqJ18UMfJxtK#:v:h=7al7q9m9HDKiwlXyK0M5Vb
"AIAAIC1773
","Drew Crecente discovered that an AI-powered chatbot had been created using the likeness and name of his dead daughter without consent, triggering anger and pain for his family.  What happened Drew Clemente discovered that a chatbot on Character AI had been set up in his daughter Jennifer Ann's name and using her likeness, without the consent of her family. The bot portrayed Jennifer Ann as a friendly and knowledgeable character, claiming expertise in journalism, which referenced her uncle, a prominent journalist. ",Entity - malicious human,Responsible Entities,"Character AI used to create ""disturbing"" Jennifer Ann Clemente persona",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/character-ai-fails-to-police-non-consensual-ai-personas,Incident,,2024,2024,"USA
","Media/entertainment/sports/arts
",,,,,,,,,,,,,,,,,10/31/2024 10:42,https://best-paper-award-ddck.dovetail.com/data/2RnvcQTcMjOqJ18UMfJxtK#:v:h=7al7q9m9HDKiwlXyK0M5Vb
"AIAAIC1773
","Drew Crecente discovered that an AI-powered chatbot had been created using the likeness and name of his dead daughter without consent, triggering anger and pain for his family.  What happened Drew Clemente discovered that a chatbot on Character AI had been set up in his daughter Jennifer Ann's name and using her likeness, without the consent of her family. The bot portrayed Jennifer Ann as a friendly and knowledgeable character, claiming expertise in journalism, which referenced her uncle, a prominent journalist. ",Cause - organization/human cause - lack of informed consent & transparency,Cause,"Character AI used to create ""disturbing"" Jennifer Ann Clemente persona",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/character-ai-fails-to-police-non-consensual-ai-personas,Incident,,2024,2024,"USA
","Media/entertainment/sports/arts
",,,,,,,,,,,,,,,,,10/31/2024 10:42,https://best-paper-award-ddck.dovetail.com/data/2RnvcQTcMjOqJ18UMfJxtK#:v:h=7al7q9m9HDKiwlXyK0M5Vb
"AIAAIC1773
","Drew Crecente discovered that an AI-powered chatbot had been created using the likeness and name of his dead daughter without consent, triggering anger and pain for his family.  What happened Drew Clemente discovered that a chatbot on Character AI had been set up in his daughter Jennifer Ann's name and using her likeness, without the consent of her family. The bot portrayed Jennifer Ann as a friendly and knowledgeable character, claiming expertise in journalism, which referenced her uncle, a prominent journalist. ",Cause - Human causes - Human abuse of AI tools,Cause,"Character AI used to create ""disturbing"" Jennifer Ann Clemente persona",,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/character-ai-fails-to-police-non-consensual-ai-personas,Incident,,2024,2024,"USA
","Media/entertainment/sports/arts
",,,,,,,,,,,,,,,,,10/31/2024 10:42,https://best-paper-award-ddck.dovetail.com/data/2RnvcQTcMjOqJ18UMfJxtK#:v:h=7al7q9m9HDKiwlXyK0M5Vb
AIAAIC1200,"Eight individuals sued (pdf) Google, DeepMind, and their parent company Alphabet",Entity - AI developer company's affiliated parterns,Responsible Entities,Google sued for AI data scraping,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-sued-for-ai-data-scraping,Incident,2023,2023,2023,USA,Multiple,,Google,Bard/Gemini,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Copyright; Privacy,Governance,IP/copyright loss,,,,,,,,10/7/2024 0:13,https://best-paper-award-ddck.dovetail.com/data/77S4eyH1VDVyIKcg5Cpm8L#:v:h=7cbgtnjkS7dmEa0zzuS0WE
AIAAIC1200,"Eight individuals sued (pdf) Google, DeepMind, and their parent company Alphabet",Entity - AI developer company,Responsible Entities,Google sued for AI data scraping,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-sued-for-ai-data-scraping,Incident,2023,2023,2023,USA,Multiple,,Google,Bard/Gemini,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Lawsuit filing/litigation,Copyright; Privacy,Governance,IP/copyright loss,,,,,,,,10/7/2024 0:13,https://best-paper-award-ddck.dovetail.com/data/77S4eyH1VDVyIKcg5Cpm8L#:v:h=7cbgtnjkS7dmEa0zzuS0WE
AIAAIC1608,"The French national police were accused of secretly and illegally using facial recognition technology since 2015, sparking significant controversy and calls for an independent investigation.  The French national police quietly started using Israeli company BriefCam's Video Synposis facial recognition software since 2015, according to non-profit journalist outfit Disclose. The software, which allows for broad, one-to-many facial matching with minimal oversight, was reportedly installed in multiple police stations, including Paris and Marseilles.  The use of facial recognition violates French and European law, including the country's Informatics and Freedom Law and the EU's General Data Protection Act, which prohibit biometric identification systems and facial recognition techniques in most circumstances.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,French national police accused of illegally using facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/french-national-police-accused-of-illegally-using-facial-recognition,Issue,2015,2023,2023,France,Govt - police,Seine-et-Marne Departmental Directorate of Public Security,BriefCam,Video Synopsis,Facial recognition,Identify criminal suspects,NGO investigation,Privacy,Governance; Marketing,Privacy loss,,,,,,Govt investigation,,9/26/2024 23:43,https://best-paper-award-ddck.dovetail.com/data/5jeoMddR9Z62yQODuMQE4v#:v:h=7eY9TDhw1R9hnxMQxqATMI
AIAAIC1156,"However, Kenyan regulators pointed out that Worldcoin had no need to collect users’ iris data, and was not regulated in the country. In October 2023 a Kenyan parliamentary committee recommended (pdf) that Worldcoin had violated Kenyan law and be shut down until the country established proper regulations over virtual assets. ",Cause - governance causes - legal loophole,Cause,"Worldcoin suspended in Kenya over privacy, security concerns",10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/worldcoin-suspended-in-kenya-for-privacy-abuse,Incident,2023,2023,2023,Kenya,Banking/financial services,"Tools for Humanity/Worldcoin
","Tools for Humanity/Worldcoin
",Worldcoin,Iris scanning; Facial detection; Vital signs detection; Blockchain; Virtual currency,Develop digital identity,Regulatory inquiry/investigation,Privacy; Security; Legal,Governance; Privacy; Marketing,Privacy loss; Financial loss,,,,System suspension,,Restraining order; Parliamentary investigation,,10/7/2024 0:35,https://best-paper-award-ddck.dovetail.com/data/4sPxaecAc36dgjjjvzKHEn#:v:h=7hdsUkvAjr967JpDUAPGtJ
AIAAIC1542,"Indian travel agency Yatra Online used the facial likeness of Indian model Kanchan Nagar in an advert without her permission, resulting in the violation of her personality rights and a legal complaint. Nagar issued a legal notice to the Advertising Standards Council of India emphasising the harms of the unregulated use of AI and the need for for ethics in advertising in order to protect the authenticity of people’s identity and their privacy.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Professional model’s AI likeness used in ad without her consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/indian-travel-company-uses-professional-models-ai-likeness-in-ad,Incident,,2024,2024,India,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Generate images,Legal filing,Ethics/values; Personality rights; Privacy,Governance; Marketing,,,,,,,,,10/12/2024 1:05,https://best-paper-award-ddck.dovetail.com/data/6oKZXaDM6c9sVvomXvr5iC#:v:h=7koZfFl3tNdjPDmDqm73m3
AIAAIC1542,"Indian travel agency Yatra Online used the facial likeness of Indian model Kanchan Nagar in an advert without her permission, resulting in the violation of her personality rights and a legal complaint. Nagar issued a legal notice to the Advertising Standards Council of India emphasising the harms of the unregulated use of AI and the need for for ethics in advertising in order to protect the authenticity of people’s identity and their privacy.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Professional model’s AI likeness used in ad without her consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/indian-travel-company-uses-professional-models-ai-likeness-in-ad,Incident,,2024,2024,India,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Generate images,Legal filing,Ethics/values; Personality rights; Privacy,Governance; Marketing,,,,,,,,,10/12/2024 1:05,https://best-paper-award-ddck.dovetail.com/data/6oKZXaDM6c9sVvomXvr5iC#:v:h=7koZfFl3tNdjPDmDqm73m3
AIAAIC1542,"Indian travel agency Yatra Online used the facial likeness of Indian model Kanchan Nagar in an advert without her permission, resulting in the violation of her personality rights and a legal complaint. Nagar issued a legal notice to the Advertising Standards Council of India emphasising the harms of the unregulated use of AI and the need for for ethics in advertising in order to protect the authenticity of people’s identity and their privacy.",Cause - organization/human cause - lack of informed consent & transparency,Cause,Professional model’s AI likeness used in ad without her consent,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/indian-travel-company-uses-professional-models-ai-likeness-in-ad,Incident,,2024,2024,India,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Generate images,Legal filing,Ethics/values; Personality rights; Privacy,Governance; Marketing,,,,,,,,,10/12/2024 1:05,https://best-paper-award-ddck.dovetail.com/data/6oKZXaDM6c9sVvomXvr5iC#:v:h=7koZfFl3tNdjPDmDqm73m3
AIAAIC1497,"A group of voiceover actors sued AI start-up, Lovo, for the unauthorised use of their voices A group of voiceover actors, including Paul Skye Lehrman",Cause - organization/human cause - lack of informed consent & transparency,Cause,Voice Actors sue AI start-up for “voice theft”,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/voice-actors-sue-ai-startup-for-voice-theft,Incident,,2024,2024,USA,Media/entertainment/sports/arts,LOVO,LOVO,Lovo Voice Generator,Deepfake - audio; Machine learning,Generate voice,Legal filing,Personality rights,Governance,Personality rights loss; Financial loss,,,Reputational damage,,$5M in damages,Litigation,,10/12/2024 0:53,https://best-paper-award-ddck.dovetail.com/data/6pHtWShnb04KpoDyxzXLX3#:v:h=7nW76FO5O240Y0i0tAsYNM
AIAAIC1165,"A disclaimer under the advert said, 'Images produced by Lisa AI. It has nothing to do with this person.'",Entity - AI developer company,Responsible Entities,Scarlett Johansson sues app for using image for AI advert,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/scarlett-johansson-sues-app-for-using-image-for-ai-advert,Incident,,2023,2023,Turkey; USA,Media/entertainment/sports/arts,Convert Yazılım Limited Şirketi,Convert Yazılım Limited Şirketi; Stability AI,Lisa AI: 90s Yearbook & Avatar,"Deepfake - audio, video; Machine learning",Increase visibility,Lawsuit filing/litigation,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 21:28,https://best-paper-award-ddck.dovetail.com/data/3lcynQ0aOrHnv0o97VAbjn#:v:h=7oS7UOQddT6Uw39M0Dgc1T
AIAAIC1413,"A facial recognition system used by Israel in Gaza misidentified scores of innocent Palestinians, resulting in their abduction, interrogration, and physical beatings.",Entity - government authorities that adopt AI,Responsible Entities,Israel facial recognition system misidentifies innocent Gazans,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/israel-facial-recognition-system-misidentifies-innocent-gazans,Incident,,2024,2024,Israel; Palestine,Govt - defence,Israel Defense Forces (IDF),Corsight,,Facial recognition,Identify terrorists,Media investigation,Human/civil rights; Privacy,Governance; Marketing,Privacy loss; Loss of rights/freedoms,Chilling effect,,,,,,,10/2/2024 15:25,https://best-paper-award-ddck.dovetail.com/data/513IxSsMP1gESrQePS8buy#:v:h=7qwVxeCFo5WUn3QoF26VBP
AIAAIC0473,"jeopardising privacy, increasing student anxiety, discriminating against students of colour and others, and inadequate transparency.",Cause - organization/human cause - lack of informed consent & transparency,Cause,"UBC academic, students accuse Proctorio of privacy abuse",10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ubc-academic-students-accuse-proctorio-of-privacy-abuse,Incident,2013,2023,2023,Canada,Education,University of British Columbia,Proctorio,Proctorio,Facial detection; Gaze detection; Machine learning,Detect exam cheating,Lawsuit filing/litigation,Bias/discrimination - race; Confidentiality; Privacy; Freedom of expression; Freedom of information,Governance; Back box; Complaints/appeals; Marketing; Legal,Privacy loss; Loss of rights/freedoms,,,Student backlash,,,Litigation,,10/13/2024 22:45,https://best-paper-award-ddck.dovetail.com/data/3iKQRgkp7wnHPaH1dvQ0OJ#:v:h=7reHyxfY93SdQwGGuj7yId
AIAAIC1161,"An image of a man carrying children through rubble during Israel's bombing of the Gaza Strip has been assessed as a probable deepfake. The deepfake image, which appears to show a man helping five children away from the scene of a destroyed building, was shared over 80,000 times on social media and was further amplified on X (formerly Twitter) of the Chinese embassy in France.",Entity - no specific info,Responsible Entities,Deepfake Palestinian man carries children out of rubble,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-palestinian-carries-children-out-of-rubble,Incident,,2023,2023,Israel; Palestine,Politics,,,,Deepfake - image; Machine learning,Manipulate public opinion,Fact check,Mis/disinformation,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:07,https://best-paper-award-ddck.dovetail.com/data/48vFaID3KLlU48nRi4xqNF#:v:h=7sE29zfSCS4q4sUlL1GNtz
AIAAIC1161,"An image of a man carrying children through rubble during Israel's bombing of the Gaza Strip has been assessed as a probable deepfake. The deepfake image, which appears to show a man helping five children away from the scene of a destroyed building, was shared over 80,000 times on social media and was further amplified on X (formerly Twitter) of the Chinese embassy in France.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake Palestinian man carries children out of rubble,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-palestinian-carries-children-out-of-rubble,Incident,,2023,2023,Israel; Palestine,Politics,,,,Deepfake - image; Machine learning,Manipulate public opinion,Fact check,Mis/disinformation,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:07,https://best-paper-award-ddck.dovetail.com/data/48vFaID3KLlU48nRi4xqNF#:v:h=7sE29zfSCS4q4sUlL1GNtz
AIAAIC1161,"An image of a man carrying children through rubble during Israel's bombing of the Gaza Strip has been assessed as a probable deepfake. The deepfake image, which appears to show a man helping five children away from the scene of a destroyed building, was shared over 80,000 times on social media and was further amplified on X (formerly Twitter) of the Chinese embassy in France.",Cause - no specific info,Cause,Deepfake Palestinian man carries children out of rubble,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-palestinian-carries-children-out-of-rubble,Incident,,2023,2023,Israel; Palestine,Politics,,,,Deepfake - image; Machine learning,Manipulate public opinion,Fact check,Mis/disinformation,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:07,https://best-paper-award-ddck.dovetail.com/data/48vFaID3KLlU48nRi4xqNF#:v:h=7sE29zfSCS4q4sUlL1GNtz
AIAAIC1705,"Apparently disgruntled former Outabox employees created a website called 'Have I Been Outaboxed' containing one million facial recognition biometric, driver's license scan,signature, club membership information, addresses, birthdays, phone numbers, club visit timestamps, and slot machine usage records from 19 clubs and bars in New SouthWales and the Australian Capital Territory operated by ClubsNSW. Outabox had introduced facial recognition kiosks in response to the COVID-19 pandemic, which scanned visitors, checked temperatures, and identified problem gamblers. Australian cybersecurity expert Troy Hunt suggested that while the breach is concerning, the biometric data may not pose a significant risk if the data is not in the form of usable templates.",Entity - malicious human,Responsible Entities,Outabox data breach exposes 1m biometric records,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/outabox-data-breach-exposes-1m-biometric-records,Incident,2021,2024,2024,Australia; Philippines; USA,Travel/hospitality,ClubsNSW,Outabox,TriAgem Facial Recognition Kiosk,Facial recognition,Identify bar/club users,Data breach,Privacy,,Privacy loss,,,Reputational damage,,,,,9/26/2024 22:29,https://best-paper-award-ddck.dovetail.com/data/2Vwbe3Qedt3gSMibUMymrw#:v:h=7sJLlwmOciBgwdW76UtCXY
AIAAIC1019,A deepfake photograph and accompanying report of an explosion near to the Pentagon outside Washington DC led to a 0.26 percent fall in the US stock market in four minutes. The report was quickly rebutted as false by Arlington authorities.,Cause - Human causes - Human abuse of AI tools,Cause,Pentagon deepfake 'explosion' jitters US stock market,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pentagon-deepfake-explosion,Incident,,2023,2023,USA,Govt - defence,X Corp/Twitter,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,,Mis/disinformation,Governance; Marketing,,Stock market price fall,,,,,,,10/30/2024 17:35,https://best-paper-award-ddck.dovetail.com/data/35vWwsC8yBttpuxC7vKuxO#:v:h=7t3g5WVUVDLCeNkSVUIY3U
AIAAIC1019,A deepfake photograph and accompanying report of an explosion near to the Pentagon outside Washington DC led to a 0.26 percent fall in the US stock market in four minutes. The report was quickly rebutted as false by Arlington authorities.,"Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Pentagon deepfake 'explosion' jitters US stock market,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pentagon-deepfake-explosion,Incident,,2023,2023,USA,Govt - defence,X Corp/Twitter,,,Deepfake - image; Machine learning,Scare/confuse/destabilise,,Mis/disinformation,Governance; Marketing,,Stock market price fall,,,,,,,10/30/2024 17:35,https://best-paper-award-ddck.dovetail.com/data/35vWwsC8yBttpuxC7vKuxO#:v:h=7t3g5WVUVDLCeNkSVUIY3U
AIAAIC1225,"prompts using specific words or phrases such as the word 'poem' can be used to cause ChatGPT to fail, causing the chatbot to copy outputs direct from its GPT-3.5 training data.  'In total, 16.9 percent of generations we tested contained memorized PII [Personally Identifying Information], and 85.8 percent of generations that contained potential PII were actual PII', the researchers said. These included information such as names, email addresses, and phone numbers that could be used to identify individuals.",Entity - AI developer company,Responsible Entities,ChatGPT used to collect users' personal information ,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/chatgpt-used-to-collect-users-personal-information,Issue,,2023,2023,USA; Switzerland,Multiple,"Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramèr, Katherine Lee",OpenAI,ChatGPT; GPT-3,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Research study/report,Privacy; Security,,Privacy loss,,,,,,,,10/6/2024 23:52,https://best-paper-award-ddck.dovetail.com/data/1Sa11cldSvyodSULBtLMq1#:v:h=7tsSGEcGQ8RvcwvFrnkjzU
AIAAIC1314," a Telegram group dedicated to abusive images of women, and created using Microsoft Designer, according to 404 Media.",Cause - Human causes - Human abuse of AI tools,Cause,X/Twitter fails to remove graphic AI images of Taylor Swift,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/xtwitter-fails-to-remove-graphic-ai-images-of-taylor-swift,Incident,,2024,2024,USA,Media/entertainment/sports/arts,XCorp/xAI/Twitter,XCorp/xAI/Twitter,X/Twitter,Content moderation system; NLP/text analysis,Moderate content,User comments/complaints,Business model; Robustness; Safety; Privacy,,Harassment/abuse; Privacy loss,,,,,,Litigation,,10/2/2024 20:16,https://best-paper-award-ddck.dovetail.com/data/61hlP660WyAyWh28geTodC#:v:h=7tw1GfCYV8ytmevBU9FBJw
AIAAIC1189,"A Canadian man was sentenced to three years in prison for using artificial intelligence to generate child pornography images and videos. To create the videos, Steven Larouche, 61, from Quebec, superimposed the faces of children onto the body of other children. The judge ruled that the sexual integrity of the children whose bodies were used had been violated. Larouche’s lawyers had argued for a lighter sentence as no children had been physically assaulted.",Cause - Human causes - Human abuse of AI tools,Cause,Quebec man jailed for producing AI child porn,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/quebec-man-jailed-for-producing-ai-child-porn,Incident,,2023,2023,Canada,Media/entertainment/sports/arts,Steven Larouche,,,"Deepfake - audio, video; Machine learning",Self-gratification,Lawsuit filing/litigation,Safety; Legal,Governance; Marketing,Dignity loss,,,,,,Litigation,,10/24/2024 22:17,https://best-paper-award-ddck.dovetail.com/data/6EbqXh5baeg6xaig7Sd3Dj#:v:h=7udHAW37kTtrQJiZty73GD
AIAAIC1189,"A Canadian man was sentenced to three years in prison for using artificial intelligence to generate child pornography images and videos. To create the videos, Steven Larouche, 61, from Quebec, superimposed the faces of children onto the body of other children. The judge ruled that the sexual integrity of the children whose bodies were used had been violated. Larouche’s lawyers had argued for a lighter sentence as no children had been physically assaulted.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Quebec man jailed for producing AI child porn,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/quebec-man-jailed-for-producing-ai-child-porn,Incident,,2023,2023,Canada,Media/entertainment/sports/arts,Steven Larouche,,,"Deepfake - audio, video; Machine learning",Self-gratification,Lawsuit filing/litigation,Safety; Legal,Governance; Marketing,Dignity loss,,,,,,Litigation,,10/24/2024 22:17,https://best-paper-award-ddck.dovetail.com/data/6EbqXh5baeg6xaig7Sd3Dj#:v:h=7udHAW37kTtrQJiZty73GD
AIAAIC1189,"A Canadian man was sentenced to three years in prison for using artificial intelligence to generate child pornography images and videos. To create the videos, Steven Larouche, 61, from Quebec, superimposed the faces of children onto the body of other children. The judge ruled that the sexual integrity of the children whose bodies were used had been violated. Larouche’s lawyers had argued for a lighter sentence as no children had been physically assaulted.",Entity - malicious human,Responsible Entities,Quebec man jailed for producing AI child porn,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/quebec-man-jailed-for-producing-ai-child-porn,Incident,,2023,2023,Canada,Media/entertainment/sports/arts,Steven Larouche,,,"Deepfake - audio, video; Machine learning",Self-gratification,Lawsuit filing/litigation,Safety; Legal,Governance; Marketing,Dignity loss,,,,,,Litigation,,10/24/2024 22:17,https://best-paper-award-ddck.dovetail.com/data/6EbqXh5baeg6xaig7Sd3Dj#:v:h=7udHAW37kTtrQJiZty73GD
AIAAIC1700,"Trump's posts are part of a pattern of using AI-generated content to blur the lines between satire and misinformation, raising alarms about the potential impact on public perception and electoral integrity.",Incident - human-driven - Public entity amplified of misleading content,Incident Type,Donald Trump uses AI to fake Taylor Swift endorsement,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/donald-trump-uses-ai-to-fake-taylor-swift-endorsement,Issue,,2024,2024,USA,Politics; Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Deceive voters,,Ethics/values; Mis/disinformation,Governance,,,,,,,,,10/18/2024 14:19,https://best-paper-award-ddck.dovetail.com/data/29x9mi44lzE1VL1iEqQWMz#:v:h=7uPLakx2KVlMk9VhH5RxfP
AIAAIC1294,"A teenage boy used AI to generate nude images of his female classmates and a member of staff at Issaquah High School, Seattle, and sent them round the school. The images were created with an unnamed web-based nudification app, which automatically edits photos of women to make them appear naked. A student reportedly discovered the app on TikTok and then posted some of nudified photographs on Snapchat or showed them to other students over lunch at the school.  ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Teen distributes AI-generated nude pictures of Issaquah students,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-generated-nude-pictures-of-issaquah-students-circulate,Incident,,2023,2023,USA,Education,School student,Issaquah High School students,,Deepfake - image; Machine learning,Harrass/intimidate/shame,Police statement,Accountability; Safety,,Anxiety/distress/depression,,,,,,,,10/24/2024 22:47,https://best-paper-award-ddck.dovetail.com/data/TiF2Ej3z7vTwyiMb1SMuc#:v:h=7vc0s9Z50hoPhpm6apLbH9
AIAAIC1294,"A teenage boy used AI to generate nude images of his female classmates and a member of staff at Issaquah High School, Seattle, and sent them round the school. The images were created with an unnamed web-based nudification app, which automatically edits photos of women to make them appear naked. A student reportedly discovered the app on TikTok and then posted some of nudified photographs on Snapchat or showed them to other students over lunch at the school.  ",Cause - Human causes - Human abuse of AI tools,Cause,Teen distributes AI-generated nude pictures of Issaquah students,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-generated-nude-pictures-of-issaquah-students-circulate,Incident,,2023,2023,USA,Education,School student,Issaquah High School students,,Deepfake - image; Machine learning,Harrass/intimidate/shame,Police statement,Accountability; Safety,,Anxiety/distress/depression,,,,,,,,10/24/2024 22:47,https://best-paper-award-ddck.dovetail.com/data/TiF2Ej3z7vTwyiMb1SMuc#:v:h=7vc0s9Z50hoPhpm6apLbH9
AIAAIC1294,"A teenage boy used AI to generate nude images of his female classmates and a member of staff at Issaquah High School, Seattle, and sent them round the school. The images were created with an unnamed web-based nudification app, which automatically edits photos of women to make them appear naked. A student reportedly discovered the app on TikTok and then posted some of nudified photographs on Snapchat or showed them to other students over lunch at the school.  ",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,Teen distributes AI-generated nude pictures of Issaquah students,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-generated-nude-pictures-of-issaquah-students-circulate,Incident,,2023,2023,USA,Education,School student,Issaquah High School students,,Deepfake - image; Machine learning,Harrass/intimidate/shame,Police statement,Accountability; Safety,,Anxiety/distress/depression,,,,,,,,10/24/2024 22:47,https://best-paper-award-ddck.dovetail.com/data/TiF2Ej3z7vTwyiMb1SMuc#:v:h=7vc0s9Z50hoPhpm6apLbH9
AIAAIC1294,"A teenage boy used AI to generate nude images of his female classmates and a member of staff at Issaquah High School, Seattle, and sent them round the school. The images were created with an unnamed web-based nudification app, which automatically edits photos of women to make them appear naked. A student reportedly discovered the app on TikTok and then posted some of nudified photographs on Snapchat or showed them to other students over lunch at the school.  ",Entity - malicious human,Responsible Entities,Teen distributes AI-generated nude pictures of Issaquah students,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-generated-nude-pictures-of-issaquah-students-circulate,Incident,,2023,2023,USA,Education,School student,Issaquah High School students,,Deepfake - image; Machine learning,Harrass/intimidate/shame,Police statement,Accountability; Safety,,Anxiety/distress/depression,,,,,,,,10/24/2024 22:47,https://best-paper-award-ddck.dovetail.com/data/TiF2Ej3z7vTwyiMb1SMuc#:v:h=7vc0s9Z50hoPhpm6apLbH9
AIAAIC1506,"An innocent shopper at retail chain Home Bargains was wrongfully accused of theft due to an error in a facial recognition system, prompting public controversy and a legal complaint. The woman, who preferred to remain anonymous, was incorrectly identified by the Facewatch facial recognition system as a shoplifter. A staff member searched her bag and she was led out of the store. She was also banned from all stores using the Facewatch technology. The woman reported that she was devastated by the incident and it caused her significant anxiety and distress. She was worried about being perceived as a shoplifter despite never having stolen anything. Facewatch later acknowledged the error and issued an apology. This incident highlights some of the potential issues with facial recognition technology, including false positives and the human rights and psychological impacts on innocent individuals.  Despite these concerns, the technology is increasingly being used by retailers and police forces in the UK.",Incident - AI-driven - false & unexpected & disappointing behavior,Incident Type,Home Bargains shopper misidentified by Facewatch facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/home-bargains-shopper-misidentified-by-facewatch,Incident,,2024,2024,UK,Retail,Home Bargains,Facewatch,Facewatch,Facial recognition,Identify criminal suspects,NGO investigation,Accuracy/reliability; Privacy,Governance,Loss of rights/freedoms,,,,,,Litigation,,9/27/2024 0:34,https://best-paper-award-ddck.dovetail.com/data/1GNJLIilqzQbhlgeigpNMm#:v:h=7veO1slrZzrO8W7FnZfGDn
AIAAIC1506,"An innocent shopper at retail chain Home Bargains was wrongfully accused of theft due to an error in a facial recognition system, prompting public controversy and a legal complaint. The woman, who preferred to remain anonymous, was incorrectly identified by the Facewatch facial recognition system as a shoplifter. A staff member searched her bag and she was led out of the store. She was also banned from all stores using the Facewatch technology. The woman reported that she was devastated by the incident and it caused her significant anxiety and distress. She was worried about being perceived as a shoplifter despite never having stolen anything. Facewatch later acknowledged the error and issued an apology. This incident highlights some of the potential issues with facial recognition technology, including false positives and the human rights and psychological impacts on innocent individuals.  Despite these concerns, the technology is increasingly being used by retailers and police forces in the UK.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Home Bargains shopper misidentified by Facewatch facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/home-bargains-shopper-misidentified-by-facewatch,Incident,,2024,2024,UK,Retail,Home Bargains,Facewatch,Facewatch,Facial recognition,Identify criminal suspects,NGO investigation,Accuracy/reliability; Privacy,Governance,Loss of rights/freedoms,,,,,,Litigation,,9/27/2024 0:34,https://best-paper-award-ddck.dovetail.com/data/1GNJLIilqzQbhlgeigpNMm#:v:h=7veO1slrZzrO8W7FnZfGDn
AIAAIC1506,"An innocent shopper at retail chain Home Bargains was wrongfully accused of theft due to an error in a facial recognition system, prompting public controversy and a legal complaint. The woman, who preferred to remain anonymous, was incorrectly identified by the Facewatch facial recognition system as a shoplifter. A staff member searched her bag and she was led out of the store. She was also banned from all stores using the Facewatch technology. The woman reported that she was devastated by the incident and it caused her significant anxiety and distress. She was worried about being perceived as a shoplifter despite never having stolen anything. Facewatch later acknowledged the error and issued an apology. This incident highlights some of the potential issues with facial recognition technology, including false positives and the human rights and psychological impacts on innocent individuals.  Despite these concerns, the technology is increasingly being used by retailers and police forces in the UK.",Entity - AI algorithm,Responsible Entities,Home Bargains shopper misidentified by Facewatch facial recognition,9/27/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/home-bargains-shopper-misidentified-by-facewatch,Incident,,2024,2024,UK,Retail,Home Bargains,Facewatch,Facewatch,Facial recognition,Identify criminal suspects,NGO investigation,Accuracy/reliability; Privacy,Governance,Loss of rights/freedoms,,,,,,Litigation,,9/27/2024 0:34,https://best-paper-award-ddck.dovetail.com/data/1GNJLIilqzQbhlgeigpNMm#:v:h=7veO1slrZzrO8W7FnZfGDn
AIAAIC1727,"Over 500 South Korean schools and universities have been overwhelmed with deepfake pornography, humiliating students and causing outrage amongst the broader general public. The deepfakes have reportedly been primarily distributed through the messaging app Telegram, where anonymous users have been sharing pornographic images and video manipulated using AI. The images typically involve superimposing the faces of real individuals onto explicit bodies, causing distress and humiliation for the victims.",Entity - malicious human,Responsible Entities,Deepfake porn engulfs South Korean schools,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-porn-engulfs-korean-schools,Incident,,2024,2024,South Korea,Education,,,,"Deepfake - video, image; Machine learning",Create nude images,,Ethics/values; Privacy; Safety,Governance; Marketing,Privacy loss,,,,,,,,10/13/2024 22:58,https://best-paper-award-ddck.dovetail.com/data/JN6AWZDap6SNPeHe1kNUt#:v:h=7vf1Tm9rqtjCATUGSrRQOC
AIAAIC1727,"Over 500 South Korean schools and universities have been overwhelmed with deepfake pornography, humiliating students and causing outrage amongst the broader general public. The deepfakes have reportedly been primarily distributed through the messaging app Telegram, where anonymous users have been sharing pornographic images and video manipulated using AI. The images typically involve superimposing the faces of real individuals onto explicit bodies, causing distress and humiliation for the victims.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake porn engulfs South Korean schools,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-porn-engulfs-korean-schools,Incident,,2024,2024,South Korea,Education,,,,"Deepfake - video, image; Machine learning",Create nude images,,Ethics/values; Privacy; Safety,Governance; Marketing,Privacy loss,,,,,,,,10/13/2024 22:58,https://best-paper-award-ddck.dovetail.com/data/JN6AWZDap6SNPeHe1kNUt#:v:h=7vf1Tm9rqtjCATUGSrRQOC
AIAAIC1727,"Over 500 South Korean schools and universities have been overwhelmed with deepfake pornography, humiliating students and causing outrage amongst the broader general public. The deepfakes have reportedly been primarily distributed through the messaging app Telegram, where anonymous users have been sharing pornographic images and video manipulated using AI. The images typically involve superimposing the faces of real individuals onto explicit bodies, causing distress and humiliation for the victims.",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,Deepfake porn engulfs South Korean schools,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-porn-engulfs-korean-schools,Incident,,2024,2024,South Korea,Education,,,,"Deepfake - video, image; Machine learning",Create nude images,,Ethics/values; Privacy; Safety,Governance; Marketing,Privacy loss,,,,,,,,10/13/2024 22:58,https://best-paper-award-ddck.dovetail.com/data/JN6AWZDap6SNPeHe1kNUt#:v:h=7vf1Tm9rqtjCATUGSrRQOC
AIAAIC1727,"Over 500 South Korean schools and universities have been overwhelmed with deepfake pornography, humiliating students and causing outrage amongst the broader general public. The deepfakes have reportedly been primarily distributed through the messaging app Telegram, where anonymous users have been sharing pornographic images and video manipulated using AI. The images typically involve superimposing the faces of real individuals onto explicit bodies, causing distress and humiliation for the victims.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake porn engulfs South Korean schools,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-porn-engulfs-korean-schools,Incident,,2024,2024,South Korea,Education,,,,"Deepfake - video, image; Machine learning",Create nude images,,Ethics/values; Privacy; Safety,Governance; Marketing,Privacy loss,,,,,,,,10/13/2024 22:58,https://best-paper-award-ddck.dovetail.com/data/JN6AWZDap6SNPeHe1kNUt#:v:h=7vf1Tm9rqtjCATUGSrRQOC
AIAAIC1161, X (formerly Twitter) of the Chinese embassy in France.,Incident - human-driven - Public entity amplified of misleading content,Incident Type,Deepfake Palestinian man carries children out of rubble,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-palestinian-carries-children-out-of-rubble,Incident,,2023,2023,Israel; Palestine,Politics,,,,Deepfake - image; Machine learning,Manipulate public opinion,Fact check,Mis/disinformation,Governance; Marketing,Manipulation,,,,,,,,10/24/2024 21:07,https://best-paper-award-ddck.dovetail.com/data/48vFaID3KLlU48nRi4xqNF#:v:h=7vkZqJYsH4o2SjDvvP1znf
AIAAIC1474,"A video purportedly showing Scotland's new First Minister lambasting his party's former leader and its policies in parliament went viral on social media.  The video showed John Swinney, the new Scottish First Minister in what appeared to be a live Sky News broadcast, thanking Nicola Sturgeon for 'ensuring' his re-election and blasting his party's policies. It was seen over 300,000 times online, having been shared by right-wing social media accounts. However, Swinney's voice had been manipulated using AI in the video. He had been officially installed as Scottish First Minister after Humza Yousaf resigned, and was elected to the post in a vote at Scotland's parliament.",Entity - no specific info,Responsible Entities,Deepfake John Swinney thanks Nicola Sturgeon for his election,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-john-swinney-thanks-nicola-sturgeon-for-his-election,Incident,,2024,2024,UK - Scotland,Politics,,,,"Deepfake - audio, video; Machine learning",Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 20:56,https://best-paper-award-ddck.dovetail.com/data/6Nu1nA3YN5parQMst7omHO#:v:h=7wlRKzGDcG9HbXsYXuSTbo
AIAAIC1474,"A video purportedly showing Scotland's new First Minister lambasting his party's former leader and its policies in parliament went viral on social media.  The video showed John Swinney, the new Scottish First Minister in what appeared to be a live Sky News broadcast, thanking Nicola Sturgeon for 'ensuring' his re-election and blasting his party's policies. It was seen over 300,000 times online, having been shared by right-wing social media accounts. However, Swinney's voice had been manipulated using AI in the video. He had been officially installed as Scottish First Minister after Humza Yousaf resigned, and was elected to the post in a vote at Scotland's parliament.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Deepfake John Swinney thanks Nicola Sturgeon for his election,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-john-swinney-thanks-nicola-sturgeon-for-his-election,Incident,,2024,2024,UK - Scotland,Politics,,,,"Deepfake - audio, video; Machine learning",Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 20:56,https://best-paper-award-ddck.dovetail.com/data/6Nu1nA3YN5parQMst7omHO#:v:h=7wlRKzGDcG9HbXsYXuSTbo
AIAAIC1474,"A video purportedly showing Scotland's new First Minister lambasting his party's former leader and its policies in parliament went viral on social media.  The video showed John Swinney, the new Scottish First Minister in what appeared to be a live Sky News broadcast, thanking Nicola Sturgeon for 'ensuring' his re-election and blasting his party's policies. It was seen over 300,000 times online, having been shared by right-wing social media accounts. However, Swinney's voice had been manipulated using AI in the video. He had been officially installed as Scottish First Minister after Humza Yousaf resigned, and was elected to the post in a vote at Scotland's parliament.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfake John Swinney thanks Nicola Sturgeon for his election,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-john-swinney-thanks-nicola-sturgeon-for-his-election,Incident,,2024,2024,UK - Scotland,Politics,,,,"Deepfake - audio, video; Machine learning",Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 20:56,https://best-paper-award-ddck.dovetail.com/data/6Nu1nA3YN5parQMst7omHO#:v:h=7wlRKzGDcG9HbXsYXuSTbo
AIAAIC1474,"A video purportedly showing Scotland's new First Minister lambasting his party's former leader and its policies in parliament went viral on social media.  The video showed John Swinney, the new Scottish First Minister in what appeared to be a live Sky News broadcast, thanking Nicola Sturgeon for 'ensuring' his re-election and blasting his party's policies. It was seen over 300,000 times online, having been shared by right-wing social media accounts. However, Swinney's voice had been manipulated using AI in the video. He had been officially installed as Scottish First Minister after Humza Yousaf resigned, and was elected to the post in a vote at Scotland's parliament.",Cause - Lack of AI control,Cause,Deepfake John Swinney thanks Nicola Sturgeon for his election,10/25/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfake-john-swinney-thanks-nicola-sturgeon-for-his-election,Incident,,2024,2024,UK - Scotland,Politics,,,,"Deepfake - audio, video; Machine learning",Damage reputation,User comments/complaints,Mis/disinformation,Governance; Marketing,,,,,,,,,10/24/2024 20:56,https://best-paper-award-ddck.dovetail.com/data/6Nu1nA3YN5parQMst7omHO#:v:h=7wlRKzGDcG9HbXsYXuSTbo
AIAAIC1145,"Snapchat's GPT-4-powered My AI feature agreed to meet a 13-year-old girl in a park in Melbourne, Australia, raising questions about the safety and reliability of the system. Posing as a 25-year-old man, the service suggested they meet at a named park one kilometer from where the girl lived, despite her phone's location services being switched off, underscoring existing concerns about its owner's Snap Inc's approach to privacy.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Snapchat My AI requests to meet 13-year-old girl in park,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-my-ai-requests-to-meet-13-year-old-girl-in-park,Incident,2023,2023,2023,Australia,Media/entertainment/sports/arts,Olinda Luketic,Snap Inc; OpenAI,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,User comments/complaints,Accuracy/reliability; Physical safety; Privacy,Governance,Manipulation,,,,,,,,10/7/2024 0:43,https://best-paper-award-ddck.dovetail.com/data/6XDh3rMr4VsRY98OJkDLYT#:v:h=7A3hYMoiYkzPRLksZkr0Iq
AIAAIC1145,"Snapchat's GPT-4-powered My AI feature agreed to meet a 13-year-old girl in a park in Melbourne, Australia, raising questions about the safety and reliability of the system. Posing as a 25-year-old man, the service suggested they meet at a named park one kilometer from where the girl lived, despite her phone's location services being switched off, underscoring existing concerns about its owner's Snap Inc's approach to privacy.",Entity - organization that used AI or allowed for the use of AI by its users (not developer),Responsible Entities,Snapchat My AI requests to meet 13-year-old girl in park,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/snapchat-my-ai-requests-to-meet-13-year-old-girl-in-park,Incident,2023,2023,2023,Australia,Media/entertainment/sports/arts,Olinda Luketic,Snap Inc; OpenAI,My AI; ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,User comments/complaints,Accuracy/reliability; Physical safety; Privacy,Governance,Manipulation,,,,,,,,10/7/2024 0:43,https://best-paper-award-ddck.dovetail.com/data/6XDh3rMr4VsRY98OJkDLYT#:v:h=7A3hYMoiYkzPRLksZkr0Iq
AIAAIC0960,"The unintended exposure on a Twitch live stream of non-consensual deepfake images of a group of female gamers and content creators horrified them, and humiliated the Twitch streamer.","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,"QTCinderella, Pokimane, Sweet Anita deepfakes exposed using live stream",11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/qtcinderella-pokimane-sweet-anita-deepfakes,Incident,,2023,2023,USA,Media/entertainment/sports/arts,,,,Deepfake - image; Machine learning,Generate revenue,Twitch streamer voyeurism,Safety; Privacy; Ethics/values,Governance; Privacy; Marketing,Privacy loss; Emotional damage; Reputational damage,,,,,,,,11/4/2024 16:49,https://best-paper-award-ddck.dovetail.com/data/LaSn2Wonl3QqFQgWUxgLe#:v:h=7A8sZsJNakNaQjkQWN2eVN
AIAAIC1611,"The controversy surrounding Bard's statements reflects broader concerns about bias in AI language models, which are trained on vast amounts of internet data that may contain inherent political leanings.",Cause - AI causes - potential AI bias (racism - inequality) ,Cause,Deepfake France 24 journalist calls Seine water 'unsafe',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-bard-says-the-uks-exit-from-the-european-union-a-bad-idea,Issue,,2024,2024,France,Media/entertainment/sports/arts; Politics,France 24,,,Deepfake - video; Machine learning,Damage reputation,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:08,https://best-paper-award-ddck.dovetail.com/data/4deVRbVj7jbS3yAXDe5qNH#:v:h=7BoeqLayIsKv9SAFLn80Ma
AIAAIC1611,"The controversy surrounding Bard's statements reflects broader concerns about bias in AI language models, which are trained on vast amounts of internet data that may contain inherent political leanings.",Cause - AI causes - AI misinterpretation & hallucinations & faulty functions & inefficiency,Cause,Deepfake France 24 journalist calls Seine water 'unsafe',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-bard-says-the-uks-exit-from-the-european-union-a-bad-idea,Issue,,2024,2024,France,Media/entertainment/sports/arts; Politics,France 24,,,Deepfake - video; Machine learning,Damage reputation,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:08,https://best-paper-award-ddck.dovetail.com/data/4deVRbVj7jbS3yAXDe5qNH#:v:h=7BoeqLayIsKv9SAFLn80Ma
AIAAIC1611,"The controversy surrounding Bard's statements reflects broader concerns about bias in AI language models, which are trained on vast amounts of internet data that may contain inherent political leanings.",Entity - AI developer company,Responsible Entities,Deepfake France 24 journalist calls Seine water 'unsafe',10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/google-bard-says-the-uks-exit-from-the-european-union-a-bad-idea,Issue,,2024,2024,France,Media/entertainment/sports/arts; Politics,France 24,,,Deepfake - video; Machine learning,Damage reputation,User comments/complaints,Ethics/values; Mis/disinformation,Governance; Marketing,,,,,,,,,10/12/2024 1:08,https://best-paper-award-ddck.dovetail.com/data/4deVRbVj7jbS3yAXDe5qNH#:v:h=7BoeqLayIsKv9SAFLn80Ma
AIAAIC1116,"AI-generated nude images of over twenty girls circulated in the town of Almendralejo in the Extremadura region of Spain, shocking the local community and prompting a police investigation. Apparently created by a group of eleven local boys in an attempt to harrass, humiliate and, in one instance, extort young students, pictures were developed using photos of local girls fully clothed, mostly from their personal social media accounts. ",Entity - malicious human,Responsible Entities,Almendralejo hit by AI naked child images,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/almendralejo-hit-by-ai-naked-child-images,Incident,,2023,2023,Spain,Education,Almendralejo school students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,User comments/complaints,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/30/2024 16:32,https://best-paper-award-ddck.dovetail.com/data/4G66AFtrhBoT2nlNuhdSiM#:v:h=7F9M1FGcqUGjtAffR2PYhi
AIAAIC1116,"AI-generated nude images of over twenty girls circulated in the town of Almendralejo in the Extremadura region of Spain, shocking the local community and prompting a police investigation. Apparently created by a group of eleven local boys in an attempt to harrass, humiliate and, in one instance, extort young students, pictures were developed using photos of local girls fully clothed, mostly from their personal social media accounts. ",Cause - Human causes - Human abuse of AI tools,Cause,Almendralejo hit by AI naked child images,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/almendralejo-hit-by-ai-naked-child-images,Incident,,2023,2023,Spain,Education,Almendralejo school students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,User comments/complaints,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/30/2024 16:32,https://best-paper-award-ddck.dovetail.com/data/4G66AFtrhBoT2nlNuhdSiM#:v:h=7F9M1FGcqUGjtAffR2PYhi
AIAAIC1116,"AI-generated nude images of over twenty girls circulated in the town of Almendralejo in the Extremadura region of Spain, shocking the local community and prompting a police investigation. Apparently created by a group of eleven local boys in an attempt to harrass, humiliate and, in one instance, extort young students, pictures were developed using photos of local girls fully clothed, mostly from their personal social media accounts. ","Incident - human-driven - nonconsensual imagery, impersonation, fake content",Incident Type,Almendralejo hit by AI naked child images,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/almendralejo-hit-by-ai-naked-child-images,Incident,,2023,2023,Spain,Education,Almendralejo school students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,User comments/complaints,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/30/2024 16:32,https://best-paper-award-ddck.dovetail.com/data/4G66AFtrhBoT2nlNuhdSiM#:v:h=7F9M1FGcqUGjtAffR2PYhi
AIAAIC1116,"AI-generated nude images of over twenty girls circulated in the town of Almendralejo in the Extremadura region of Spain, shocking the local community and prompting a police investigation. Apparently created by a group of eleven local boys in an attempt to harrass, humiliate and, in one instance, extort young students, pictures were developed using photos of local girls fully clothed, mostly from their personal social media accounts. ",Incident - human-driven - de-anonymize & stalking & harassment,Incident Type,Almendralejo hit by AI naked child images,11/1/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/almendralejo-hit-by-ai-naked-child-images,Incident,,2023,2023,Spain,Education,Almendralejo school students,"Alaiksandr Babichau, Alexander German, Dasha Babicheva, Yevhen Bondarenko",ClothOff,Deepfake - image; Machine learning,Nudify women,User comments/complaints,Ethics/values; Safety; Privacy,Governance; Marketing,Anxiety/distress/depression,,,,,,Police investigation,,10/30/2024 16:32,https://best-paper-award-ddck.dovetail.com/data/4G66AFtrhBoT2nlNuhdSiM#:v:h=7F9M1FGcqUGjtAffR2PYhi
AIAAIC1446,"The Greek Ministry of Migration and Asylum was fined EUR 175,000 for incorrectly developing and installing two surveillance systems at asylum centres on the Aegean islands. Centaur is an integrated digital Electronic and Physical Security management system that uses cameras, drones and motion analysis algorithms to control reception and hospitality structures for third-country citizens on the Aegean islands.  Another system, Hyperion, is described as an integrated entry-exit control system. Asylum seekers, certified members of NGOs and other guests present cards read by an RFID [Radio Frequency Identification] reader combined with a fingerprint through which personal data and biometric data are processed.",Incident - organization/government-driven - use of unlawful/problematic AI tools,Incident Type,Greece fined for AI-powered asylum centre monitoring system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greece-fined-for-ai-powered-asylum-centre-monitoring-system,Incident,,2024,2024,Greece,Govt - immigration,Ministry of Immigration and Asylum,Ministry of Immigration and Asylum,Centaur; Hyperion,Computer vision; Drone; Machine learning; Motion analysis,Monitor asylum centres,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,"EUR 175,000 fine",,,10/2/2024 13:53,https://best-paper-award-ddck.dovetail.com/data/3DmI2hEdtkisj5sDsJPgAG#:v:h=7Fp6Umt2pmauRIDQYAx4J4
AIAAIC1446,"The Greek Ministry of Migration and Asylum was fined EUR 175,000 for incorrectly developing and installing two surveillance systems at asylum centres on the Aegean islands. Centaur is an integrated digital Electronic and Physical Security management system that uses cameras, drones and motion analysis algorithms to control reception and hospitality structures for third-country citizens on the Aegean islands.  Another system, Hyperion, is described as an integrated entry-exit control system. Asylum seekers, certified members of NGOs and other guests present cards read by an RFID [Radio Frequency Identification] reader combined with a fingerprint through which personal data and biometric data are processed.",Entity - government authorities that adopt AI,Responsible Entities,Greece fined for AI-powered asylum centre monitoring system,10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/greece-fined-for-ai-powered-asylum-centre-monitoring-system,Incident,,2024,2024,Greece,Govt - immigration,Ministry of Immigration and Asylum,Ministry of Immigration and Asylum,Centaur; Hyperion,Computer vision; Drone; Machine learning; Motion analysis,Monitor asylum centres,Regulatory inquiry/investigation,Privacy,Governance,Privacy loss,,,,,"EUR 175,000 fine",,,10/2/2024 13:53,https://best-paper-award-ddck.dovetail.com/data/3DmI2hEdtkisj5sDsJPgAG#:v:h=7Fp6Umt2pmauRIDQYAx4J4
AIAAIC1206,OpenAI's ChatGPT chatbot was temporarily banned in Italy amidst concerns that it violated the country's  data collection laws. Italy data privacy regulator Garante questioned OpenAI's data collection practices and whether the breadth of data being retained was legal. It also took issue with the lack of an age verification system to prevent minors from being exposed to inappropriate answers.,Entity - AI developer company,Responsible Entities,Italy bans ChatGPT over data privacy concerns,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/italy-bans-chatgpt-over-privacy-concerns,Incident,2022,2023,2023,Italy,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory action,Privacy,,Privacy loss,,,,,,,,10/7/2024 0:04,https://best-paper-award-ddck.dovetail.com/data/4UkxqcOFQKjmKukEznU8aw#:v:h=7Hb8nR5MQNPDHvySC2Qk0Q
AIAAIC1206,OpenAI's ChatGPT chatbot was temporarily banned in Italy amidst concerns that it violated the country's  data collection laws. Italy data privacy regulator Garante questioned OpenAI's data collection practices and whether the breadth of data being retained was legal. It also took issue with the lack of an age verification system to prevent minors from being exposed to inappropriate answers.,Incident - organization-driven - problematic AI implementation,Incident Type,Italy bans ChatGPT over data privacy concerns,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/italy-bans-chatgpt-over-privacy-concerns,Incident,2022,2023,2023,Italy,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory action,Privacy,,Privacy loss,,,,,,,,10/7/2024 0:04,https://best-paper-award-ddck.dovetail.com/data/4UkxqcOFQKjmKukEznU8aw#:v:h=7Hb8nR5MQNPDHvySC2Qk0Q
AIAAIC1206,OpenAI's ChatGPT chatbot was temporarily banned in Italy amidst concerns that it violated the country's  data collection laws. Italy data privacy regulator Garante questioned OpenAI's data collection practices and whether the breadth of data being retained was legal. It also took issue with the lack of an age verification system to prevent minors from being exposed to inappropriate answers.,Cause - organization causes - legal non-compliance,Cause,Italy bans ChatGPT over data privacy concerns,10/11/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/italy-bans-chatgpt-over-privacy-concerns,Incident,2022,2023,2023,Italy,Multiple,,OpenAI,ChatGPT,Chatbot; Machine learning; NLP/text analysis; Neural network; Deep learning; Machine learning; Reinforcement learning,Generate text,Regulatory action,Privacy,,Privacy loss,,,,,,,,10/7/2024 0:04,https://best-paper-award-ddck.dovetail.com/data/4UkxqcOFQKjmKukEznU8aw#:v:h=7Hb8nR5MQNPDHvySC2Qk0Q
AIAAIC1624,"he British Medical Journal (BMJ) found AI-generated videos falsely featuring UK TV doctors, including the late Michael Mosley, Hilary Jones and Rajan Chatterjee, endorsing products for blood pressure and diabetes, and selling items such as hemp gummies. Designed to exploit the trust many people have in health experts, many of the videos were discovered on Facebook, YouTube and Instagram, and frequently resurfaced despite efforts to remove them.",Cause - Human causes - Human abuse of AI tools,Cause,Deepfakes of UK health expert used to promote health scams,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfakes-of-uk-tv-health-experts-used-to-promote-health-scams,Incident,2023,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - video; Machine learning,Generate video,Industry investigation,Ethics/values; Fraud; Personality rights; Mis/disinformation,Governance; Marketing,Personality rights loss,,,,,,,,10/12/2024 1:21,https://best-paper-award-ddck.dovetail.com/data/pFSly53pGLC6OGZhCpmoX#:v:h=7HGdYFZS2gdqIH9TvfOF2N
AIAAIC1624,"he British Medical Journal (BMJ) found AI-generated videos falsely featuring UK TV doctors, including the late Michael Mosley, Hilary Jones and Rajan Chatterjee, endorsing products for blood pressure and diabetes, and selling items such as hemp gummies. Designed to exploit the trust many people have in health experts, many of the videos were discovered on Facebook, YouTube and Instagram, and frequently resurfaced despite efforts to remove them.",Entity - malicious human,Responsible Entities,Deepfakes of UK health expert used to promote health scams,10/18/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/deepfakes-of-uk-tv-health-experts-used-to-promote-health-scams,Incident,2023,2024,2024,UK,Media/entertainment/sports/arts,,,,Deepfake - video; Machine learning,Generate video,Industry investigation,Ethics/values; Fraud; Personality rights; Mis/disinformation,Governance; Marketing,Personality rights loss,,,,,,,,10/12/2024 1:21,https://best-paper-award-ddck.dovetail.com/data/pFSly53pGLC6OGZhCpmoX#:v:h=7HGdYFZS2gdqIH9TvfOF2N
AIAAIC1303,"The complaint, which seeks USD 15,000 for each resident harmed, named the company, its cofounders Lucasz Kowalczyk and Denis Tatina, and its current CEO Giorgi Gobronidze, as defendants. BIPA makes it illegal for companies to collect or store data, including data about Illinois residents' faces, without their consent.  It also states that visitors must be informed in writing of the specific purpose of why the biometric data is being collected, how long it will be stored, and that companies must receive a written release from visitors for the collection of biometric data. ",Entity - AI developer company,Responsible Entities,"PimEyes sued in Illinois, USA, for privacy violations",10/4/2024 0:00,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/pimeyes-sued-in-illinois-usa-for-privacy-violations,Incident,2017,2023,2023,USA,Technology,PimEyes,PimEyes,PimEyes,Facial recognition,Identify individuals,Lawsuit filing/litigation,Governance; Privacy,Governance,Privacy loss,,,,,,Litigation,,10/2/2024 20:44,https://best-paper-award-ddck.dovetail.com/data/2kP3ZgJskd8oyopMz2hnhm#:v:h=7J4YAnyhdYJwOq1AP8Tg6D
